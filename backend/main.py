from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Query
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from typing import Optional, List
from pydantic import BaseModel
import json
import os
import requests
import shutil
import time
from urllib.parse import urlparse
from video_generator import VideoGenerator
import random
import glob
import re
import asyncio
from bs4 import BeautifulSoup
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError as e:
    print(f"OpenAI import ì˜¤ë¥˜: {e}")
    OpenAI = None
    OPENAI_AVAILABLE = False
import logging
import re
import uuid
from urllib.parse import urlparse, parse_qs
from dotenv import load_dotenv
try:
    from youtube_transcript_api import YouTubeTranscriptApi
    YOUTUBE_TRANSCRIPT_AVAILABLE = True
except ImportError as e:
    print(f"YouTube Transcript API import ì˜¤ë¥˜: {e}")
    print("pip install youtube-transcript-api==0.6.1 ë¡œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    YouTubeTranscriptApi = None
    YOUTUBE_TRANSCRIPT_AVAILABLE = False

try:
    import aiohttp
    AIOHTTP_AVAILABLE = True
except ImportError as e:
    print(f"aiohttp import ì˜¤ë¥˜: {e}")
    print("pip install aiohttp==3.9.1 ë¡œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    aiohttp = None
    AIOHTTP_AVAILABLE = False
# Updated with create_simple_group_clip method

# ìƒˆë¡œìš´ ëª¨ë“ˆë“¤ import (ë°°ì¹˜ ì‘ì—… ì‹œìŠ¤í…œ)
try:
    from job_queue import job_queue, JobStatus
    from email_service import email_service
    JOB_QUEUE_AVAILABLE = True
    print("âœ… ë°°ì¹˜ ì‘ì—… ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ ë°°ì¹˜ ì‘ì—… ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    job_queue = None
    email_service = None
    JOB_QUEUE_AVAILABLE = False

# Job ë¡œê¹… ì‹œìŠ¤í…œ import
try:
    from job_logger import job_logger
    JOB_LOGGER_AVAILABLE = True
    print("âœ… Job ë¡œê¹… ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ Job ë¡œê¹… ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    job_logger = None
    JOB_LOGGER_AVAILABLE = False

# Folder ê´€ë¦¬ ì‹œìŠ¤í…œ import
try:
    from folder_manager import folder_manager
    FOLDER_MANAGER_AVAILABLE = True
    print("âœ… Folder ê´€ë¦¬ ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ Folder ê´€ë¦¬ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    folder_manager = None
    FOLDER_MANAGER_AVAILABLE = False

# ì¸ë„¤ì¼ ìƒì„± ì‹œìŠ¤í…œ import
try:
    from thumbnail_generator import generate_missing_thumbnails
    THUMBNAIL_GENERATOR_AVAILABLE = True
    print("âœ… ì¸ë„¤ì¼ ìƒì„± ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    print(f"âš ï¸ ì¸ë„¤ì¼ ìƒì„± ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {e}")
    generate_missing_thumbnails = None
    THUMBNAIL_GENERATOR_AVAILABLE = False

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# API ë¡œê¹… ì„¤ì • - ì„œë²„ ì¬ì‹œì‘ ì‹œ ê¸°ì¡´ ë¡œê·¸ ì‚­ì œ
API_LOG_FILE = "api.log"
if os.path.exists(API_LOG_FILE):
    os.remove(API_LOG_FILE)
    print(f"ğŸ—‘ï¸ ê¸°ì¡´ ë¡œê·¸ íŒŒì¼ ì‚­ì œ: {API_LOG_FILE}")

# ë¡œê±° ì„¤ì • - api.log íŒŒì¼ì—ë§Œ ì¶œë ¥ (ì½˜ì†” ì¶œë ¥ ì œê±°)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(API_LOG_FILE, encoding='utf-8')
    ],
    force=True  # ê¸°ì¡´ ì„¤ì • ê°•ì œ ì¬ì„¤ì •
)
logger = logging.getLogger(__name__)
logger.info(f"âœ… API ë¡œê·¸ íŒŒì¼ ìƒì„±: {API_LOG_FILE}")

app = FastAPI(title="Reels Video Generator", version="1.0.0")

# uploads ë””ë ‰í† ë¦¬ ìƒì„± (ì •ì  íŒŒì¼ ë§ˆìš´íŠ¸ëŠ” nginxì—ì„œ ì²˜ë¦¬)
uploads_dir = os.path.join(os.path.dirname(__file__), "uploads")
os.makedirs(uploads_dir, exist_ok=True)

# Pydantic ëª¨ë¸ ì •ì˜
class URLExtractRequest(BaseModel):
    url: str

class ImageGenerateRequest(BaseModel):
    texts: List[str]  # ì´ë¯¸ì§€ ìƒì„±í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    mode: str = "per_script"  # "per_script" ë˜ëŠ” "per_two_scripts"
    job_id: Optional[str] = None  # Job ID ì¶”ê°€ (ì„ íƒì )

class ReelsContent(BaseModel):
    title: str
    body1: str = ""
    body2: str = ""
    body3: str = ""
    body4: str = ""
    body5: str = ""
    body6: str = ""
    body7: str = ""

# ë°°ì¹˜ ì‘ì—… ê´€ë ¨ ëª¨ë¸ë“¤
class AsyncVideoRequest(BaseModel):
    user_email: str
    content_data: str
    music_mood: str = "bright"
    image_allocation_mode: str = "2_per_image"
    text_position: str = "bottom"
    text_style: str = "outline"
    title_area_mode: str = "keep"
    selected_bgm_path: str = ""
    use_test_files: bool = False

class JobStatusResponse(BaseModel):
    job_id: str
    status: str
    created_at: str
    updated_at: str
    result: Optional[dict] = None
    error_message: Optional[str] = None

# Job í´ë” ê´€ë ¨ ëª¨ë¸ë“¤
class CreateJobFolderRequest(BaseModel):
    job_id: str

class CreateJobFolderResponse(BaseModel):
    status: str
    message: str
    job_id: str
    uploads_folder: Optional[str] = None
    output_folder: Optional[str] = None

class CleanupJobFolderRequest(BaseModel):
    job_id: str
    keep_output: bool = True

class CleanupJobFolderResponse(BaseModel):
    status: str
    message: str
    job_id: str
    cleaned: bool

# OpenAI import ìƒíƒœ ë¡œê¹…
if OPENAI_AVAILABLE:
    logger.info("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì„±ê³µ")
else:
    logger.error("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨")

# aiohttp import ìƒíƒœ ë¡œê¹…
if AIOHTTP_AVAILABLE:
    logger.info("aiohttp ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì„±ê³µ - ë³‘ë ¬ ì´ë¯¸ì§€ ì²˜ë¦¬ ê°€ëŠ¥")
else:
    logger.warning("aiohttp ë¼ì´ë¸ŒëŸ¬ë¦¬ import ì‹¤íŒ¨ - ìˆœì°¨ ì´ë¯¸ì§€ ì²˜ë¦¬ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤")

# OpenAI API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ë¡œë“œ)
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
if not OPENAI_API_KEY:
    logger.warning("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. URLì—ì„œ ë¦´ìŠ¤ ì¶”ì¶œ ê¸°ëŠ¥ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
else:
    logger.info("OpenAI API í‚¤ ë¡œë“œ ì„±ê³µ")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://zstus.synology.me:8097"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì˜ìƒ ì¶œë ¥ í´ë” ì„¤ì •
OUTPUT_FOLDER = "output_videos"
UPLOAD_FOLDER = "uploads"
BGM_FOLDER = "bgm"
BOOKMARK_VIDEOS_FOLDER = os.path.join("assets", "videos", "bookmark")

# í´ë” ìƒì„±
os.makedirs(OUTPUT_FOLDER, exist_ok=True)
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(BGM_FOLDER, exist_ok=True)
os.makedirs(BOOKMARK_VIDEOS_FOLDER, exist_ok=True)

# ê¸€ë¡œë²Œ ë³€ìˆ˜
CURRENT_BGM_PATH = None

async def download_file(url: str, save_path: str):
    """URLì—ì„œ íŒŒì¼ ë‹¤ìš´ë¡œë“œ"""
    try:
        response = requests.get(url, stream=True, timeout=30)
        response.raise_for_status()
        
        with open(save_path, 'wb') as f:
            for chunk in response.iter_content(chunk_size=8192):
                f.write(chunk)
        
        print(f"âœ… ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {url} â†’ {os.path.basename(save_path)}")
        return True
    except Exception as e:
        print(f"âŒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {url} - {e}")
        return False

def get_file_extension(url: str) -> str:
    """URLì—ì„œ íŒŒì¼ í™•ì¥ì ì¶”ì¶œ"""
    parsed = urlparse(url)
    path = parsed.path.lower()
    
    # ì¼ë°˜ì ì¸ í™•ì¥ìë“¤
    for ext in ['.mp3', '.wav', '.m4a', '.json', '.png', '.jpg', '.jpeg', '.gif', '.webp', '.bmp']:
        if path.endswith(ext):
            return ext
    
    # ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì—ì„œ í™•ì¥ì ì°¾ê¸°
    if '.' in path:
        return os.path.splitext(path)[1]
    
    return ''  # í™•ì¥ì ì—†ìŒ

def select_random_bgm(mood: str) -> str:
    """bgm í´ë”ì—ì„œ ì§€ì •ëœ ì„±ê²©ì˜ ìŒì•…ì„ ëœë¤ ì„ íƒ"""
    valid_moods = ["bright", "calm", "romantic", "sad", "suspense"]
    
    if mood not in valid_moods:
        print(f"âš ï¸ ì˜ëª»ëœ ìŒì•… ì„±ê²©: {mood}, ê¸°ë³¸ê°’ 'bright' ì‚¬ìš©")
        mood = "bright"
    
    mood_folder = os.path.join(BGM_FOLDER, mood)
    
    # bgm í´ë”ê°€ ì—†ëŠ” ê²½ìš°
    if not os.path.exists(mood_folder):
        print(f"âŒ bgm/{mood} í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. test í´ë” ìŒì•… ì‚¬ìš©")
        return None
    
    # ìŒì•… íŒŒì¼ë“¤ ê²€ìƒ‰ (mp3, wav, m4a ì§€ì›)
    music_patterns = ["*.mp3", "*.wav", "*.m4a"]
    music_files = []
    
    for pattern in music_patterns:
        music_files.extend(glob.glob(os.path.join(mood_folder, pattern)))
    
    if not music_files:
        print(f"âŒ bgm/{mood} í´ë”ì— ìŒì•… íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. test í´ë” ìŒì•… ì‚¬ìš©")
        return None
    
    # ëœë¤ ì„ íƒ
    selected_music = random.choice(music_files)
    print(f"ğŸµ ì„ íƒëœ {mood} ìŒì•…: {os.path.basename(selected_music)}")
    
    return selected_music

def copy_test_images():
    """test í´ë”ì—ì„œ uploads í´ë”ë¡œ ì´ë¯¸ì§€ ë° ë¹„ë””ì˜¤ íŒŒì¼ë“¤ ë³µì‚¬"""
    try:
        test_folder = "./test"
        media_extensions = ["jpg", "jpeg", "png", "bmp", "gif", "webp", "mp4", "mov", "avi", "webm", "mkv"]
        
        # 1, 2, 3, 4 ìˆœì„œë¡œ ë¯¸ë””ì–´ íŒŒì¼ ì°¾ê¸°
        copied_count = 0
        for i in range(1, 5):  # 1, 2, 3, 4
            found_file = None
            for ext in media_extensions:
                test_path = os.path.join(test_folder, f"{i}.{ext}")
                if os.path.exists(test_path):
                    found_file = test_path
                    break
            
            if found_file:
                # ì›ë³¸ í™•ì¥ì ìœ ì§€í•˜ì—¬ uploadsì— ë³µì‚¬
                original_ext = os.path.splitext(found_file)[1]
                target_name = f"{i}{original_ext}"
                target_path = os.path.join(UPLOAD_FOLDER, target_name)
                
                shutil.copy2(found_file, target_path)
                file_type = "ë¹„ë””ì˜¤" if original_ext.lower() in ['.mp4', '.mov', '.avi', '.webm', '.mkv'] else "ì´ë¯¸ì§€"
                print(f"âœ… test {file_type} ë³µì‚¬: {os.path.basename(found_file)} â†’ {target_name}")
                copied_count += 1
            else:
                print(f"âš ï¸ {i}ë²ˆ ë¯¸ë””ì–´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì§€ì› í˜•ì‹: {', '.join(media_extensions)})")
        
        print(f"ğŸ“Š test í´ë”ì—ì„œ {copied_count}ê°œ ë¯¸ë””ì–´ íŒŒì¼ ë³µì‚¬ ì™„ë£Œ")
        return True
        
    except Exception as e:
        print(f"âŒ test ì´ë¯¸ì§€ ë³µì‚¬ ì‹¤íŒ¨: {e}")
        return False

async def prepare_files(json_url: str, music_mood: str, image_urls: str, 
                       content_data: str, background_music, use_test_files: bool,
                       selected_bgm_path: str = "", uploaded_images: List = []):
    """ëª¨ë“  íŒŒì¼ì„ uploads í´ë”ì— ì¤€ë¹„"""
    
    # 1. JSON íŒŒì¼ ì²˜ë¦¬
    if use_test_files:
        # test í´ë”ì˜ JSON ë³µì‚¬
        test_json = "./test/text.json"
        if os.path.exists(test_json):
            shutil.copy2(test_json, os.path.join(UPLOAD_FOLDER, "text.json"))
            print("âœ… test JSON ë³µì‚¬: text.json â†’ text.json")
        else:
            raise ValueError("test/text.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
    else:
        # URL ë˜ëŠ” ì§ì ‘ ë°ì´í„°ë¡œ JSON ì²˜ë¦¬
        if json_url:
            json_path = os.path.join(UPLOAD_FOLDER, "text.json")
            await download_file(json_url, json_path)
        elif content_data:
            json_path = os.path.join(UPLOAD_FOLDER, "text.json")
            content = json.loads(content_data)  # ê²€ì¦
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(content, f, ensure_ascii=False, indent=2)
            print("âœ… ì§ì ‘ JSON ë°ì´í„° ì €ì¥: text.json")
        else:
            raise ValueError("JSON ë‚´ìš©ì´ í•„ìš”í•©ë‹ˆë‹¤ (json_url ë˜ëŠ” content_data)")
    
    # 2. ìŒì•… íŒŒì¼ ì²˜ë¦¬ (ìš°ì„ ìˆœìœ„: ì—…ë¡œë“œ > ì„ íƒëœ íŒŒì¼ > ëœë¤)
    global CURRENT_BGM_PATH
    
    if background_music:
        # ì§ì ‘ ì—…ë¡œë“œëœ ìŒì•… íŒŒì¼ ì €ì¥ (ìš°ì„ ìˆœìœ„ 1)
        music_path = os.path.join(UPLOAD_FOLDER, "back.mp3")
        with open(music_path, "wb") as f:
            content = await background_music.read()
            f.write(content)
        print("âœ… ì—…ë¡œë“œ ìŒì•… ì €ì¥: back.mp3")
        CURRENT_BGM_PATH = None  # ì—…ë¡œë“œ íŒŒì¼ ì‚¬ìš©ì‹œ ê¸€ë¡œë²Œ ë³€ìˆ˜ ì´ˆê¸°í™”
    elif selected_bgm_path:
        # íŠ¹ì • BGM íŒŒì¼ì´ ì„ íƒëœ ê²½ìš° (ìš°ì„ ìˆœìœ„ 2)
        bgm_file_path = os.path.join(BGM_FOLDER, music_mood, selected_bgm_path)
        if os.path.exists(bgm_file_path):
            CURRENT_BGM_PATH = bgm_file_path
            print(f"ğŸµ ì„ íƒëœ BGM íŒŒì¼ ì‚¬ìš©: {selected_bgm_path}")
        else:
            # ì„ íƒëœ íŒŒì¼ì´ ì—†ìœ¼ë©´ ëœë¤ ì„ íƒìœ¼ë¡œ í´ë°±
            print(f"âš ï¸ ì„ íƒëœ íŒŒì¼({selected_bgm_path})ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ëœë¤ ì„ íƒìœ¼ë¡œ ë³€ê²½")
            selected_bgm = select_random_bgm(music_mood)
            if not selected_bgm:
                raise ValueError(f"ë°°ê²½ìŒì•…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. bgm/{music_mood} í´ë”ì— ìŒì•… íŒŒì¼ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
            CURRENT_BGM_PATH = selected_bgm
    else:
        # bgm í´ë”ì—ì„œ ì„±ê²©ë³„ ëœë¤ ìŒì•… ì„ íƒ (ìš°ì„ ìˆœìœ„ 3)
        print(f"ğŸµ ìŒì•… ì„±ê²© '{music_mood}' ê¸°ë°˜ìœ¼ë¡œ bgm ëœë¤ ì„ íƒ ì¤‘...")
        selected_bgm = select_random_bgm(music_mood)
        
        if not selected_bgm:
            raise ValueError(f"ë°°ê²½ìŒì•…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. bgm/{music_mood} í´ë”ì— ìŒì•… íŒŒì¼(.mp3/.wav/.m4a)ì„ ì¶”ê°€í•´ì£¼ì„¸ìš”.")
        
        CURRENT_BGM_PATH = selected_bgm
        print(f"ğŸµ ëœë¤ ì„ íƒëœ BGM: {os.path.basename(selected_bgm)}")
    
    # 3. ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì²˜ë¦¬
    if use_test_files:
        # test í´ë”ì—ì„œ ì´ë¯¸ì§€ë“¤ë§Œ ë³µì‚¬
        copy_test_images()
        print("ğŸ“Š test í´ë” ì´ë¯¸ì§€ ì‚¬ìš©")
    elif uploaded_images:
        # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ì €ì¥
        for i, image_file in enumerate(uploaded_images, 1):
            if image_file:
                # íŒŒì¼ í™•ì¥ì ì¶”ì¶œ
                ext = os.path.splitext(image_file.filename)[1] or '.png'
                image_path = os.path.join(UPLOAD_FOLDER, f"{i}{ext}")
                
                # ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
                with open(image_path, "wb") as f:
                    content = await image_file.read()
                    f.write(content)
                
                print(f"âœ… ì´ë¯¸ì§€ {i} ì €ì¥: {image_file.filename} â†’ {i}{ext}")
        
        print(f"ğŸ“Š {len(uploaded_images)}ê°œ ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")
    else:
        # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (ê¸°ì¡´ ë°©ì‹)
        try:
            image_url_list = json.loads(image_urls) if image_urls else []
        except:
            image_url_list = []
        
        if image_url_list:
            for i, img_url in enumerate(image_url_list, 1):
                ext = get_file_extension(img_url)
                if not ext:
                    ext = '.png'
                img_path = os.path.join(UPLOAD_FOLDER, f"{i}{ext}")
                await download_file(img_url, img_path)
            print(f"ğŸ“Š {len(image_url_list)}ê°œ ì´ë¯¸ì§€ URLì—ì„œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")
        else:
            raise ValueError("ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤ (uploaded_images, image_urls ë˜ëŠ” use_test_files=true)")

@app.get("/")
async def root():
    return {"message": "Reels Video Generator API"}

@app.get("/status")
async def get_status():
    """API ìƒíƒœ ë° ê¸°ëŠ¥ í™•ì¸"""
    status = {
        "status": "running",
        "features": {
            "openai": OPENAI_AVAILABLE,
            "youtube_transcript": YOUTUBE_TRANSCRIPT_AVAILABLE,
            "aiohttp": AIOHTTP_AVAILABLE
        },
        "message": "Reels Video Generator API is running"
    }
    
    warnings = []
    if not YOUTUBE_TRANSCRIPT_AVAILABLE:
        warnings.append("YouTube transcript APIê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pip install youtube-transcript-api==0.6.1 ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    
    if not AIOHTTP_AVAILABLE:
        warnings.append("aiohttp ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. pip install aiohttp==3.9.1 ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”. ë³‘ë ¬ ì´ë¯¸ì§€ ìƒì„±ì´ ìˆœì°¨ ì²˜ë¦¬ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤.")
    
    if warnings:
        status["warnings"] = warnings
    
    return status

@app.get("/youtube-test-videos")
async def get_youtube_test_videos():
    """ìë§‰ì´ ìˆëŠ” YouTube í…ŒìŠ¤íŠ¸ ë¹„ë””ì˜¤ ëª©ë¡"""
    return {
        "status": "success",
        "recommended_videos": [
            {
                "title": "Me at the zoo (ì²« ë²ˆì§¸ YouTube ë¹„ë””ì˜¤)",
                "url": "https://www.youtube.com/watch?v=jNQXAC9IVRw",
                "language": "English",
                "description": "YouTube ì—­ì‚¬ìƒ ì²« ë²ˆì§¸ ì—…ë¡œë“œëœ ë¹„ë””ì˜¤, ì˜ì–´ ìë§‰"
            },
            {
                "title": "PSY - Gangnam Style",
                "url": "https://www.youtube.com/watch?v=9bZkp7q19f0", 
                "language": "Korean/English",
                "description": "ì„¸ê³„ì ìœ¼ë¡œ ìœ ëª…í•œ K-POP ë¹„ë””ì˜¤, ë‹¤êµ­ì–´ ìë§‰"
            },
            {
                "title": "TED Talk ì˜ˆì‹œ",
                "url": "https://www.youtube.com/watch?v=ZSHk0I9XHLE",
                "language": "English/Multiple",
                "description": "êµìœ¡ì ì¸ ë‚´ìš©ìœ¼ë¡œ ìë§‰ì´ ì˜ ë˜ì–´ìˆìŒ"
            }
        ],
        "tips": [
            "TED Talks, ê¸°ì—… ê³µì‹ ì±„ë„, êµìœ¡ ì½˜í…ì¸ ëŠ” ë³´í†µ ìë§‰ì´ ì˜ ë˜ì–´ìˆìŠµë‹ˆë‹¤",
            "ê°œì¸ ë¸Œì´ë¡œê·¸, ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¼, ìŒì•… ë¹„ë””ì˜¤ëŠ” ìë§‰ì´ ì—†ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤",
            "ë¹„ë””ì˜¤ ì¬ìƒ ì‹œ ì„¤ì •ì—ì„œ 'ìë§‰/CC'ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”"
        ]
    }

@app.post("/generate-video")
async def generate_video(
    # ì›¹ì„œë¹„ìŠ¤ìš© URL ì…ë ¥
    json_url: str = Form(default=""),           # JSON ë‚´ìš© URL
    music_mood: str = Form(default="bright"),   # ë°°ê²½ìŒì•… ì„±ê²© (bright, calm, romantic, sad, suspense)
    image_urls: str = Form(default="[]"),       # ì´ë¯¸ì§€ URLs JSON ë°°ì—´
    
    # ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€ (ì˜µì…˜)
    content_data: str = Form(default=""),       # ì§ì ‘ JSON ë‚´ìš©
    background_music: Optional[UploadFile] = File(None),  # ì§ì ‘ ìŒì•… ì—…ë¡œë“œ
    
    # ìƒˆë¡œìš´ íŒŒë¼ë¯¸í„°: ì„ íƒëœ BGM íŒŒì¼ëª…
    selected_bgm_path: str = Form(default=""),  # ì„ íƒëœ BGM íŒŒì¼ ê²½ë¡œ
    
    # ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ ì„ íƒ
    image_allocation_mode: str = Form(default="2_per_image"),  # "2_per_image" ë˜ëŠ” "1_per_image"
    
    # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì„ íƒ
    text_position: str = Form(default="bottom"),  # "top", "bottom", "bottom-edge"
    
    # í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ì„ íƒ
    text_style: str = Form(default="outline"),  # "outline" (ì™¸ê³½ì„ ) ë˜ëŠ” "background" (ë°˜íˆ¬ëª… ë°°ê²½)

    # íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œ ì„ íƒ
    title_area_mode: str = Form(default="keep"),  # "keep" (í™•ë³´) ë˜ëŠ” "remove" (ì œê±°)

    # í°íŠ¸ ì„¤ì •
    title_font: str = Form(default="BMYEONSUNG_otf.otf"),  # íƒ€ì´í‹€ í°íŠ¸
    body_font: str = Form(default="BMYEONSUNG_otf.otf"),   # ë³¸ë¬¸ í°íŠ¸
    title_font_size: int = Form(default=42),               # íƒ€ì´í‹€ í°íŠ¸ í¬ê¸° (pt)
    body_font_size: int = Form(default=36),                # ë³¸ë¬¸ í°íŠ¸ í¬ê¸° (pt)

    # ìë§‰ ì½ì–´ì£¼ê¸° ì„¤ì •
    voice_narration: str = Form(default="enabled"),        # "enabled" (ì¶”ê°€) ë˜ëŠ” "disabled" (ì œê±°)

    # í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì„¤ì •
    cross_dissolve: str = Form(default="enabled"),          # "enabled" (ì ìš©) ë˜ëŠ” "disabled" (ë¯¸ì ìš©)

    # ìë§‰ ì§€ì† ì‹œê°„ ì„¤ì • (ì´ˆ ë‹¨ìœ„)
    subtitle_duration: float = Form(default=0.0),           # 0: ìŒì„± ê¸¸ì´ ì‚¬ìš©, 0 ì´ˆê³¼: ì§€ì • ì‹œê°„ ì‚¬ìš©

    # ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ (ìµœëŒ€ 8ê°œ)
    image_1: Optional[UploadFile] = File(None),
    image_2: Optional[UploadFile] = File(None),
    image_3: Optional[UploadFile] = File(None),
    image_4: Optional[UploadFile] = File(None),
    image_5: Optional[UploadFile] = File(None),
    image_6: Optional[UploadFile] = File(None),
    image_7: Optional[UploadFile] = File(None),
    image_8: Optional[UploadFile] = File(None),

    # ëª¨ë“œ ì„¤ì •
    use_test_files: bool = Form(default=False),  # test í´ë” ì‚¬ìš© ì—¬ë¶€

    # Job ID (ì„ íƒì )
    job_id: Optional[str] = Form(None)  # Job ID ì¶”ê°€
):
    try:
        print("ğŸš€ ì›¹ì„œë¹„ìŠ¤ API í˜¸ì¶œ ì‹œì‘")

        # Job IDì— ë”°ë¼ ì‘ì—… í´ë” ì„¤ì •
        global UPLOAD_FOLDER, OUTPUT_FOLDER
        original_upload_folder = UPLOAD_FOLDER
        original_output_folder = OUTPUT_FOLDER

        if job_id and FOLDER_MANAGER_AVAILABLE:
            try:
                job_uploads_folder, job_output_folder = folder_manager.get_job_folders(job_id)
                UPLOAD_FOLDER = job_uploads_folder
                OUTPUT_FOLDER = job_output_folder
                print(f"ğŸ—‚ï¸ Job ê³ ìœ  í´ë” ì‚¬ìš© (ì˜ìƒ ìƒì„±): uploads={UPLOAD_FOLDER}, output={OUTPUT_FOLDER}")
            except Exception as job_error:
                print(f"âš ï¸ Job í´ë” ì‚¬ìš© ì‹¤íŒ¨, ê¸°ë³¸ í´ë” ì‚¬ìš© (ì˜ìƒ ìƒì„±): {job_error}")

        # 1. uploads í´ë” ì¤€ë¹„ ë° ì •ë¦¬
        if job_id and FOLDER_MANAGER_AVAILABLE:
            # Job í´ë” ì‚¬ìš© ì‹œ: ê¸°ì¡´ íŒŒì¼ë“¤ ë³´ì¡´ (ì´ë¯¸ì§€ ìë™ìƒì„±, í”„ë¦¬ë·° ë“±)
            os.makedirs(UPLOAD_FOLDER, exist_ok=True)
            print(f"ğŸ“ ê¸°ì¡´ Job í´ë” ì¬ì‚¬ìš©: {UPLOAD_FOLDER}")
        else:
            # ê¸°ë³¸ í´ë” ì‚¬ìš© ì‹œ: ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ í´ë” ì´ˆê¸°í™”
            if os.path.exists(UPLOAD_FOLDER):
                shutil.rmtree(UPLOAD_FOLDER)
            os.makedirs(UPLOAD_FOLDER, exist_ok=True)
            print("ğŸ“ uploads í´ë” ì¤€ë¹„ ì™„ë£Œ")
        
        # 2. íŒŒì¼ë“¤ì„ uploads í´ë”ì— ì¤€ë¹„
        # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ìˆ˜ì§‘
        uploaded_images = [
            image_1, image_2, image_3, image_4,
            image_5, image_6, image_7, image_8
        ]
        uploaded_images = [img for img in uploaded_images if img is not None]
        
        await prepare_files(
            json_url, music_mood, image_urls, 
            content_data, background_music, use_test_files,
            selected_bgm_path, uploaded_images
        )
        
        # 3. uploads í´ë”ì˜ íŒŒì¼ë“¤ë¡œ ì˜ìƒ ìƒì„±
        video_gen = VideoGenerator()
        # bgm íŒŒì¼ ê²½ë¡œ ê²°ì • ìš°ì„ ìˆœìœ„:
        # 1. ì§ì ‘ ì—…ë¡œë“œëœ ìŒì•… íŒŒì¼
        # 2. ì„ íƒëœ íŠ¹ì • BGM íŒŒì¼
        # 3. ì„±ê²©ë³„ ëœë¤ ì„ íƒ (ê¸°ì¡´ ë°©ì‹)
        if background_music:
            bgm_file = os.path.join(UPLOAD_FOLDER, "back.mp3")
            print(f"ğŸµ ì§ì ‘ ì—…ë¡œë“œëœ ìŒì•… ì‚¬ìš©: {bgm_file}")
        elif CURRENT_BGM_PATH:
            bgm_file = CURRENT_BGM_PATH
            print(f"ğŸµ ì„ íƒëœ BGM íŒŒì¼ ì‚¬ìš©: {bgm_file}")
        else:
            bgm_file = None
            print("âš ï¸ BGM íŒŒì¼ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # Frontendì˜ ëª¨ë“œë¥¼ Backend í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        # ğŸ¯ ë¯¸ë””ì–´ ì—…ë¡œë“œ ëª¨ë“œ 3ê°€ì§€ ì˜µì…˜:
        # 1. per-script: ëŒ€ì‚¬ë§ˆë‹¤ ë¯¸ë””ì–´ 1ê°œ (1:1 ë§¤í•‘)
        # 2. per-two-scripts: ëŒ€ì‚¬ 2ê°œë§ˆë‹¤ ë¯¸ë””ì–´ 1ê°œ (2:1 ë§¤í•‘)
        # 3. single-for-all: ëª¨ë“  ëŒ€ì‚¬ì— ë¯¸ë””ì–´ 1ê°œ (1:ALL ë§¤í•‘)
        mode_mapping = {
            "per-script": "1_per_image",           # ëŒ€ì‚¬ë§ˆë‹¤ ë¯¸ë””ì–´ 1ê°œ
            "per-two-scripts": "2_per_image",      # ëŒ€ì‚¬ 2ê°œë§ˆë‹¤ ë¯¸ë””ì–´ 1ê°œ
            "single-for-all": "single_for_all"     # ëª¨ë“  ëŒ€ì‚¬ì— ë¯¸ë””ì–´ 1ê°œ
        }

        if image_allocation_mode in mode_mapping:
            original_mode = image_allocation_mode
            image_allocation_mode = mode_mapping[image_allocation_mode]
            print(f"ğŸ¯ ë¯¸ë””ì–´ ëª¨ë“œ ë³€í™˜: {original_mode} â†’ {image_allocation_mode}")

        # ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ ê²€ì¦
        if image_allocation_mode not in ["2_per_image", "1_per_image", "single_for_all"]:
            image_allocation_mode = "2_per_image"  # ê¸°ë³¸ê°’
            print(f"âš ï¸ ì˜ëª»ëœ ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ, ê¸°ë³¸ê°’ ì‚¬ìš©: {image_allocation_mode}")
        
        # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê²€ì¦
        if text_position not in ["top", "bottom", "bottom-edge"]:
            text_position = "bottom"  # ê¸°ë³¸ê°’
            print(f"âš ï¸ ì˜ëª»ëœ í…ìŠ¤íŠ¸ ìœ„ì¹˜, ê¸°ë³¸ê°’ ì‚¬ìš©: {text_position}")
        
        # í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ê²€ì¦
        if text_style not in ["outline", "background"]:
            text_style = "outline"  # ê¸°ë³¸ê°’
            print(f"âš ï¸ ì˜ëª»ëœ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼, ê¸°ë³¸ê°’ ì‚¬ìš©: {text_style}")
        
        print(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ: {image_allocation_mode}")
        print(f"ğŸ“ í…ìŠ¤íŠ¸ ìœ„ì¹˜: {text_position}")
        print(f"ğŸ¨ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼: {text_style}")
        print(f"ğŸ  íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œ: {title_area_mode}")
        print(f"ğŸ”¤ íƒ€ì´í‹€ í°íŠ¸: {title_font} ({title_font_size}pt)")
        print(f"ğŸ“ ë³¸ë¬¸ í°íŠ¸: {body_font} ({body_font_size}pt)")
        print(f"ğŸ¤ ìë§‰ ì½ì–´ì£¼ê¸°: {voice_narration}")
        print(f"ğŸ¬ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ: {cross_dissolve}")
        print(f"â±ï¸ ìë§‰ ì§€ì† ì‹œê°„: {subtitle_duration}ì´ˆ (0=ìŒì„±ê¸¸ì´)")

        output_path = video_gen.create_video_from_uploads(
            OUTPUT_FOLDER,
            bgm_file,
            image_allocation_mode,
            text_position,
            text_style,
            title_area_mode,
            title_font,
            body_font,
            title_font_size,
            body_font_size,
            "uploads",
            music_mood,
            voice_narration,
            cross_dissolve,
            subtitle_duration
        )

        # ì˜ìƒ ìƒì„± ì„±ê³µ ì‹œ job í´ë” ì •ë¦¬
        if job_id and FOLDER_MANAGER_AVAILABLE:
            try:
                # Job í´ë” ì •ë¦¬ (output í´ë”ëŠ” ë³´ì¡´, uploads í´ë”ëŠ” ì •ë¦¬)
                cleaned = folder_manager.cleanup_job_folders(job_id, keep_output=True)
                if cleaned:
                    print(f"âœ… Job í´ë” ì •ë¦¬ ì™„ë£Œ: {job_id}")
                else:
                    print(f"âš ï¸ Job í´ë” ì •ë¦¬ ì‹¤íŒ¨: {job_id}")
            except Exception as cleanup_error:
                print(f"âš ï¸ Job í´ë” ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {cleanup_error}")

        # ê¸€ë¡œë²Œ ë³€ìˆ˜ ë³µì›
        if job_id and FOLDER_MANAGER_AVAILABLE:
            UPLOAD_FOLDER = original_upload_folder
            OUTPUT_FOLDER = original_output_folder

        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "message": "Video generated successfully",
                "video_path": output_path
            }
        )

    except Exception as e:
        # ì—ëŸ¬ ì‹œì—ë„ job í´ë” ì •ë¦¬ (uploads í´ë” ì •ë¦¬)
        if job_id and FOLDER_MANAGER_AVAILABLE:
            try:
                # ì—ëŸ¬ ì‹œì—ëŠ” ëª¨ë“  íŒŒì¼ ì •ë¦¬ (output í´ë”ë„ ì •ë¦¬)
                cleaned = folder_manager.cleanup_job_folders(job_id, keep_output=False)
                if cleaned:
                    print(f"ğŸ—‘ï¸ ì—ëŸ¬ ë°œìƒìœ¼ë¡œ Job í´ë” ì „ì²´ ì •ë¦¬: {job_id}")
                else:
                    print(f"âš ï¸ ì—ëŸ¬ ì‹œ Job í´ë” ì •ë¦¬ ì‹¤íŒ¨: {job_id}")
            except Exception as cleanup_error:
                print(f"âš ï¸ ì—ëŸ¬ ì‹œ Job í´ë” ì •ë¦¬ ì¤‘ ì¶”ê°€ ì˜¤ë¥˜: {cleanup_error}")

        # ê¸€ë¡œë²Œ ë³€ìˆ˜ ë³µì› (ì—ëŸ¬ ì‹œì—ë„)
        if job_id and FOLDER_MANAGER_AVAILABLE:
            UPLOAD_FOLDER = original_upload_folder
            OUTPUT_FOLDER = original_output_folder

        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": str(e)
            }
        )

class SingleImageRequest(BaseModel):
    text: Optional[str] = None
    custom_prompt: Optional[str] = None
    additional_context: Optional[str] = None
    job_id: Optional[str] = None  # Job ID ì¶”ê°€ (ì„ íƒì )

@app.post("/generate-single-image")
async def generate_single_image(request: SingleImageRequest):
    """ê°œë³„ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ì´ë¯¸ì§€ ìë™ ìƒì„± (ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì§€ì›)"""
    try:
        logger.info(f"ğŸ”¥ ê°œë³„ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ ì‹œì‘")
        logger.info(f"ğŸ“ ìš”ì²­ í…ìŠ¤íŠ¸: {request.text}")
        logger.info(f"ğŸ¨ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸: {request.custom_prompt}")
        logger.info(f"ğŸ“ ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸: {request.additional_context}")

        # ì…ë ¥ ìœ íš¨ì„± ê²€ì¦
        if not request.text and not request.custom_prompt:
            logger.error("âŒ í…ìŠ¤íŠ¸ ë˜ëŠ” ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")
            raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ ë˜ëŠ” ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì¤‘ í•˜ë‚˜ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤")

        if not OPENAI_AVAILABLE:
            logger.error("âŒ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ")
            raise HTTPException(status_code=500, detail="OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        # OpenAI API í‚¤ í™•ì¸
        OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')
        if not OPENAI_API_KEY:
            logger.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            raise HTTPException(status_code=500, detail="OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        logger.info("ğŸ”‘ OpenAI API í‚¤ í™•ì¸ ì™„ë£Œ")

        # ì´ë¯¸ì§€ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ì„ íƒ
        if request.custom_prompt and request.custom_prompt.strip():
            # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            image_prompt = request.custom_prompt.strip()
            logger.info(f"ğŸ¨ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©: {image_prompt[:200]}...")
        else:
            # ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
            image_prompt = create_image_generation_prompt(request.text, request.additional_context)
            logger.info(f"ğŸ¯ ê¸°ë³¸ í…ìŠ¤íŠ¸ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸: {image_prompt[:200]}...")
        
        # OpenAI DALL-Eë¥¼ í†µí•œ ì´ë¯¸ì§€ ìƒì„±
        client = OpenAI(api_key=OPENAI_API_KEY, timeout=30.0)
        logger.info("ğŸ¤– DALL-E API í˜¸ì¶œ ì‹œì‘...")
        
        try:
            response = client.images.generate(
                model="dall-e-3",
                prompt=image_prompt,
                size="1024x1024",
                quality="standard",
                n=1,
            )
            logger.info("âœ… DALL-E API í˜¸ì¶œ ì„±ê³µ")
        except Exception as dalle_error:
            logger.error(f"ğŸ’¥ DALL-E API í˜¸ì¶œ ì‹¤íŒ¨: {dalle_error}")
            # í”„ë¡¬í”„íŠ¸ ì•ˆì „í™” ì‹œë„
            if "safety system" in str(dalle_error) or "content_policy_violation" in str(dalle_error):
                logger.info("ğŸ›¡ï¸ ì•ˆì „ ì •ì±… ìœ„ë°˜ ê°ì§€ - í”„ë¡¬í”„íŠ¸ ì•ˆì „í™” ì‹œë„")

                if request.custom_prompt and request.custom_prompt.strip():
                    # ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ì˜ ê²½ìš° ê¸°ë³¸ ì•ˆì „í•œ í”„ë¡¬í”„íŠ¸ë¡œ ëŒ€ì²´
                    safe_prompt = "A peaceful and beautiful landscape with soft colors, professional photography style"
                    logger.info(f"ğŸ”’ ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ ì•ˆì „í™”: {safe_prompt}")
                else:
                    # ê¸°ì¡´ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì•ˆì „í™”
                    safe_prompt = create_safe_image_prompt(request.text, request.additional_context)
                    logger.info(f"ğŸ”’ í…ìŠ¤íŠ¸ ê¸°ë°˜ ì•ˆì „í™”: {safe_prompt[:200]}...")
                
                response = client.images.generate(
                    model="dall-e-3",
                    prompt=safe_prompt,
                    size="1024x1024",
                    quality="standard",
                    n=1,
                )
                logger.info("âœ… ì•ˆì „í™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì„±ê³µ")
            else:
                raise dalle_error
        
        image_url = response.data[0].url
        logger.info(f"ğŸŒ ì´ë¯¸ì§€ URL ìˆ˜ì‹ : {image_url}")
        
        # ìƒì„±ëœ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
        import requests
        from datetime import datetime
        
        logger.info("ğŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œì‘...")
        image_response = requests.get(image_url, timeout=30)
        image_response.raise_for_status()
        logger.info(f"ğŸ“¥ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ({len(image_response.content)} bytes)")
        
        # Job í´ë” ë˜ëŠ” ê¸°ë³¸ uploads í´ë”ì— ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"generated_single_{timestamp}_{uuid.uuid4().hex[:8]}.png"

        if request.job_id and FOLDER_MANAGER_AVAILABLE:
            # Job ê³ ìœ  í´ë”ì— ì €ì¥
            try:
                job_uploads_folder, _ = folder_manager.get_job_folders(request.job_id)
                os.makedirs(job_uploads_folder, exist_ok=True)
                local_path = os.path.join(job_uploads_folder, filename)

                with open(local_path, 'wb') as f:
                    f.write(image_response.content)

                logger.info(f"ğŸ’¾ ê°œë³„ ì´ë¯¸ì§€ job í´ë” ì €ì¥ ì™„ë£Œ: {filename}")
                logger.info(f"ğŸ“‚ Job ê²½ë¡œ: {local_path}")

                # job_idê°€ ìˆëŠ” ê²½ìš° jobë³„ URL ë°˜í™˜
                return {
                    "status": "success",
                    "message": "ì´ë¯¸ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
                    "image_url": f"/job-uploads/{request.job_id}/{filename}",
                    "local_path": local_path,
                    "job_id": request.job_id
                }

            except Exception as job_error:
                logger.warning(f"âš ï¸ Job í´ë” ì €ì¥ ì‹¤íŒ¨, ê¸°ë³¸ í´ë” ì‚¬ìš©: {job_error}")
                # Job í´ë” ì €ì¥ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í´ë”ë¡œ fallback

        # ê¸°ë³¸ uploads í´ë”ì— ì €ì¥ (Job ID ì—†ìŒ ë˜ëŠ” Job í´ë” ì €ì¥ ì‹¤íŒ¨)
        os.makedirs(UPLOAD_FOLDER, exist_ok=True)
        local_path = os.path.join(UPLOAD_FOLDER, filename)

        with open(local_path, 'wb') as f:
            f.write(image_response.content)

        logger.info(f"ğŸ’¾ ê°œë³„ ì´ë¯¸ì§€ ê¸°ë³¸ í´ë” ì €ì¥ ì™„ë£Œ: {filename}")
        logger.info(f"ğŸ“‚ ë¡œì»¬ ê²½ë¡œ: {local_path}")

        return {
            "status": "success",
            "message": "ì´ë¯¸ì§€ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤",
            "image_url": f"/uploads/{filename}",
            "local_path": local_path
        }
        
    except HTTPException:
        raise  # HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „íŒŒ
    except Exception as e:
        logger.error(f"ğŸ’¥ ê°œë³„ ì´ë¯¸ì§€ ìƒì„± ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
        logger.error(f"ğŸ” ì˜¤ë¥˜ íƒ€ì…: {type(e).__name__}")
        raise HTTPException(status_code=500, detail=f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {str(e)}")

def create_image_generation_prompt(text: str, additional_context: Optional[str] = None) -> str:
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    # ì‹¤ì‚¬í’ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    base_prompt = f"""
Create a photorealistic digital painting with soft, natural lighting and seamless blending based on this Korean text: "{text}"

The image should have:
- No visible outlines or hard edges between objects
- Natural shadows and highlights
- Realistic textures and materials
- Soft gradients and smooth color transitions
- Professional photography-like composition
- Warm, ambient lighting
- High detail and depth
- Suitable for vertical video format (9:16 aspect ratio content)
- Safe for all audiences
"""
    
    # ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ í¬í•¨
    if additional_context:
        base_prompt += f"\nAdditional context: \"{additional_context}\""
    
    base_prompt += """

Style: Digital painting, photorealistic, cinematic lighting, professional photography aesthetic
Quality: High resolution, sharp details, realistic depth of field
Mood: Natural, engaging, appropriate for social media
Avoid: Vector graphics, line art, cartoon style, bold outlines, flat colors, text, letters, words, typography, captions, labels, any written content
"""
    
    return base_prompt.strip()

def create_safe_image_prompt(text: str, additional_context: Optional[str] = None) -> str:
    """ì•ˆì „ ì •ì±… ìœ„ë°˜ì„ í”¼í•˜ê¸° ìœ„í•œ ì•ˆì „í™”ëœ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    
    # í­ë ¥ì /ìœ„í—˜í•œ í‘œí˜„ë“¤ì„ ì•ˆì „í•œ í‘œí˜„ìœ¼ë¡œ ëŒ€ì²´
    safe_text = text.replace("ë•Œë¦¬", "í„°ì¹˜").replace("ë•Œë¦°", "í„°ì¹˜").replace("í€ì¹˜", "ì›€ì§ì„")
    safe_text = safe_text.replace("íƒ€ê²©", "ì ‘ì´‰").replace("ê³µê²©", "ë™ì‘").replace("í­ë°œ", "ë°˜ì‘")
    safe_text = safe_text.replace("ì¶©ê²©", "ì—ë„ˆì§€").replace("íŒŒê´´", "ë³€í™”").replace("ê¹¨", "ë³€í˜•")
    
    if additional_context:
        safe_additional = additional_context.replace("ë•Œë¦¬", "í„°ì¹˜").replace("ë•Œë¦°", "í„°ì¹˜").replace("í€ì¹˜", "ì›€ì§ì„")
        safe_additional = safe_additional.replace("íƒ€ê²©", "ì ‘ì´‰").replace("ê³µê²©", "ë™ì‘").replace("í­ë°œ", "ë°˜ì‘")
    else:
        safe_additional = None
    
    # ë§¤ìš° ì•ˆì „í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    base_prompt = f"""
Create a peaceful, educational illustration about marine life and science based on this Korean text: "{safe_text}"

The image should be:
- Educational and informative
- Bright, colorful, and family-friendly
- Featuring marine creatures in their natural habitat
- Scientific and nature-focused
- Suitable for educational content
- Completely safe for all audiences

Focus on:
- Beautiful ocean scenes
- Colorful marine life
- Scientific concepts visualization
- Peaceful underwater environments
"""
    
    if safe_additional:
        base_prompt += f"\nAdditional educational context: \"{safe_additional}\""
    
    base_prompt += """

Style: Educational illustration, nature documentary style
Quality: High resolution, sharp details
Mood: Peaceful, educational, wonder and discovery
No violence, conflict, or aggressive themes
"""
    
    return base_prompt.strip()

@app.get("/uploads/{filename}")
async def serve_uploaded_file(filename: str):
    """ì—…ë¡œë“œëœ íŒŒì¼ ì œê³µ"""
    file_path = os.path.join(UPLOAD_FOLDER, filename)
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    return FileResponse(file_path)

@app.get("/job-uploads/{job_id}/{filename}")
async def serve_job_uploaded_file(job_id: str, filename: str):
    """Jobë³„ ì—…ë¡œë“œëœ íŒŒì¼ ì œê³µ"""
    try:
        if not FOLDER_MANAGER_AVAILABLE:
            raise HTTPException(status_code=500, detail="í´ë” ê´€ë¦¬ ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        # Job í´ë” ê²½ë¡œ ì¡°íšŒ
        job_uploads_folder, _ = folder_manager.get_job_folders(job_id)
        file_path = os.path.join(job_uploads_folder, filename)

        if not os.path.exists(file_path):
            logger.warning(f"ğŸ” Job íŒŒì¼ ì—†ìŒ: {file_path}")
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        logger.info(f"ğŸ“ Job íŒŒì¼ ì œê³µ: {job_id}/{filename}")
        return FileResponse(file_path)

    except Exception as e:
        logger.error(f"âŒ Job íŒŒì¼ ì œê³µ ì‹¤íŒ¨: {job_id}/{filename} - {e}")
        raise HTTPException(status_code=500, detail="íŒŒì¼ ì œê³µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

@app.get("/bgm-list")
async def get_bgm_list():
    """BGM í´ë” ëª©ë¡ ë° ê° í´ë”ì˜ íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        bgm_data = {}
        valid_moods = ["bright", "calm", "romantic", "sad", "suspense"]
        
        for mood in valid_moods:
            mood_folder = os.path.join(BGM_FOLDER, mood)
            files = []
            
            if os.path.exists(mood_folder):
                # ìŒì•… íŒŒì¼ë“¤ ê²€ìƒ‰
                music_patterns = ["*.mp3", "*.wav", "*.m4a"]
                for pattern in music_patterns:
                    found_files = glob.glob(os.path.join(mood_folder, pattern))
                    for file_path in found_files:
                        filename = os.path.basename(file_path)
                        # íŒŒì¼ëª…ì—ì„œ ì•„í‹°ìŠ¤íŠ¸ì™€ ì œëª© ë¶„ë¦¬
                        display_name = filename.replace('.mp3', '').replace('.wav', '').replace('.m4a', '')
                        if ' - ' in display_name:
                            parts = display_name.split(' - ')
                            display_name = parts[0] if len(parts) > 1 else display_name
                        
                        files.append({
                            "filename": filename,
                            "displayName": display_name,
                            "mood": mood,
                            "url": f"/bgm/{mood}/{filename}"
                        })
            
            bgm_data[mood] = {
                "mood": mood,
                "displayName": {
                    "bright": "ë°ì€ ìŒì•…",
                    "calm": "ì°¨ë¶„í•œ ìŒì•…", 
                    "romantic": "ë¡œë§¨í‹±í•œ ìŒì•…",
                    "sad": "ìŠ¬í”ˆ ìŒì•…",
                    "suspense": "ê¸´ì¥ê° ìˆëŠ” ìŒì•…"
                }.get(mood, mood),
                "files": files
            }
        
        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "data": bgm_data
            }
        )
    
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": str(e)
            }
        )

@app.get("/bgm/{mood}")
async def get_bgm_by_mood(mood: str):
    """íŠ¹ì • ì„±ê²©ì˜ BGM íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        if mood not in ["bright", "calm", "romantic", "sad", "suspense"]:
            return JSONResponse(
                status_code=400,
                content={
                    "status": "error",
                    "message": "Invalid mood. Available moods: bright, calm, romantic, sad, suspense"
                }
            )
        
        mood_folder = os.path.join(BGM_FOLDER, mood)
        files = []
        
        if os.path.exists(mood_folder):
            music_patterns = ["*.mp3", "*.wav", "*.m4a"]
            for pattern in music_patterns:
                found_files = glob.glob(os.path.join(mood_folder, pattern))
                for file_path in found_files:
                    filename = os.path.basename(file_path)
                    display_name = filename.replace('.mp3', '').replace('.wav', '').replace('.m4a', '')
                    if ' - ' in display_name:
                        parts = display_name.split(' - ')
                        display_name = parts[0] if len(parts) > 1 else display_name
                    
                    files.append({
                        "filename": filename,
                        "displayName": display_name,
                        "mood": mood,
                        "url": f"/bgm/{mood}/{filename}"
                    })
        
        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "data": files
            }
        )
    
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": str(e)
            }
        )

@app.get("/font-list")
async def get_font_list():
    """font í´ë”ì˜ í°íŠ¸ íŒŒì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        font_folder = os.path.join(os.path.dirname(__file__), "font")
        fonts = []

        if os.path.exists(font_folder):
            # í°íŠ¸ íŒŒì¼ í™•ì¥ì
            font_patterns = ["*.ttf", "*.otf", "*.woff", "*.woff2"]
            for pattern in font_patterns:
                found_files = glob.glob(os.path.join(font_folder, pattern))
                for file_path in found_files:
                    filename = os.path.basename(file_path)
                    # í™•ì¥ì ì œê±°í•œ í‘œì‹œ ì´ë¦„
                    display_name = os.path.splitext(filename)[0]

                    # íŒŒì¼ í¬ê¸° ì •ë³´
                    file_size = os.path.getsize(file_path)
                    file_size_mb = round(file_size / (1024 * 1024), 2)

                    fonts.append({
                        "filename": filename,
                        "display_name": display_name,
                        "file_path": filename,  # ìƒëŒ€ ê²½ë¡œ
                        "size_mb": file_size_mb,
                        "extension": os.path.splitext(filename)[1].lower()
                    })

        # íŒŒì¼ëª… ìˆœìœ¼ë¡œ ì •ë ¬
        fonts.sort(key=lambda x: x['display_name'])

        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "message": f"{len(fonts)}ê°œì˜ í°íŠ¸ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤",
                "data": fonts
            }
        )

    except Exception as e:
        logger.error(f"í°íŠ¸ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": str(e)
            }
        )

@app.get("/bookmark-videos")
async def get_bookmark_videos():
    """ë¶ë§ˆí¬ ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ (ìµœê·¼ ë“±ë¡ìˆœ, ì¸ë„¤ì¼ í¬í•¨)"""
    try:
        videos = []

        if os.path.exists(BOOKMARK_VIDEOS_FOLDER):
            # ì¸ë„¤ì¼ ìë™ ìƒì„± (ëˆ„ë½ëœ ì¸ë„¤ì¼ë§Œ)
            if THUMBNAIL_GENERATOR_AVAILABLE:
                try:
                    logger.info("ğŸ¬ ì¸ë„¤ì¼ ìƒì„± ì‹œì‘...")
                    result = generate_missing_thumbnails(BOOKMARK_VIDEOS_FOLDER)
                    logger.info(f"âœ… ì¸ë„¤ì¼ ìƒì„± ì™„ë£Œ: ìƒˆë¡œ ìƒì„± {result['generated']}ê°œ, ê¸°ì¡´ {result['skipped']}ê°œ, ì‹¤íŒ¨ {result['errors']}ê°œ")
                except Exception as thumbnail_error:
                    logger.warning(f"âš ï¸ ì¸ë„¤ì¼ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ê³„ì† ì§„í–‰): {thumbnail_error}")
            else:
                logger.warning("âš ï¸ ì¸ë„¤ì¼ ìƒì„±ê¸°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            # mp4 íŒŒì¼ë“¤ë§Œ ê²€ìƒ‰
            video_files = glob.glob(os.path.join(BOOKMARK_VIDEOS_FOLDER, "*.mp4"))

            for video_path in video_files:
                filename = os.path.basename(video_path)

                # íŒŒì¼ ì •ë³´
                file_stat = os.stat(video_path)
                file_size = file_stat.st_size
                file_size_mb = round(file_size / (1024 * 1024), 2)
                modified_time = file_stat.st_mtime

                # ì¸ë„¤ì¼ ì´ë¯¸ì§€ ì°¾ê¸° (ê°™ì€ ì´ë¦„ì˜ .jpg íŒŒì¼)
                thumbnail_name = filename.replace('.mp4', '.jpg')
                thumbnail_path = os.path.join(BOOKMARK_VIDEOS_FOLDER, thumbnail_name)
                has_thumbnail = os.path.exists(thumbnail_path)

                videos.append({
                    "filename": filename,
                    "display_name": filename.replace('.mp4', ''),
                    "size_mb": file_size_mb,
                    "modified_time": modified_time,
                    "video_url": f"/bookmark-videos/{filename}",
                    "thumbnail_url": f"/bookmark-videos/{thumbnail_name}" if has_thumbnail else None,
                    "has_thumbnail": has_thumbnail
                })

        # ìµœê·¼ ë“±ë¡ìˆœìœ¼ë¡œ ì •ë ¬ (modified_time ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ)
        videos.sort(key=lambda x: x['modified_time'], reverse=True)

        logger.info(f"âœ… ë¶ë§ˆí¬ ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ ì™„ë£Œ: {len(videos)}ê°œ")

        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "message": f"{len(videos)}ê°œì˜ ë¶ë§ˆí¬ ë¹„ë””ì˜¤ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤",
                "data": videos
            }
        )

    except Exception as e:
        logger.error(f"âŒ ë¶ë§ˆí¬ ë¹„ë””ì˜¤ ëª©ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": str(e)
            }
        )

@app.get("/bookmark-videos/{filename}")
async def serve_bookmark_video(filename: str):
    """ë¶ë§ˆí¬ ë¹„ë””ì˜¤ ë˜ëŠ” ì¸ë„¤ì¼ íŒŒì¼ ì œê³µ"""
    try:
        file_path = os.path.join(BOOKMARK_VIDEOS_FOLDER, filename)

        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # íŒŒì¼ í™•ì¥ìì— ë”°ë¼ ì ì ˆí•œ ë¯¸ë””ì–´ íƒ€ì… ë°˜í™˜
        if filename.endswith('.mp4'):
            media_type = "video/mp4"
        elif filename.endswith('.jpg') or filename.endswith('.jpeg'):
            media_type = "image/jpeg"
        else:
            media_type = "application/octet-stream"

        return FileResponse(
            path=file_path,
            media_type=media_type,
            filename=filename
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ë¶ë§ˆí¬ íŒŒì¼ ì œê³µ ì‹¤íŒ¨: {filename} - {e}")
        raise HTTPException(status_code=500, detail="íŒŒì¼ ì œê³µ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤")

class CopyBookmarkVideoRequest(BaseModel):
    job_id: str
    video_filename: str
    image_index: int

@app.post("/copy-bookmark-video")
async def copy_bookmark_video(request: CopyBookmarkVideoRequest):
    """ë¶ë§ˆí¬ ë¹„ë””ì˜¤ë¥¼ Job í´ë”ë¡œ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©"""
    try:
        logger.info(f"ğŸ¬ ë¶ë§ˆí¬ ë¹„ë””ì˜¤ ë³µì‚¬ ìš”ì²­: job_id={request.job_id}, video={request.video_filename}, index={request.image_index}")

        # 1. ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ í™•ì¸
        source_video_path = os.path.join(BOOKMARK_VIDEOS_FOLDER, request.video_filename)

        if not os.path.exists(source_video_path):
            raise HTTPException(status_code=404, detail=f"ë¶ë§ˆí¬ ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {request.video_filename}")

        # 2. Job í´ë” í™•ì¸ (ì—†ìœ¼ë©´ ìƒì„±)
        if FOLDER_MANAGER_AVAILABLE:
            job_uploads_folder, job_output_folder = folder_manager.get_job_folders(request.job_id)
            if not os.path.exists(job_uploads_folder):
                job_uploads_folder, job_output_folder = folder_manager.create_job_folders(request.job_id)
                logger.info(f"ğŸ“ Job í´ë” ìƒì„±: {job_uploads_folder}")
            uploads_folder = job_uploads_folder
        else:
            # Fallback: ê¸°ë³¸ uploads í´ë” ì‚¬ìš©
            uploads_folder = UPLOAD_FOLDER
            os.makedirs(uploads_folder, exist_ok=True)

        # 3. ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ ì„¤ì • (image_index ì‚¬ìš©)
        file_extension = os.path.splitext(request.video_filename)[1]
        dest_filename = f"{request.image_index + 1}{file_extension}"
        dest_video_path = os.path.join(uploads_folder, dest_filename)

        # 4. ë¹„ë””ì˜¤ íŒŒì¼ ë³µì‚¬
        shutil.copy2(source_video_path, dest_video_path)
        logger.info(f"âœ… ë¹„ë””ì˜¤ íŒŒì¼ ë³µì‚¬ ì™„ë£Œ: {source_video_path} â†’ {dest_video_path}")

        # 5. íŒŒì¼ URL ë°˜í™˜
        if FOLDER_MANAGER_AVAILABLE:
            file_url = f"/job-uploads/{request.job_id}/{dest_filename}"
        else:
            file_url = f"/uploads/{dest_filename}"

        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "message": "ë¶ë§ˆí¬ ë¹„ë””ì˜¤ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë³µì‚¬í–ˆìŠµë‹ˆë‹¤",
                "data": {
                    "filename": dest_filename,
                    "file_url": file_url,
                    "image_index": request.image_index
                }
            }
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ë¶ë§ˆí¬ ë¹„ë””ì˜¤ ë³µì‚¬ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ë¹„ë””ì˜¤ ë³µì‚¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/preview-video")
async def preview_video(
    title: str = Form(...),
    body1: str = Form(...),
    text_position: str = Form(default="bottom"),
    text_style: str = Form(default="outline"),
    title_area_mode: str = Form(default="keep"),
    title_font: str = Form(default="BMYEONSUNG_otf.otf"),
    body_font: str = Form(default="BMYEONSUNG_otf.otf"),
    title_font_size: int = Form(default=42),
    body_font_size: int = Form(default=36),
    image_1: Optional[UploadFile] = File(None),
    job_id: Optional[str] = Form(None),  # Job ID ì¶”ê°€
):
    """ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ìƒì„±"""
    try:
        logger.info(f"ë¯¸ë¦¬ë³´ê¸° ìš”ì²­: {title[:20]}...")

        # VideoGenerator ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        video_generator = VideoGenerator()

        # ì—…ë¡œë“œ í´ë” ì„¤ì • (Job IDì— ë”°ë¼ ë¶„ê¸°)
        if job_id and FOLDER_MANAGER_AVAILABLE:
            try:
                job_uploads_folder, _ = folder_manager.get_job_folders(job_id)
                uploads_folder = job_uploads_folder
                os.makedirs(uploads_folder, exist_ok=True)
                logger.info(f"ğŸ—‚ï¸ Job ê³ ìœ  í´ë” ì‚¬ìš© (í”„ë¦¬ë·°): {uploads_folder}")
            except Exception as job_error:
                logger.warning(f"âš ï¸ Job í´ë” ì‚¬ìš© ì‹¤íŒ¨, ê¸°ë³¸ í´ë” ì‚¬ìš© (í”„ë¦¬ë·°): {job_error}")
                uploads_folder = os.path.join(os.path.dirname(__file__), "uploads")
                os.makedirs(uploads_folder, exist_ok=True)
        else:
            uploads_folder = os.path.join(os.path.dirname(__file__), "uploads")
            os.makedirs(uploads_folder, exist_ok=True)

        # ì´ë¯¸ì§€/ë¹„ë””ì˜¤ íŒŒì¼ ì²˜ë¦¬
        preview_image_path = None
        if image_1 and hasattr(image_1, 'filename') and image_1.filename:
            # ì—…ë¡œë“œëœ íŒŒì¼ ì €ì¥
            image_filename = f"preview_{int(time.time())}_{image_1.filename}"
            image_save_path = os.path.join(uploads_folder, image_filename)

            with open(image_save_path, "wb") as buffer:
                shutil.copyfileobj(image_1.file, buffer)

            # ë¹„ë””ì˜¤ íŒŒì¼ì¸ì§€ í™•ì¸
            video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
            is_video = any(image_1.filename.lower().endswith(ext) for ext in video_extensions)
            
            if is_video:
                # ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ì²« ë²ˆì§¸ í”„ë ˆì„ ì¶”ì¶œ
                try:
                    from moviepy.editor import VideoFileClip
                    import tempfile
                    
                    # ë¹„ë””ì˜¤ì—ì„œ ì²« ë²ˆì§¸ í”„ë ˆì„ ì¶”ì¶œ
                    video_clip = VideoFileClip(image_save_path)
                    frame = video_clip.get_frame(0)  # ì²« ë²ˆì§¸ í”„ë ˆì„ (t=0)
                    video_clip.close()
                    
                    # í”„ë ˆì„ì„ ì´ë¯¸ì§€ë¡œ ì €ì¥
                    from PIL import Image
                    frame_image = Image.fromarray(frame)
                    
                    # ë¹„ë””ì˜¤ íŒŒì¼ëª…ì„ ì´ë¯¸ì§€ íŒŒì¼ëª…ìœ¼ë¡œ ë³€ê²½
                    frame_filename = f"preview_{int(time.time())}_frame.png"
                    frame_save_path = os.path.join(uploads_folder, frame_filename)
                    frame_image.save(frame_save_path, "PNG")
                    
                    # ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ ì‚­ì œ
                    os.unlink(image_save_path)
                    preview_image_path = frame_save_path
                    
                    logger.info(f"ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ: {frame_filename}")
                    
                except Exception as e:
                    logger.warning(f"ë¹„ë””ì˜¤ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}, ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©")
                    # ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ì›ë³¸ íŒŒì¼ ì‚­ì œí•˜ê³  ê¸°ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©
                    try:
                        os.unlink(image_save_path)
                    except:
                        pass
                    preview_image_path = None
            else:
                # ì´ë¯¸ì§€ íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                preview_image_path = image_save_path
        else:
            # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì‚¬ìš©
            test_folder = os.path.join(os.path.dirname(__file__), "test")
            test_images = []
            for ext in ["jpg", "jpeg", "png", "webp", "gif", "bmp"]:
                test_files = glob.glob(os.path.join(test_folder, f"1.{ext}"))
                test_images.extend(test_files)

            if test_images:
                preview_image_path = test_images[0]

        if not preview_image_path or not os.path.exists(preview_image_path):
            raise HTTPException(status_code=400, detail="ë¯¸ë¦¬ë³´ê¸°ìš© ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # PILë¡œ ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ í•©ì„±
        from PIL import Image

        # ë°°ê²½ ì´ë¯¸ì§€ (504x890)
        final_image = Image.new('RGB', (504, 890), color=(0, 0, 0))

        title_image_path = None

        if title_area_mode == "keep":
            # ê¸°ì¡´ ë°©ì‹: íƒ€ì´í‹€ ì˜ì—­ + ë¯¸ë””ì–´ ì˜ì—­
            # íƒ€ì´í‹€ ì´ë¯¸ì§€ ìƒì„± (504x220)
            title_image_path = video_generator.create_title_image(
                title,
                504,
                220,
                title_font,
                title_font_size
            )

            # ë°°ê²½ ì´ë¯¸ì§€ ì²˜ë¦¬ (670px ì˜ì—­)
            if os.path.exists(preview_image_path):
                bg_image = Image.open(preview_image_path)
                work_area_height = 670  # 890 - 220
                bg_image = bg_image.resize((504, work_area_height), Image.Resampling.LANCZOS)
                final_image.paste(bg_image, (0, 220))  # íƒ€ì´í‹€ ì•„ë˜ì— ë°°ì¹˜

            # íƒ€ì´í‹€ ì´ë¯¸ì§€ í•©ì„± (ìƒë‹¨)
            if os.path.exists(title_image_path):
                title_img = Image.open(title_image_path)
                final_image.paste(title_img, (0, 0))
        else:
            # remove ëª¨ë“œ: ì „ì²´ í™”ë©´ ë¯¸ë””ì–´
            # ë°°ê²½ ì´ë¯¸ì§€ ì²˜ë¦¬ (ì „ì²´ 890px)
            if os.path.exists(preview_image_path):
                bg_image = Image.open(preview_image_path)
                bg_image = bg_image.resize((504, 890), Image.Resampling.LANCZOS)
                final_image.paste(bg_image, (0, 0))  # ì „ì²´ í™”ë©´

        # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (504x890) - ëª¨ë“  ëª¨ë“œ ê³µí†µ
        body_text_image_path = video_generator.create_text_image(
            body1,
            504,
            890,
            text_position,
            text_style,
            is_title=False,
            title_font=title_font,
            body_font=body_font,
            title_area_mode=title_area_mode,
            title_font_size=title_font_size,
            body_font_size=body_font_size
        )

        # ë³¸ë¬¸ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ í•©ì„± (ì˜¤ë²„ë ˆì´)
        if os.path.exists(body_text_image_path):
            body_img = Image.open(body_text_image_path).convert('RGBA')
            final_image.paste(body_img, (0, 0), body_img)

        # ë¯¸ë¦¬ë³´ê¸° ì´ë¯¸ì§€ ì €ì¥
        preview_filename = f"preview_{int(time.time())}.png"
        preview_save_path = os.path.join(uploads_folder, preview_filename)
        final_image.save(preview_save_path, "PNG")

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for temp_file in [title_image_path, body_text_image_path]:
            if temp_file and os.path.exists(temp_file):
                try:
                    os.unlink(temp_file)
                except:
                    pass

        logger.info(f"ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì™„ë£Œ: {preview_filename}")

        # Job IDì— ë”°ë¼ URL ê²½ë¡œ ì„¤ì •
        if job_id and FOLDER_MANAGER_AVAILABLE:
            preview_url = f"/job-uploads/{job_id}/{preview_filename}"
        else:
            preview_url = f"/uploads/{preview_filename}"

        return JSONResponse(
            status_code=200,
            content={
                "status": "success",
                "message": "ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì„±ê³µ",
                "preview_url": preview_url,
                "preview_path": preview_save_path
            }
        )

    except Exception as e:
        logger.error(f"ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "status": "error",
                "message": f"ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì‹¤íŒ¨: {str(e)}"
            }
        )

def extract_youtube_video_id(url: str) -> str:
    """YouTube URLì—ì„œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ"""
    # YouTube URL íŒ¨í„´ë“¤
    youtube_patterns = [
        r'(?:youtube\.com\/watch\?v=|youtu\.be\/|youtube\.com\/embed\/)([^&\n?#]+)',
        r'youtube\.com.*[?&]v=([^&\n?#]+)',
    ]
    
    for pattern in youtube_patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    return None

def is_youtube_url(url: str) -> bool:
    """YouTube URL ì—¬ë¶€ í™•ì¸"""
    youtube_domains = ['youtube.com', 'youtu.be', 'www.youtube.com', 'm.youtube.com']
    try:
        parsed_url = urlparse(url)
        return parsed_url.netloc.lower() in youtube_domains
    except:
        return False

def get_youtube_transcript(video_id: str) -> str:
    """YouTube ë¹„ë””ì˜¤ì˜ ìŠ¤í¬ë¦½íŠ¸(ìë§‰) ê°€ì ¸ì˜¤ê¸°"""
    
    # ë¼ì´ë¸ŒëŸ¬ë¦¬ ê°€ìš©ì„± í™•ì¸
    if not YOUTUBE_TRANSCRIPT_AVAILABLE:
        raise ValueError("YouTube transcript APIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ì— youtube-transcript-api ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
    
    try:
        # í•œêµ­ì–´ ìë§‰ì„ ìš°ì„ ì ìœ¼ë¡œ ì‹œë„, ì—†ìœ¼ë©´ ì˜ì–´, ê·¸ ë‹¤ìŒ ìë™ìƒì„± ìë§‰
        languages = ['ko', 'en', 'ko-KR', 'en-US']
        
        for lang in languages:
            try:
                logger.info(f"YouTube ìŠ¤í¬ë¦½íŠ¸ ì‹œë„ ì–¸ì–´: {lang}")
                transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=[lang])
                
                # ìŠ¤í¬ë¦½íŠ¸ë¥¼ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ë¡œ í•©ì¹˜ê¸°
                full_text = ' '.join([item['text'] for item in transcript_list])
                logger.info(f"YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì„±ê³µ ({lang}): {len(full_text)}ì")
                return full_text
                
            except Exception as e:
                logger.warning(f"ì–¸ì–´ {lang} ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                continue
        
        # ëª¨ë“  ì–¸ì–´ ì‹œë„ ì‹¤íŒ¨ ì‹œ, ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ ì–¸ì–´ í™•ì¸
        try:
            logger.info("ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ ì–¸ì–´ í™•ì¸ ì¤‘...")
            transcript_list = YouTubeTranscriptApi.list_transcripts(video_id)
            available_languages = []
            
            for transcript in transcript_list:
                available_languages.append(f"{transcript.language} ({transcript.language_code})")
                
            if available_languages:
                logger.info(f"ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ ì–¸ì–´: {', '.join(available_languages)}")
                
                # ì‚¬ìš© ê°€ëŠ¥í•œ ìë§‰ìœ¼ë¡œ ë‹¤ì–‘í•œ ë°©ë²• ì‹œë„
                for transcript in transcript_list:
                    # ë°©ë²• 1: ê¸°ë³¸ fetch ì‹œë„
                    try:
                        logger.info(f"ì–¸ì–´ {transcript.language_code} ({transcript.language})ë¡œ ìë§‰ ì¶”ì¶œ ì‹œë„...")
                        transcript_data = transcript.fetch()
                        
                        # ìë§‰ ë°ì´í„°ê°€ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸
                        if not transcript_data:
                            logger.warning(f"ì–¸ì–´ {transcript.language} ìë§‰ì´ ë¹„ì–´ìˆìŒ")
                            continue
                            
                        full_text = ' '.join([item['text'] for item in transcript_data if item.get('text', '').strip()])
                        
                        # ì‹¤ì œ í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
                        if not full_text.strip():
                            logger.warning(f"ì–¸ì–´ {transcript.language} ìë§‰ì— í…ìŠ¤íŠ¸ ë‚´ìš©ì´ ì—†ìŒ")
                            continue
                            
                        logger.info(f"YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì„±ê³µ ({transcript.language}): {len(full_text)}ì")
                        return full_text
                        
                    except Exception as transcript_error:
                        error_msg = str(transcript_error)
                        if "no element found" in error_msg.lower():
                            logger.info(f"ì–¸ì–´ {transcript.language} ì²« ë²ˆì§¸ ì‹œë„ ì‹¤íŒ¨ (XML íŒŒì‹± ì—ëŸ¬), ì¬ì‹œë„...")
                            
                            # ë°©ë²• 2: ì ì‹œ ëŒ€ê¸° í›„ ì¬ì‹œë„
                            try:
                                import time
                                time.sleep(1)  # 1ì´ˆ ëŒ€ê¸°
                                logger.info(f"ì–¸ì–´ {transcript.language_code} ì¬ì‹œë„ ì¤‘...")
                                transcript_data = transcript.fetch()
                                
                                if transcript_data:
                                    full_text = ' '.join([item['text'] for item in transcript_data if item.get('text', '').strip()])
                                    if full_text.strip():
                                        logger.info(f"YouTube ìŠ¤í¬ë¦½íŠ¸ ì¬ì‹œë„ ì„±ê³µ ({transcript.language}): {len(full_text)}ì")
                                        return full_text
                                
                                logger.warning(f"ì–¸ì–´ {transcript.language} ì¬ì‹œë„ë„ ë¹„ì–´ìˆìŒ")
                                
                            except Exception as retry_error:
                                logger.warning(f"ì–¸ì–´ {transcript.language} ì¬ì‹œë„ ì‹¤íŒ¨: {retry_error}")
                        else:
                            logger.warning(f"ì–¸ì–´ {transcript.language} ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {transcript_error}")
                        continue
                        
                # ìë§‰ì´ ìˆë‹¤ê³  í‘œì‹œë˜ì§€ë§Œ ëª¨ë‘ ë¹„ì–´ìˆëŠ” ê²½ìš°
                logger.error(f"ëª¨ë“  ìë§‰ì´ ë¹„ì–´ìˆê±°ë‚˜ ì ‘ê·¼ ë¶ˆê°€: {', '.join(available_languages)}")
                raise ValueError("ì´ YouTube ë¹„ë””ì˜¤ëŠ” ìë§‰ì´ í‘œì‹œë˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ë¹„ë””ì˜¤ë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                raise ValueError("ì´ YouTube ë¹„ë””ì˜¤ì—ëŠ” ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            logger.error(f"ìë§‰ í™•ì¸ ì‹¤íŒ¨: {e}")
            
            # ë” êµ¬ì²´ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€ ì œê³µ
            if "TranscriptsDisabled" in str(e):
                raise ValueError("ì´ YouTube ë¹„ë””ì˜¤ëŠ” ìë§‰ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            elif "VideoUnavailable" in str(e):
                raise ValueError("YouTube ë¹„ë””ì˜¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            elif "TooManyRequests" in str(e):
                raise ValueError("YouTube API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            elif "No transcripts were found" in str(e):
                raise ValueError("ì´ YouTube ë¹„ë””ì˜¤ì—ëŠ” ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤. ìë§‰ì´ ìˆëŠ” ë‹¤ë¥¸ ë¹„ë””ì˜¤ë¥¼ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                raise ValueError(f"YouTube ë¹„ë””ì˜¤ì˜ ìë§‰ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
            
    except Exception as e:
        logger.error(f"YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        raise ValueError(f"YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

def scrape_website_content(url: str) -> str:
    """ì›¹ì‚¬ì´íŠ¸ì—ì„œ í…ìŠ¤íŠ¸ ë‚´ìš©ì„ ìŠ¤í¬ë˜í•‘"""
    try:
        logger.info(f"ì›¹í˜ì´ì§€ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {url}")

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ì¸ì§€ í™•ì¸
        if 'blog.naver.com' in url:
            return scrape_naver_blog(url)
        else:
            return scrape_general_website(url)

    except Exception as e:
        logger.error(f"ìŠ¤í¬ë˜í•‘ ì˜¤ë¥˜: {e}")
        raise ValueError(f"ì›¹í˜ì´ì§€ ë‚´ìš©ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

def scrape_naver_blog(url: str) -> str:
    """ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì „ìš© ìŠ¤í¬ë˜í•‘ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    import time

    max_retries = 3
    retry_delay = 2.0  # 2ì´ˆ ê°„ê²©

    for attempt in range(max_retries):
        try:
            logger.info(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘ ì‹œë„ {attempt + 1}/{max_retries}: {url}")

            # ì„¸ì…˜ ìƒì„± ë° ì´ˆê¸°í™”
            session = requests.Session()

            # ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì „ìš© í—¤ë” (ë” ìƒì„¸í•˜ê²Œ)
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
                'Accept-Language': 'ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7',
                'Accept-Encoding': 'gzip, deflate, br',
                'Referer': 'https://www.naver.com/',
                'Connection': 'keep-alive',
                'Upgrade-Insecure-Requests': '1',
                'Sec-Fetch-Dest': 'document',
                'Sec-Fetch-Mode': 'navigate',
                'Sec-Fetch-Site': 'cross-site',
                'Sec-Fetch-User': '?1',
                'Cache-Control': 'max-age=0',
                'DNT': '1'
            }

            # ë¨¼ì € ë„¤ì´ë²„ ë©”ì¸ í˜ì´ì§€ ë°©ë¬¸ (ì¿ í‚¤ ë° ì„¸ì…˜ ì„¤ì •)
            try:
                time.sleep(0.5)  # ì§§ì€ ë”œë ˆì´
                session.get('https://www.naver.com/', headers=headers, timeout=8)
                logger.info("ë„¤ì´ë²„ ë©”ì¸ í˜ì´ì§€ ë°©ë¬¸ ì™„ë£Œ")

                # ë¸”ë¡œê·¸ ë©”ì¸ í˜ì´ì§€ë„ ë°©ë¬¸
                time.sleep(0.5)
                headers['Referer'] = 'https://www.naver.com/'
                session.get('https://blog.naver.com/', headers=headers, timeout=8)
                logger.info("ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë©”ì¸ í˜ì´ì§€ ë°©ë¬¸ ì™„ë£Œ")
            except Exception as e:
                logger.warning(f"ë„¤ì´ë²„ ì„ í–‰ ë°©ë¬¸ ì‹¤íŒ¨: {e}")

            # ì‹¤ì œ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ìš”ì²­
            time.sleep(1.0)  # ìš”ì²­ ì „ 1ì´ˆ ëŒ€ê¸°
            headers['Referer'] = 'https://blog.naver.com/'
            response = session.get(url, headers=headers, timeout=20)

            # ìƒíƒœ ì½”ë“œ ì²´í¬
            if response.status_code == 403:
                logger.warning(f"ì ‘ê·¼ ì°¨ë‹¨ (403) - ì‹œë„ {attempt + 1}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay * (attempt + 1))  # ì ì§„ì  ì¦ê°€
                    continue
                else:
                    raise requests.exceptions.RequestException(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì ‘ê·¼ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤ (403)")

            elif response.status_code == 400:
                logger.warning(f"ì˜ëª»ëœ ìš”ì²­ (400) - ì‹œë„ {attempt + 1}")
                if attempt < max_retries - 1:
                    time.sleep(retry_delay * (attempt + 1))
                    continue
                else:
                    raise requests.exceptions.RequestException(f"ì˜ëª»ëœ ìš”ì²­ì…ë‹ˆë‹¤. URLì„ í™•ì¸í•´ì£¼ì„¸ìš” (400)")

            response.raise_for_status()
            logger.info(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìš”ì²­ ì„±ê³µ: {response.status_code}")
            break  # ì„±ê³µì‹œ ë£¨í”„ ì¢…ë£Œ

        except requests.exceptions.Timeout as e:
            logger.warning(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ íƒ€ì„ì•„ì›ƒ - ì‹œë„ {attempt + 1}: {e}")
            if attempt < max_retries - 1:
                time.sleep(retry_delay)
                continue
            else:
                raise ValueError(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì‘ë‹µ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

        except requests.exceptions.RequestException as e:
            logger.warning(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ ìš”ì²­ ì‹¤íŒ¨ - ì‹œë„ {attempt + 1}: {e}")
            if attempt < max_retries - 1:
                time.sleep(retry_delay * (attempt + 1))
                continue
            else:
                raise ValueError(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

    # ì—¬ê¸°ê¹Œì§€ ì˜¤ë©´ responseê°€ ì„±ê³µì ìœ¼ë¡œ ë°›ì•„ì§„ ìƒíƒœ
    try:
        # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
        soup = BeautifulSoup(response.content, 'html.parser')

        # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
        for script in soup(["script", "style", "nav", "header", "footer", "aside", "form", "button", "iframe"]):
            script.decompose()

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì „ìš© ì½˜í…ì¸  ì…€ë ‰í„°
        naver_selectors = [
            '.se-main-container',           # ìŠ¤ë§ˆíŠ¸ì—ë””í„° 3.0 ë©”ì¸ ì»¨í…Œì´ë„ˆ
            '.post-view',                   # êµ¬ ì—ë””í„° í¬ìŠ¤íŠ¸ ë·°
            '#postViewArea',                # í¬ìŠ¤íŠ¸ ë·° ì˜ì—­
            '.se-component-content',        # ìŠ¤ë§ˆíŠ¸ì—ë””í„° ì½˜í…ì¸ 
            '.post_ct',                     # í¬ìŠ¤íŠ¸ ë‚´ìš©
            '.se-text-paragraph',           # ìŠ¤ë§ˆíŠ¸ì—ë””í„° í…ìŠ¤íŠ¸ ë‹¨ë½
            '.blog-post-content',           # ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸ ì½˜í…ì¸ 
            '.post_body',                   # í¬ìŠ¤íŠ¸ ë³¸ë¬¸
            '.se-section-text',             # ìŠ¤ë§ˆíŠ¸ì—ë””í„° í…ìŠ¤íŠ¸ ì„¹ì…˜
        ]

        text_content = ""

        # ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì „ìš© ì…€ë ‰í„°ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        for selector in naver_selectors:
            elements = soup.select(selector)
            if elements:
                logger.info(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ ì½˜í…ì¸  ë°œê²¬: {selector}")
                for element in elements:
                    text = element.get_text(strip=True, separator=' ')
                    if text and len(text) > 50:  # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ
                        text_content += text + " "
                if text_content:
                    break

        # ë„¤ì´ë²„ ì „ìš© ì…€ë ‰í„°ë¡œ ì°¾ì§€ ëª»í•œ ê²½ìš° ì¼ë°˜ì ì¸ ë°©ë²• ì‹œë„
        if not text_content:
            logger.warning("ë„¤ì´ë²„ ì „ìš© ì…€ë ‰í„°ë¡œ ì½˜í…ì¸ ë¥¼ ì°¾ì§€ ëª»í•¨, ì¼ë°˜ ë°©ë²• ì‹œë„")
            body = soup.find('body')
            if body:
                text_content = body.get_text(strip=True, separator=' ')

        return process_extracted_text(text_content, url)

    except Exception as e:
        logger.error(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
        raise ValueError(f"ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë‚´ìš©ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

def scrape_general_website(url: str) -> str:
    """ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í•‘"""
    try:
        # ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸ìš© í—¤ë” (ê¸°ì¡´ ë°©ì‹ ê°œì„ )
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1'
        }

        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        
        # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±°
        for script in soup(["script", "style", "nav", "header", "footer", "aside", "form", "button"]):
            script.decompose()
        
        # í…ìŠ¤íŠ¸ ì¶”ì¶œ - ì£¼ìš” ì½˜í…ì¸  ì˜ì—­ ìš°ì„ 
        content_selectors = [
            'article', 'main', '.content', '.article', '.post', 
            '.entry-content', '.post-content', '.article-content',
            'div[role="main"]', '.main-content'
        ]
        
        text_content = ""
        
        # ì£¼ìš” ì½˜í…ì¸  ì˜ì—­ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
        for selector in content_selectors:
            elements = soup.select(selector)
            if elements:
                for element in elements:
                    text_content += element.get_text(strip=True, separator=' ')
                break
        
        # ì£¼ìš” ì˜ì—­ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° bodyì—ì„œ ì¶”ì¶œ
        if not text_content:
            body = soup.find('body')
            if body:
                text_content = body.get_text(strip=True, separator=' ')
        
        return process_extracted_text(text_content, url)

    except requests.exceptions.RequestException as e:
        logger.error(f"ì›¹í˜ì´ì§€ ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise ValueError(f"ì›¹í˜ì´ì§€ì— ì ‘ê·¼í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")

def process_extracted_text(text_content: str, url: str) -> str:
    """ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ê³µí†µ ì²˜ë¦¬"""
    try:
        # í…ìŠ¤íŠ¸ ì •ì œ
        text_content = re.sub(r'\s+', ' ', text_content).strip()

        # ë¹ˆ ë‚´ìš© ì²´í¬
        if not text_content:
            raise ValueError("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")

        # ë„ˆë¬´ ì§§ì€ ê²½ìš° ì—ëŸ¬
        if len(text_content) < 100:
            logger.warning(f"ì§§ì€ í…ìŠ¤íŠ¸ ì¶”ì¶œ: {len(text_content)}ì")
            raise ValueError("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ URLì„ ì‹œë„í•´ë³´ì„¸ìš”.")

        # ë„ˆë¬´ ê¸´ ê²½ìš° ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (ChatGPT í† í° ì œí•œ ê³ ë ¤)
        original_length = len(text_content)
        if original_length > 8000:
            text_content = text_content[:8000] + "..."
            logger.info(f"í…ìŠ¤íŠ¸ ê¸¸ì´ ì¡°ì •: {original_length}ì â†’ 8000ì")

        logger.info(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(text_content)}ì")
        return text_content

    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise

async def generate_reels_with_chatgpt(
    content: str,
    is_youtube: bool = False,
    *,
    preserve_target: float = 0.60,        # ì›ë¬¸ ë³´ì¡´ ëª©í‘œì¹˜(ì •ì„±ì  ì§€ì‹œ)
    preserve_threshold: float = 0.22,     # ë³´ì¡´ìœ¨ ìˆ˜ì¹˜ ì„ê³„ì¹˜(ì´ë³´ë‹¤ ë‚®ìœ¼ë©´ ê°•í™” ì¬ì‘ì„± ì‹œë„)
    max_critic_loops: int = 2,            # ë¹„í‰/ìˆ˜ì • ìë™ ë£¨í”„ íšŸìˆ˜
    line_len_min: int = 20,               # body ê° ì¤„ ìµœì†Œ ê¸¸ì´
    line_len_max: int = 42,               # body ê° ì¤„ ìµœëŒ€ ê¸¸ì´
    title_len_max: int = 15               # ì œëª© ìµœëŒ€ ê¸¸ì´
) -> ReelsContent:
    """
    ì›ë¬¸ì¶©ì‹¤ + ìœ„íŠ¸ + ê°•ë ¬í•œ 3ì´ˆ í›„í‚¹ì„ ìœ„í•œ ë‹¤ë‹¨ê³„ ìƒì„±ê¸° (ìµœì‹  ëª¨ë¸ ì„ í˜¸, ì´ì „ í˜¸ì¶œ 100% í˜¸í™˜)

    - ê¸°ì¡´ í˜¸ì¶œ ë°©ì‹ ìœ ì§€: generate_reels_with_chatgpt(content, is_youtube=False)
    - pip ì¶”ê°€ ì„¤ì¹˜ ë¶ˆí•„ìš”(í‘œì¤€ re ì‚¬ìš©)
    - ë„¤íŠ¸ì›Œí¬ í”„ë¡ì‹œ í™˜ê²½ ì•ˆì „ì¥ì¹˜ í¬í•¨(ê¸°ì¡´ ëª¨ë“ˆ í˜¸í™˜)
    - 'OpenAI' import ì˜¤ë¥˜ ë°©ì§€ ë° ì¹œì ˆí•œ ì˜ˆì™¸ ë©”ì‹œì§€
    - ìµœì‹  ëª¨ë¸ ìš°ì„  ì‹œë„ í›„ ìë™ í´ë°±(ê°€ìš© ëª¨ë¸ì— ë”°ë¼ ìˆœì°¨ ì‹œë„)
    - ë³¸ë¬¸ ê¸¸ì´ ìƒ/í•˜í•œ ëª¨ë‘ ë³´ì •(ì§§ì€ ë¬¸ì¥ ìì—° í™•ì¥)
    """
    # --- ì•ˆì „í•œ OpenAI import (pip ì¶”ê°€ ì„¤ì¹˜ ì—†ì´, ë¯¸íƒ‘ì¬ ì‹œ ì¹œì ˆ ë©”ì‹œì§€) ---
    try:
        from openai import OpenAI  # ìµœì‹  íŒŒì´ì¬ SDK (Responses/Chat Completions ëª¨ë‘ ì§€ì›)
    except Exception:
        OpenAI = None

    # FastAPI ì‚¬ìš© í™˜ê²½ì´ ì•„ë‹ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ, HTTPExceptionì€ ì˜µì…˜ ì·¨ê¸‰
    try:
        from fastapi import HTTPException as _HTTPException  # noqa
        _has_http_exc = True
    except Exception:
        _has_http_exc = False

    # --- í™˜ê²½/í‚¤ í™•ì¸ (ì´ì „ ëª¨ë“ˆê³¼ ë™ì¼ ë™ì‘) ---
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY") or os.getenv("OPENAI_APIKEY") or os.getenv("OPENAI_KEY")
    if not OPENAI_API_KEY:
        raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    if OpenAI is None:
        # FastAPI í™˜ê²½ì´ë©´ HTTPExceptionìœ¼ë¡œë„ ëŒ€ì‘ ê°€ëŠ¥í•˜ì§€ë§Œ, ValueError í†µì¼ë¡œ ë‹¨ìˆœí™”
        if _has_http_exc:
            raise _HTTPException(status_code=500, detail="OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        raise ValueError("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

    # --- ë„¤íŠ¸ì›Œí¬ í”„ë¡ì‹œ í•´ì œ(ê¸°ì¡´ ëª¨ë“ˆê³¼ ë™ì¼í•œ ì•ˆì „ì¥ì¹˜) ---
    os.environ.pop('HTTP_PROXY', None)
    os.environ.pop('HTTPS_PROXY', None)

    # --- OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„± ---
    client = OpenAI(api_key=OPENAI_API_KEY, timeout=60.0)

    # ---------- ê³µí†µ ê·œì¹™/ê°€ì´ë“œ ----------
    RULES = rf"""
[ê·œì¹™ - ë°˜ë“œì‹œ ì§€ì¼œ]
- ì›ë¬¸ ì¶©ì‹¤ë„ ìµœìš°ì„ : ì›ë¬¸ ë¬¸ì¥ì„ ê·¸ëŒ€ë¡œ ë˜ëŠ” ì•„ì£¼ ê°€ë³ê²Œ ë‹¤ë“¬ì–´ ì‚¬ìš©(í•µì‹¬ ì–´íœ˜/ê°ì •/ë§íˆ¬ ë³´ì¡´).
- ë‚ ì¡°/ì¶”ì¸¡ ê¸ˆì§€(ì—†ëŠ” ì‚¬ì‹¤ ì¶”ê°€ ê¸ˆì§€), ê³¼ì¥ ê¸ˆì§€, ì´ëª¨ì§€ ê¸ˆì§€.
- í†¤: ëê¹Œì§€ ì¹œê·¼í•œ ë°˜ë§. ì¡´ëŒ“ë§/ë°˜ë§ ì„ì§€ ë§ ê²ƒ.
- ê¸¸ì´: ê¸¸ì´: body1~body7 ê° {line_len_min}ì ì´ìƒ, ê°€ëŠ¥í•˜ë©´ {line_len_max}ì ì•ˆíŒ. ì œëª© {title_len_max}ì ì´ë‚´.
- êµ¬ì¡°(7ì¤„): â‘ í›„í‚¹(ê°•ë ¬ ì˜ë¬¸/ê°ˆë“±) â†’ â‘¡ìƒí™© â†’ â‘¢ê°ì • â†’ â‘£ê·œë²”/ê³µì •ì„± â†’ â‘¤ê°ˆë“± ê°€ì¤‘ â†’ â‘¥ìì˜ë¬¸ â†’ â‘¦ì–‘ìíƒì¼(+ëŒ“ê¸€ ìœ ë„ ê°€ëŠ¥).
- ì¶œë ¥ì€ ì•„ë˜ JSON ìŠ¤í‚¤ë§ˆë§Œ. ì—¬ë¶„ í…ìŠ¤íŠ¸/ì„¤ëª…/ì½”ë“œë¸”ë¡ ì ˆëŒ€ ê¸ˆì§€.
{{
  "title": "...",
  "body1": "...",
  "body2": "...",
  "body3": "...",
  "body4": "...",
  "body5": "...",
  "body6": "...",
  "body7": "..."
}}
"""

    STYLE_HINT = ("YouTube ìŠ¤í¬ë¦½íŠ¸" if is_youtube else "ì›¹ ë³¸ë¬¸")

    # ---------- ìœ í‹¸ ----------
    def _pick_json(s: str) -> str:
        m = re.search(r'\{[\s\S]*\}', s)
        return m.group(0) if m else s

    def _len_ok(line: str) -> bool:
        return line_len_min <= len(line.strip()) <= line_len_max

    def _strip_emoji(s: str) -> str:
        # ëŒ€ë¶€ë¶„ì˜ ì´ëª¨ì§€, í™•ì¥ ê¸°í˜¸ ì œê±°(í‘œì¤€ re ê¸°ë°˜)
        return re.sub(r'[\U00010000-\U0010FFFF]', '', s)

    def _soft_shorten(line: str) -> str:
        # ìì—° ì¶•ì•½ ì‚¬ì „(ë§ë§› ìœ ì§€)
        repl = [
            (" ê²ƒì€", "ê±´"), (" ì¸ê±°ì•¼", "ì¸ ê±°ì•¼"),
            (" í•˜ëŠ” ê±°ì•¼", "í•˜ëŠ” ê±°ì•¼"), (" ê²ƒ ê°™ì•„", " ê°™ì•„"),
            (" í•˜ëŠ” ê²ƒì€", "í•˜ëŠ” ê±´"), (" ê·¸ëŸ°ë°", " ê·¼ë°"),
            (" ì´ë ‡ê²Œ", " ì´ë ‡ê²Œ"), (" ì €ë ‡ê²Œ", " ì €ë ‡ê²Œ"),
            (" ì •ë§", ""), (" ì§„ì§œ", ""), (" ë„ˆë¬´", ""),  # ì¶”ê°€ ì¶•ì•½
        ]
        out = line.strip()
        for _ in range(6):
            if len(out) <= line_len_max:
                break
            for a, b in repl:
                if len(out) <= line_len_max:
                    break
                out = out.replace(a, b)
            # ì—¬ì „íˆ ê¸¸ë©´ 'ë¬¸ì¥ ë‹¨ìœ„'ë¡œ ë¶€ë“œëŸ½ê²Œ ì˜ë¼ë³´ê¸°
            if len(out) > line_len_max:
                # ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ ì´ì „ ê²½ê³„ë¡œ ìë¥´ê¸°
                m = re.findall(r'^(.{,' + str(line_len_max) + r'}[.!?])', out)
                if m:
                    out = m[0].strip()
                    break
                # ê·¸ë˜ë„ ì—†ìœ¼ë©´ 'â€¦' ì—†ì´ í•˜ë“œ ì»· (ë§ë¯¸ êµ¬ë‘ì  ì œê±°)
                out = re.sub(r'[,.â€¦!?]*$', '', out)
                out = out[:line_len_max].rstrip()
                break
        return out

    def _soft_lengthen(line: str, target_min: int) -> str:
        # ì§§ì€ ë¬¸ì¥ì„ ìì—°ìŠ¤ëŸ½ê²Œ í™•ì¥
        s = line.strip()
        fillers: List[str] = [
            " ê·¸ë˜ì„œ ë§ì´ì•¼.", " ê·¼ë° ì—¬ê¸°ì„œ ê³ ë¯¼ë¼.", " ê²°êµ­ ì´ê²Œ í¬ì¸íŠ¸ì•¼.",
            " ë„¤ ìƒê°ì€ ì–´ë•Œ?", " ì†”ì§íˆ ì¢€ ë¬˜í•˜ì§€?", " ì¸ì •í•˜ì§€?",
            " ì´ ë¶€ë¶„ì´ í•µì‹¬ì´ì•¼.", " ë‹¤ì‹œ ìƒê°í•´ë³´ì."
        ]
        i = 0
        # ê³¼ë„ í™•ì¥ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ í•œ ë²ˆì— í•œ ë¬¸ì¥ì”©ë§Œ ë¶™ì—¬ê°€ë©° target_minê¹Œì§€
        while len(s) < target_min and i < len(fillers):
            s = (s.rstrip("â€¦.,!?") + fillers[i]).strip()
            i += 1
        # ê·¸ë˜ë„ ëª¨ìë¼ë©´ ë§ì¤„ì„í‘œë¡œ ë§ˆë¬´ë¦¬
        if len(s) < target_min:
            s = s + "â€¦"
        return s

    def _post_fix(data: dict) -> dict:
        # ì´ëª¨ì§€ ì œê±° + ê¸¸ì´ ë³´ì •(ê¸¸ë©´ ì¤„ì´ê³ , ì§§ìœ¼ë©´ ëŠ˜ë¦¬ê³ ) + ì œëª© ê¸¸ì´ ì œí•œ
        for k in ["body1", "body2", "body3", "body4", "body5", "body6", "body7"]:
            if k in data and isinstance(data[k], str):
                s = _strip_emoji(data[k]).strip()
                if not _len_ok(s):
                    if len(s) > line_len_max:
                        s = _soft_shorten(s)
                    if len(s) < line_len_min:
                        s = _soft_lengthen(s, line_len_min)
                data[k] = s
        if "title" in data and isinstance(data["title"], str):
            t = _strip_emoji(data["title"]).strip()
            if len(t) > title_len_max:
                t = t[:title_len_max]
            data["title"] = t
        return data

    def _preserve_score(original: str, draft_texts: str) -> float:
        """
        ê°„ë‹¨ í† í° ë³´ì¡´ìœ¨: ê³µë°±/êµ¬ë‘ì  ê¸°ì¤€ í† í°í™” í›„ êµì§‘í•© ë¹„ìœ¨
        (í•œêµ­ì–´ í•œê³„ëŠ” ìˆìœ¼ë‚˜ ê³¼ë„ ì˜ì—­ ê°ì§€ìš©ìœ¼ë¡œ ì¶©ë¶„)
        """
        def tok(s: str):
            s = re.sub(r'[^0-9A-Za-zê°€-í£\s]', ' ', s)
            s = re.sub(r'\s+', ' ', s).strip().lower()
            return set(s.split()) if s else set()
        a, b = tok(original), tok(draft_texts)
        if not a or not b:
            return 0.0
        return len(a & b) / max(1, len(a))

    # ---------- OpenAI ëª¨ë¸ ì„ íƒ(ìµœì‹  ì„ í˜¸ + í´ë°±) ----------
    # chat.completionsì—ì„œ í”íˆ ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì‹  ê³„ì—´ ìš°ì„ ìˆœìœ„
    PREFERRED_MODELS = [
        "gpt-4.1",        # ìµœì‹  ê³„ì—´(ê°€ìš© ì‹œ ìš°ì„ )
        "gpt-4.1-mini",   # ê²½ëŸ‰ ìµœì‹ 
        "gpt-4o",         # ê³ ì„±ëŠ¥ ë©€í‹°ëª¨ë‹¬(ê´‘ë²”ìœ„ ê°€ìš©)
        "gpt-4o-mini"     # ê²½ëŸ‰ 4o
    ]

    def _chat_complete_or_raise(model: str, system: str, user: str, temperature: float, max_tokens: int):
        return client.chat.completions.create(
            model=model,
            messages=[{"role": "system", "content": system},
                      {"role": "user", "content": user}],
            temperature=temperature,
            max_tokens=max_tokens
        )

    def _try_models(system: str, user: str, temperature: float, max_tokens: int):
        last_err = None
        for m in PREFERRED_MODELS:
            try:
                return _chat_complete_or_raise(m, system, user, temperature, max_tokens), m
            except Exception as e:
                last_err = e
                continue
        # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨ ì‹œ ì›ì¸ ì „ë‹¬
        raise ValueError(f"ëª¨ë¸ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(last_err) if last_err else 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}")

    # ---------- 1) EXTRACT ----------
    extract_prompt = f"""
ë„ˆëŠ” ì¹´í”¼ë¼ì´í„°ë‹¤. ë‹¤ìŒ {STYLE_HINT}ì—ì„œ 'ì§ì ‘ ì¸ìš© ë˜ëŠ” ë³´ì¡´í•  ë§Œí•œ í•µì‹¬ ë¬¸ì¥'ì„ ë½‘ì•„ë¼.
- í›…/ê°ˆë“±/ê°ì •/ê·œë²”(ê³µì •ì„±)/ì–‘ìíƒì¼ ì‹ í˜¸ê°€ ìˆëŠ” ë¬¸ì¥ì„ ìš°ì„ .
- ê° í•­ëª©ì€ ê·¸ëŒ€ë¡œ ì¸ìš© ê°€ëŠ¥í•œ ë¬¸ì¥ ë˜ëŠ” ê°€ë³ê²Œ ë¬¸ì¥ë¶€í˜¸ë§Œ ì†ë³¸ í˜•íƒœ.
- ê° í•­ëª©ì— role=hook|situation|feeling|norms|conflict|self_doubt|choice ì¤‘ í•˜ë‚˜ì˜ íƒœê·¸ë¥¼ ë¶™ì—¬ë¼.
- 10ê°œ ì´ë‚´ë¡œ JSON ë°°ì—´ë§Œ ì¶œë ¥.

[ì›ë¬¸]
{content}

[ì¶œë ¥ í˜•ì‹(JSONë§Œ)]
[
  {{ "role": "hook", "text": "..." }},
  {{ "role": "situation", "text": "..." }}
]
"""
    extract_resp, _ = _try_models(
        system="ë¬¸ì¥ ì¶”ì¶œê°€ì´ì ì–¸ì–´ì •ì œì.",
        user=extract_prompt,
        temperature=0.3,
        max_tokens=1000
    )
    extract = extract_resp.choices[0].message.content

    try:
        cand_json = json.loads(re.findall(r'\[[\s\S]*\]', extract)[0])
    except Exception:
        cand_json = []

    # ---------- 2) WRITE (ì´ˆì•ˆ) ----------
    write_prompt = f"""
ë‹¤ìŒì€ ì›ë¬¸ì—ì„œ ì¶”ì¶œí•œ 'ë³´ì¡´ í›„ë³´ ë¬¸ì¥ë“¤'ì´ë‹¤. ì´ë¥¼ ìµœëŒ€í•œ í™œìš©í•´ ë¦´ìŠ¤ ëŒ€ì‚¬ë¥¼ ì‘ì„±í•˜ë¼.
- ì§ì ‘ ì¸ìš© ë˜ëŠ” ì›ë¬¸ ì–´êµ¬ ë³´ì¡´ ë¹„ìœ¨ì„ ë†’ì—¬ë¼(ëª©í‘œ: ì•½ {int(preserve_target*100)}% ì´ìƒ).
- ë¶€ì¡±í•œ ì—°ê²°ë§Œ ìµœì†Œí•œìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë³´ì™„.
- [ê·œì¹™]ì„ ì—„ê²©íˆ ì¤€ìˆ˜.

[ë³´ì¡´ í›„ë³´ ë¬¸ì¥ë“¤(JSON)]
{json.dumps(cand_json, ensure_ascii=False, indent=2)}

{RULES}
"""
    draft_resp, _ = _try_models(
        system="ë¦´ìŠ¤ ì¹´í”¼ë¼ì´íŒ… ì „ë¬¸ê°€.",
        user=write_prompt,
        temperature=0.6,
        max_tokens=1000
    )
    draft = draft_resp.choices[0].message.content

    # ---------- 3) CRITIC ë£¨í”„ ----------
    def _critic_fix(text: str) -> str:
        critic_prompt = f"""
ë„ˆëŠ” ì—„ê²©í•œ ì—ë””í„°ë‹¤. ì•„ë˜ ì´ˆì•ˆì´ [ê·œì¹™]ì„ ìœ„ë°˜í•˜ë©´ ìŠ¤ìŠ¤ë¡œ ê³ ì³ì„œ ìµœì¢… JSONë§Œ ì¶œë ¥í•˜ë¼.
íŠ¹íˆ ê¸¸ì´({line_len_min}~{line_len_max}ì), ë°˜ë§ í†µì¼, ì´ëª¨ì§€ ì œê±°, ë‚ ì¡° ê¸ˆì§€, êµ¬ì¡°(7ì¤„) ì¤€ìˆ˜, ì œëª© {title_len_max}ì ì´ë‚´ë¥¼ ì ê²€í•˜ë¼.

[ì´ˆì•ˆ]
{text}

{RULES}
"""
        resp, _ = _try_models(
            system="í˜•ì‹Â·ì œì•½ ê²€ìˆ˜ ì „ë¬¸ê°€.",
            user=critic_prompt,
            temperature=0.2,
            max_tokens=800
        )
        return resp.choices[0].message.content.strip()

    final_out = draft
    for _ in range(max(0, int(max_critic_loops))):
        final_out = _critic_fix(final_out)

    # ---------- 4) JSON íŒŒì‹± + POST ----------
    try:
        data = json.loads(_pick_json(final_out))
    except Exception:
        repair_prompt = f"""
ì•„ë˜ í…ìŠ¤íŠ¸ì—ì„œ JSONë§Œ ì¶”ì¶œí•´ ìœ íš¨í•œ JSONìœ¼ë¡œ ì •ë¦¬í•´ë¼. í•„ë“œ ëˆ„ë½ì‹œ ê³µë°± ë¬¸ìì—´ë¡œ ì±„ì›Œë¼.
í•„ë“œëŠ” title, body1~body7 ì´ë‹¤. ì„¤ëª… ê¸ˆì§€. JSONë§Œ ì¶œë ¥.

[í…ìŠ¤íŠ¸]
{final_out}
"""
        fixed_resp, _ = _try_models(
            system="JSON ì •ë¦¬ì",
            user=repair_prompt,
            temperature=0.0,
            max_tokens=300
        )
        fixed = fixed_resp.choices[0].message.content
        data = json.loads(_pick_json(fixed))

    data = _post_fix(data)

    # ---------- 5) ë³´ì¡´ìœ¨ ê²€ì‚¬(ë‚®ìœ¼ë©´ 1íšŒ ì¬ì‘ì„±) ----------
    joined_bodies = " ".join([data.get(k, "") for k in ["body1", "body2", "body3", "body4", "body5", "body6", "body7"]])
    score = _preserve_score(content, joined_bodies)

    if score < preserve_threshold:
        reinforce_prompt = f"""
ë³´ì¡´ìœ¨(ì›ë¬¸ ì–´êµ¬ ë³´ì¡´)ì´ ë‚®ë‹¤. ì•„ë˜ JSONì„ ì°¸ê³ í•˜ì—¬ ì›ë¬¸ í‘œí˜„ì„ ë” ì§ì ‘ì ìœ¼ë¡œ ì‚´ë ¤ ë‹¤ì‹œ ì¨ë¼.
- ê°€ëŠ¥í•œ ë¬¸ì¥ì€ 'ê±°ì˜ ê·¸ëŒ€ë¡œ' ì‚¬ìš©í•˜ë˜ ê¸¸ì´ ê·œì¹™ì„ ì§€ì¼œë¼.
- íŠ¹íˆ í›…/ê°ˆë“±/ê°ì • ë¬¸ì¥ì€ ì›ë¬¸ ì§ì¸ìš© ìš°ì„ .
- JSONë§Œ ì¶œë ¥.

[í˜„ì¬ ê²°ê³¼(JSON)]
{json.dumps(data, ensure_ascii=False, indent=2)}

[ì›ë¬¸]
{content}

{RULES}
"""
        reinforced_resp, _ = _try_models(
            system="ì›ë¬¸ ë³´ì¡´ ê°•í™” ë¦¬ë¼ì´í„°",
            user=reinforce_prompt,
            temperature=0.4,
            max_tokens=900
        )
        reinforced = reinforced_resp.choices[0].message.content

        try:
            data2 = json.loads(_pick_json(reinforced))
            data2 = _post_fix(data2)
            joined2 = " ".join([data2.get(k, "") for k in ["body1", "body2", "body3", "body4", "body5", "body6", "body7"]])
            score2 = _preserve_score(content, joined2)
            if score2 >= score:
                data = data2
        except Exception:
            pass

    # ---------- ëª¨ë¸ ê°ì²´ë¡œ ë°˜í™˜ (ì´ì „ê³¼ ë™ì¼ ReelsContent) ----------
    reels_content = ReelsContent(
        title=data.get("title", ""),
        body1=data.get("body1", ""),
        body2=data.get("body2", ""),
        body3=data.get("body3", ""),
        body4=data.get("body4", ""),
        body5=data.get("body5", ""),
        body6=data.get("body6", ""),
        body7=data.get("body7", "")
    )
    return reels_content


# ê³µí†µ í”„ë¡¬í”„íŠ¸ ë¹Œë” -----------------------------------------------------------
def build_illustration_prompt(source_text: str) -> str:
    """
    'ì‹¤ì‚¬ ì‚¬ì§„ ê°™ì€(photorealistic), í†¤ë‹¤ìš´' ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•œ í”„ë¡¬í”„íŠ¸.
    ì…ë ¥ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ì£¼ì œë¡œ ì‚¼ì•„ ì¶©ì‹¤íˆ ì‹œê°í™”í•˜ë©°,
    ê³¼ë„í•œ ì±„ë„/ëŒ€ë¹„ë¥¼ í”¼í•˜ê³  ìì—°ê´‘ê³¼ ì˜í™”ì  í†¤ìœ¼ë¡œ ë¬˜ì‚¬í•˜ë„ë¡ ì§€ì‹œí•©ë‹ˆë‹¤.
    """
    return f"""
Create a photorealistic color photograph that faithfully visualizes the meaning and main subject of this sentence:

"{source_text}"

Output intent:
- Show a believable real-world scene that clearly expresses the sentence's core idea.
- Stay faithful to the content; do not introduce objects, characters, or events that are not implied.

Look & grading:
- Muted, toned-down palette with soft natural/ambient lighting.
- Gentle contrast and highlights; subtle filmic grain; realistic materials and textures.
- Cinematic color grading leaning warm neutrals; avoid neon or oversaturated colors.

Camera & optics:
- Full-frame aesthetic, 35â€“50mm equivalent, f/2.8â€“f/4 for shallow-to-moderate depth of field.
- Physically plausible shadows/reflections and coherent global illumination.
- Accurate perspective and scale; natural bokeh if applicable.

Composition:
- Clean and uncluttered; contemporary, minimal styling.
- Square format (1024Ã—1024) with balanced framing and negative space allowed.

Strict rules:
- Do NOT render any words, letters, numbers, captions, UI, logos, brands, watermarks, or signage.
- Avoid illustration, vector art, cartoon/comic style, heavy outlines, flat primary colors, 3D render look, HDR/over-processed effects, or surreal elements.
- People (if any) must be generic and anonymous (no celebrity likeness, no identifying details).

Keywords: photorealistic, filmic, muted colors, natural light, soft shadows, depth of field, realistic textures, subtle grain, cinematic, refined.
""".strip()



def build_safe_retry_prompt(source_text: str) -> str:
    """
    ì½˜í…ì¸  í•„í„° ì¬ì‹œë„ìš©: 'ì‹¤ì‚¬(photorealistic), í†¤ë‹¤ìš´' ì´ë¯¸ì§€ ì§€ì‹œë¬¸.
    ì…ë ¥ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ë³´ì¡´í•˜ë˜, ì‹ë³„ ê°€ëŠ¥í•œ ë””í…Œì¼ì„ ì¤„ì´ê¸° ìœ„í•´
    'ê·¸ë¦¼ì/ì‹¤ë£¨ì—£/ë°˜ì‚¬' ìœ„ì£¼ë¡œ ì•ˆì „í•˜ê²Œ ì‹œê°í™”í•œë‹¤.
    """
    return f"""
Create a muted, photorealistic color photograph that conveys the core meaning of this sentence
through silhouettes, soft shadows, or subtle reflections only (no readable details):

"{source_text}"

Output intent:
- Depict a believable real-world scene that clearly relates to the sentence above.
- Visualize the subject via silhouettes/shadows/reflections on simple surfaces (walls, floors, curtains, tables),
  or through diffused light and occlusion; avoid identifiable details.
- If the sentence implies people, show backlit figures or partial silhouettes only; otherwise, prefer object/environment shadows.

Look & grading:
- Muted, toned-down colors; soft ambient/natural light (overcast or late-afternoon backlight).
- Gentle contrast; subtle filmic grain; realistic materials and textures.
- Coherent global illumination and physically plausible shadows/reflections.

Camera & optics:
- 35â€“50mm full-frame equivalent, f/2.8â€“f/4 for shallow-to-moderate depth of field.
- Accurate perspective and scale; natural bokeh if applicable.

Composition:
- Clean, uncluttered frame; negative space allowed.
- Square format (1024Ã—1024); balanced, minimal composition focused on silhouettes/shadows.

Strict safety rules:
- No readable text, letters, numbers, logos, brands, UI, or watermarks.
- No identifiable faces or unique personal details (tattoos, plates, IDs).
- Avoid violence, medical/graphic content, sexual/suggestive elements, minors.
- Avoid illustration/vector/cartoon look, heavy outlines, HDR/over-processed effects, surreal/fantasy.

Keywords: photorealistic, silhouette, shadow play, muted colors, natural light, subtle grain, cinematic calm, minimal, safe content.
""".strip()

# ---------------------------------------------------------------------------
# 1) ë³‘ë ¬(ë¹„ë™ê¸°) ìƒì„± í•¨ìˆ˜
# ---------------------------------------------------------------------------
async def generate_images_with_dalle(texts: List[str], job_id: Optional[str] = None) -> List[str]:
    """DALL-Eë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±í•˜ê³  ë¡œì»¬ì— ì €ì¥ (ë³‘ë ¬ ì²˜ë¦¬ë¡œ 60-80% ì„±ëŠ¥ í–¥ìƒ)"""
    import requests
    import aiohttp
    from openai import OpenAI
    from urllib.parse import urlparse

    # aiohttp ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    try:
        _ = aiohttp.__version__
        AIOHTTP_AVAILABLE = True
    except Exception:
        AIOHTTP_AVAILABLE = False

    if not AIOHTTP_AVAILABLE:
        logger.warning("aiohttpê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ìˆœì°¨ ì²˜ë¦¬ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        # ìˆœì°¨ ì²˜ë¦¬ fallback ì‚¬ìš© (job_id ì „ë‹¬)
        return await generate_images_with_dalle_sequential(texts, job_id)

    try:
        if not OPENAI_API_KEY:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        logger.info(f"ğŸš€ ë³‘ë ¬ DALL-E ì´ë¯¸ì§€ ìƒì„± ì‹œì‘: {len(texts)}ê°œ (ì„±ëŠ¥ ìµœì í™” ëª¨ë“œ)")

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = OpenAI(api_key=OPENAI_API_KEY, timeout=60.0)

        # uploads ë””ë ‰í† ë¦¬ ì„¤ì • (Job IDì— ë”°ë¼ ë¶„ê¸°)
        if job_id and FOLDER_MANAGER_AVAILABLE:
            try:
                job_uploads_folder, _ = folder_manager.get_job_folders(job_id)
                uploads_dir = job_uploads_folder
                os.makedirs(uploads_dir, exist_ok=True)
                logger.info(f"ğŸ—‚ï¸ Job ê³ ìœ  í´ë” ì‚¬ìš©: {uploads_dir}")
            except Exception as job_error:
                logger.warning(f"âš ï¸ Job í´ë” ì‚¬ìš© ì‹¤íŒ¨, ê¸°ë³¸ í´ë” ì‚¬ìš©: {job_error}")
                uploads_dir = os.path.join(os.path.dirname(__file__), "uploads")
                os.makedirs(uploads_dir, exist_ok=True)
        else:
            uploads_dir = os.path.join(os.path.dirname(__file__), "uploads")
            os.makedirs(uploads_dir, exist_ok=True)

        async def generate_single_image(i: int, text: str) -> str:
            """ë‹¨ì¼ ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (ë¹„ë™ê¸° ì²˜ë¦¬)"""
            try:
                logger.info(f"ğŸ“¸ ì´ë¯¸ì§€ {i+1}/{len(texts)} ìƒì„± ì‹œì‘: {text[:30]}...")

                prompt = build_illustration_prompt(text)
                logger.info(f"ğŸ¯ ì´ë¯¸ì§€ {i+1} DALL-E í”„ë¡¬í”„íŠ¸(ìš”ì•½): {prompt.splitlines()[0]} ...")

                # DALL-E API í˜¸ì¶œ (ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸° ë˜í¼ë¡œ ì²˜ë¦¬)
                loop = asyncio.get_event_loop()
                response = await loop.run_in_executor(
                    None,
                    lambda: client.images.generate(
                        model="dall-e-3",
                        prompt=prompt,
                        size="1024x1024",
                        quality="standard",
                        n=1,
                    ),
                )

                # ì´ë¯¸ì§€ URL ì¶”ì¶œ
                image_url = response.data[0].url
                logger.info(f"âœ… ì´ë¯¸ì§€ {i+1} ìƒì„± ì™„ë£Œ, ë‹¤ìš´ë¡œë“œ ì¤‘...")

                # ë¹„ë™ê¸° ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
                    async with session.get(image_url) as img_response:
                        if img_response.status == 200:
                            filename = f"generated_{uuid.uuid4().hex[:8]}_{i+1}.png"
                            file_path = os.path.join(uploads_dir, filename)
                            with open(file_path, "wb") as f:
                                f.write(await img_response.read())

                            # Job IDì— ë”°ë¼ URL ê²½ë¡œ ì„¤ì •
                            if job_id and FOLDER_MANAGER_AVAILABLE:
                                image_url_path = f"/job-uploads/{job_id}/{filename}"
                            else:
                                image_url_path = f"/get-image/{filename}"

                            logger.info(f"ğŸ’¾ ì´ë¯¸ì§€ {i+1} ì €ì¥ ì™„ë£Œ: {filename}")
                            return image_url_path
                        else:
                            logger.error(f"âŒ ì´ë¯¸ì§€ {i+1} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {img_response.status}")
                            return ""

            except Exception as e:
                logger.error(f"ğŸ’¥ ì´ë¯¸ì§€ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

                # ì½˜í…ì¸  í•„í„°ë§ ì—ëŸ¬ì¸ ê²½ìš° ì¬ì‹œë„
                if "content_policy_violation" in str(e).lower():
                    logger.info(f"ğŸ”„ ì´ë¯¸ì§€ {i+1} ì½˜í…ì¸  í•„í„°ë§ìœ¼ë¡œ ì¸í•œ ì¬ì‹œë„ ì¤‘...")
                    try:
                        retry_prompt = build_safe_retry_prompt(text)
                        loop = asyncio.get_event_loop()
                        retry_response = await loop.run_in_executor(
                            None,
                            lambda: client.images.generate(
                                model="dall-e-3",
                                prompt=retry_prompt,
                                size="1024x1024",
                                quality="standard",
                                n=1,
                            ),
                        )

                        retry_image_url = retry_response.data[0].url
                        logger.info(f"ğŸ”„ ì´ë¯¸ì§€ {i+1} ì¬ì‹œë„ ì„±ê³µ, ë‹¤ìš´ë¡œë“œ ì¤‘...")

                        async with aiohttp.ClientSession(timeout=aiohttp.ClientTimeout(total=30)) as session:
                            async with session.get(retry_image_url) as retry_img_response:
                                if retry_img_response.status == 200:
                                    retry_filename = f"generated_{uuid.uuid4().hex[:8]}_{i+1}_retry.png"
                                    retry_file_path = os.path.join(uploads_dir, retry_filename)
                                    with open(retry_file_path, "wb") as f:
                                        f.write(await retry_img_response.read())

                                    retry_image_url_path = f"/get-image/{retry_filename}"
                                    logger.info(f"ğŸ’¾ ì´ë¯¸ì§€ {i+1} ì¬ì‹œë„ ì €ì¥ ì™„ë£Œ: {retry_filename}")
                                    return retry_image_url_path
                                else:
                                    logger.error(
                                        f"âŒ ì´ë¯¸ì§€ {i+1} ì¬ì‹œë„ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {retry_img_response.status}"
                                    )
                                    return ""
                    except Exception as retry_e:
                        logger.error(f"ğŸ’¥ ì´ë¯¸ì§€ {i+1} ì¬ì‹œë„ ì‹¤íŒ¨: {retry_e}")
                        return ""
                else:
                    return ""

        # ğŸš€ ë³‘ë ¬ ì²˜ë¦¬ë¡œ ëª¨ë“  ì´ë¯¸ì§€ ë™ì‹œ ìƒì„±
        logger.info(f"âš¡ {len(texts)}ê°œ ì´ë¯¸ì§€ë¥¼ ë³‘ë ¬ë¡œ ì²˜ë¦¬ ì‹œì‘... (ê¸°ì¡´ ëŒ€ë¹„ 60-80% ì‹œê°„ ë‹¨ì¶•)")
        # (ì„ íƒ) ë ˆì´íŠ¸ë¦¬ë°‹ ëŒ€ë¹„ ë™ì‹œì„± ì œí•œì„ ê±¸ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ ì„¸ë§ˆí¬ì–´ ì‚¬ìš©
        # sem = asyncio.Semaphore(5)
        # tasks = [run_with_sem(sem, generate_single_image, i, text) for i, text in enumerate(texts)]
        tasks = [generate_single_image(i, text) for i, text in enumerate(texts)]
        generated_image_paths = await asyncio.gather(*tasks)

        success_count = sum(1 for path in generated_image_paths if path)
        logger.info(f"ğŸ‰ ë³‘ë ¬ DALL-E ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {success_count}/{len(texts)}ê°œ ì„±ê³µ")

        return generated_image_paths

    except Exception as e:
        logger.error(f"DALL-E API ì˜¤ë¥˜: {e}")
        raise ValueError(f"ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")


# ---------------------------------------------------------------------------
# 2) ìˆœì°¨(ë™ê¸°) í´ë°± í•¨ìˆ˜
# ---------------------------------------------------------------------------
async def generate_images_with_dalle_sequential(texts: List[str], job_id: Optional[str] = None) -> List[str]:
    """DALL-Eë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„±í•˜ê³  ë¡œì»¬ì— ì €ì¥ (ìˆœì°¨ ì²˜ë¦¬ fallback)"""
    import requests
    from openai import OpenAI
    from urllib.parse import urlparse

    try:
        if not OPENAI_API_KEY:
            raise ValueError("OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        logger.info(f"ğŸ”„ ìˆœì°¨ DALL-E ì´ë¯¸ì§€ ìƒì„± ì‹œì‘: {len(texts)}ê°œ (fallback ëª¨ë“œ)")

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        client = OpenAI(api_key=OPENAI_API_KEY, timeout=60.0)

        # uploads ë””ë ‰í† ë¦¬ ì„¤ì • (Job IDì— ë”°ë¼ ë¶„ê¸°)
        if job_id and FOLDER_MANAGER_AVAILABLE:
            try:
                job_uploads_folder, _ = folder_manager.get_job_folders(job_id)
                uploads_dir = job_uploads_folder
                os.makedirs(uploads_dir, exist_ok=True)
                logger.info(f"ğŸ—‚ï¸ Job ê³ ìœ  í´ë” ì‚¬ìš© (ìˆœì°¨ ì²˜ë¦¬): {uploads_dir}")
            except Exception as job_error:
                logger.warning(f"âš ï¸ Job í´ë” ì‚¬ìš© ì‹¤íŒ¨, ê¸°ë³¸ í´ë” ì‚¬ìš© (ìˆœì°¨ ì²˜ë¦¬): {job_error}")
                uploads_dir = os.path.join(os.path.dirname(__file__), "uploads")
                os.makedirs(uploads_dir, exist_ok=True)
        else:
            uploads_dir = os.path.join(os.path.dirname(__file__), "uploads")
            os.makedirs(uploads_dir, exist_ok=True)

        generated_image_paths: List[str] = []

        for i, text in enumerate(texts):
            try:
                logger.info(f"ğŸ“¸ ì´ë¯¸ì§€ {i+1}/{len(texts)} ìƒì„± ì‹œì‘: {text[:30]}...")

                prompt = build_illustration_prompt(text)
                logger.info(f"ğŸ¯ ì´ë¯¸ì§€ {i+1} DALL-E í”„ë¡¬í”„íŠ¸(ìš”ì•½): {prompt.splitlines()[0]} ...")

                # DALL-E API í˜¸ì¶œ
                response = client.images.generate(
                    model="dall-e-3",
                    prompt=prompt,
                    size="1024x1024",
                    quality="standard",
                    n=1,
                )

                image_url = response.data[0].url
                logger.info(f"âœ… ì´ë¯¸ì§€ {i+1} ìƒì„± ì™„ë£Œ, ë‹¤ìš´ë¡œë“œ ì¤‘...")

                # ìˆœì°¨ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (requests ì‚¬ìš©)
                img_response = requests.get(image_url, timeout=30)
                if img_response.status_code == 200:
                    filename = f"generated_{uuid.uuid4().hex[:8]}_{i+1}.png"
                    file_path = os.path.join(uploads_dir, filename)
                    with open(file_path, "wb") as f:
                        f.write(img_response.content)

                    # Job IDì— ë”°ë¼ URL ê²½ë¡œ ì„¤ì •
                    if job_id and FOLDER_MANAGER_AVAILABLE:
                        image_url_path = f"/job-uploads/{job_id}/{filename}"
                    else:
                        image_url_path = f"/get-image/{filename}"

                    logger.info(f"ğŸ’¾ ì´ë¯¸ì§€ {i+1} ì €ì¥ ì™„ë£Œ: {filename}")
                    generated_image_paths.append(image_url_path)
                else:
                    logger.error(f"âŒ ì´ë¯¸ì§€ {i+1} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {img_response.status_code}")
                    generated_image_paths.append("")

            except Exception as e:
                logger.error(f"ğŸ’¥ ì´ë¯¸ì§€ {i+1} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

                # ì½˜í…ì¸  í•„í„°ë§ ì—ëŸ¬ì¸ ê²½ìš° ì¬ì‹œë„(ìˆœì°¨)
                if "content_policy_violation" in str(e).lower():
                    try:
                        retry_prompt = build_safe_retry_prompt(text)
                        retry_response = client.images.generate(
                            model="dall-e-3",
                            prompt=retry_prompt,
                            size="1024x1024",
                            quality="standard",
                            n=1,
                        )
                        retry_image_url = retry_response.data[0].url

                        retry_img = requests.get(retry_image_url, timeout=30)
                        if retry_img.status_code == 200:
                            retry_filename = f"generated_{uuid.uuid4().hex[:8]}_{i+1}_retry.png"
                            retry_file_path = os.path.join(uploads_dir, retry_filename)
                            with open(retry_file_path, "wb") as f:
                                f.write(retry_img.content)

                            # Job IDì— ë”°ë¼ URL ê²½ë¡œ ì„¤ì • (ì¬ì‹œë„)
                            if job_id and FOLDER_MANAGER_AVAILABLE:
                                retry_image_url_path = f"/job-uploads/{job_id}/{retry_filename}"
                            else:
                                retry_image_url_path = f"/get-image/{retry_filename}"

                            logger.info(f"ğŸ’¾ ì´ë¯¸ì§€ {i+1} ì¬ì‹œë„ ì €ì¥ ì™„ë£Œ: {retry_filename}")
                            generated_image_paths.append(retry_image_url_path)
                        else:
                            logger.error(f"âŒ ì´ë¯¸ì§€ {i+1} ì¬ì‹œë„ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: HTTP {retry_img.status_code}")
                            generated_image_paths.append("")
                    except Exception as retry_e:
                        logger.error(f"ğŸ’¥ ì´ë¯¸ì§€ {i+1} ì¬ì‹œë„ ì‹¤íŒ¨: {retry_e}")
                        generated_image_paths.append("")
                else:
                    generated_image_paths.append("")

        success_count = sum(1 for path in generated_image_paths if path)
        logger.info(f"ğŸ‰ ìˆœì°¨ DALL-E ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {success_count}/{len(texts)}ê°œ ì„±ê³µ (fallback ëª¨ë“œ)")

        return generated_image_paths

    except Exception as e:
        logger.error(f"ìˆœì°¨ DALL-E API ì˜¤ë¥˜: {e}")
        raise ValueError(f"ìˆœì°¨ ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}")

@app.post("/generate-images")
async def generate_images(request: ImageGenerateRequest):
    """í…ìŠ¤íŠ¸ ê¸°ë°˜ ì´ë¯¸ì§€ ìë™ ìƒì„±"""
    try:
        logger.info(f"ì´ë¯¸ì§€ ìƒì„± ìš”ì²­: {len(request.texts)}ê°œ í…ìŠ¤íŠ¸")
        
        # í…ìŠ¤íŠ¸ ê²€ì¦
        if not request.texts or len(request.texts) == 0:
            raise HTTPException(status_code=400, detail="ìƒì„±í•  í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ëª¨ë“œì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ì²˜ë¦¬
        if request.mode == "per_two_scripts":
            # 2ê°œì”© ë¬¶ì–´ì„œ ì²˜ë¦¬
            processed_texts = []
            for i in range(0, len(request.texts), 2):
                combined_text = request.texts[i]
                if i + 1 < len(request.texts):
                    combined_text += f" {request.texts[i + 1]}"
                processed_texts.append(combined_text)
        else:
            # ê°ê° ê°œë³„ ì²˜ë¦¬
            processed_texts = request.texts
        
        # DALL-Eë¡œ ì´ë¯¸ì§€ ìƒì„± (Job ID ì „ë‹¬)
        try:
            image_urls = await generate_images_with_dalle(processed_texts, request.job_id)
        except ValueError as e:
            raise HTTPException(status_code=500, detail=str(e))
        
        return JSONResponse(
            content={
                "status": "success",
                "message": f"{len([url for url in image_urls if url])}ê°œ ì´ë¯¸ì§€ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "image_urls": image_urls  # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail="ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@app.get("/get-image/{filename}")
async def get_image(filename: str):
    """ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ì„œë¹™"""
    try:
        file_path = os.path.join(uploads_dir, filename)
        
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë³´ì•ˆì„ ìœ„í•´ íŒŒì¼ëª… ê²€ì¦
        if not filename.startswith("generated_") or not filename.endswith(".png"):
            raise HTTPException(status_code=403, detail="ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì€ íŒŒì¼ì…ë‹ˆë‹¤.")
        
        return FileResponse(
            path=file_path,
            media_type="image/png",
            headers={"Cache-Control": "public, max-age=3600"}  # 1ì‹œê°„ ìºì‹œ
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ íŒŒì¼ ì„œë¹™ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ì´ë¯¸ì§€ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

@app.get("/download-image/{filename}")
async def download_image(filename: str):
    """ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (attachmentë¡œ)"""
    try:
        file_path = os.path.join(uploads_dir, filename)
        
        # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(file_path):
            raise HTTPException(status_code=404, detail="ì´ë¯¸ì§€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ë³´ì•ˆì„ ìœ„í•´ íŒŒì¼ëª… ê²€ì¦
        if not filename.startswith("generated_") or not filename.endswith(".png"):
            raise HTTPException(status_code=403, detail="ì ‘ê·¼ì´ í—ˆìš©ë˜ì§€ ì•Šì€ íŒŒì¼ì…ë‹ˆë‹¤.")
        
        # ë” ì¹œí™”ì ì¸ íŒŒì¼ëª… ìƒì„± (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜)
        from datetime import datetime
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        download_filename = f"reels_image_{timestamp}.png"
        
        return FileResponse(
            path=file_path,
            media_type="image/png",
            filename=download_filename,
            headers={
                "Content-Disposition": f"attachment; filename={download_filename}",
                "Cache-Control": "no-cache"
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

@app.post("/extract-reels-from-url")
async def extract_reels_from_url(request: URLExtractRequest):
    """URLì—ì„œ ë¦´ìŠ¤ ëŒ€ë³¸ ì¶”ì¶œ"""
    try:
        logger.info(f"ë¦´ìŠ¤ ì¶”ì¶œ ìš”ì²­: {request.url}")
        
        # URL ê²€ì¦
        if not request.url.strip():
            raise HTTPException(status_code=400, detail="URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        
        # URL í˜•ì‹ ê²€ì¦
        try:
            parsed_url = urlparse(request.url)
            if not parsed_url.scheme or not parsed_url.netloc:
                raise ValueError("ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        except Exception:
            raise HTTPException(status_code=400, detail="ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.")
        
        # YouTube URLì¸ì§€ í™•ì¸í•˜ê³  ì ì ˆí•œ ì½˜í…ì¸  ì¶”ì¶œ
        try:
            if is_youtube_url(request.url):
                # YouTube ë¹„ë””ì˜¤ ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ
                video_id = extract_youtube_video_id(request.url)
                if not video_id:
                    logger.error(f"YouTube ë¹„ë””ì˜¤ ID ì¶”ì¶œ ì‹¤íŒ¨: {request.url}")
                    raise ValueError("YouTube ë¹„ë””ì˜¤ IDë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
                logger.info(f"YouTube ë¹„ë””ì˜¤ ê°ì§€: {video_id}")
                scraped_content = get_youtube_transcript(video_id)
                logger.info(f"YouTube ìŠ¤í¬ë¦½íŠ¸ ì¶”ì¶œ ì™„ë£Œ: {len(scraped_content)} ë¬¸ì")
            else:
                # ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í•‘
                logger.info(f"ì¼ë°˜ ì›¹ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í•‘ ì‹œì‘: {request.url}")
                scraped_content = scrape_website_content(request.url)
                logger.info(f"ì›¹ì‚¬ì´íŠ¸ ìŠ¤í¬ë˜í•‘ ì™„ë£Œ: {len(scraped_content)} ë¬¸ì")
        except ValueError as e:
            logger.error(f"ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨ - ValueError: {str(e)}")
            raise HTTPException(status_code=400, detail=str(e))
        except Exception as e:
            logger.error(f"ì½˜í…ì¸  ì¶”ì¶œ ì‹¤íŒ¨ - ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}")
            raise HTTPException(status_code=500, detail=f"ì½˜í…ì¸  ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
        
        # ChatGPTë¡œ ë¦´ìŠ¤ ëŒ€ë³¸ ìƒì„±
        try:
            is_youtube_content = is_youtube_url(request.url)
            reels_content = await generate_reels_with_chatgpt(scraped_content, is_youtube_content)
        except ValueError as e:
            raise HTTPException(status_code=500, detail=str(e))
        
        return JSONResponse(
            content={
                "status": "success",
                "message": "ë¦´ìŠ¤ ëŒ€ë³¸ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "reels_content": reels_content.model_dump()
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ë¦´ìŠ¤ ì¶”ì¶œ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
        raise HTTPException(status_code=500, detail="ë¦´ìŠ¤ ëŒ€ë³¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ë°°ì¹˜ ì‘ì—… ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.post("/generate-video-async")
async def generate_video_async(
    user_email: str = Form(...),
    content_data: str = Form(...),
    music_mood: str = Form(default="bright"),
    image_allocation_mode: str = Form(default="2_per_image"),
    text_position: str = Form(default="bottom"),
    text_style: str = Form(default="outline"),
    title_area_mode: str = Form(default="keep"),
    selected_bgm_path: str = Form(default=""),
    use_test_files: bool = Form(default=False),
    
    # í°íŠ¸ ì„¤ì • ì¶”ê°€
    title_font: str = Form(default="BMYEONSUNG_otf.otf"),  # íƒ€ì´í‹€ í°íŠ¸
    body_font: str = Form(default="BMYEONSUNG_otf.otf"),   # ë³¸ë¬¸ í°íŠ¸
    title_font_size: int = Form(default=42),               # íƒ€ì´í‹€ í°íŠ¸ í¬ê¸° (pt)
    body_font_size: int = Form(default=36),                # ë³¸ë¬¸ í°íŠ¸ í¬ê¸° (pt)

    # ìë§‰ ì½ì–´ì£¼ê¸° ì„¤ì •
    voice_narration: str = Form(default="enabled"),        # "enabled" (ì¶”ê°€) ë˜ëŠ” "disabled" (ì œê±°)

    # í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì„¤ì •
    cross_dissolve: str = Form(default="enabled"),          # "enabled" (ì ìš©) ë˜ëŠ” "disabled" (ë¯¸ì ìš©)

    # ìë§‰ ì§€ì† ì‹œê°„ ì„¤ì • (ì´ˆ ë‹¨ìœ„)
    subtitle_duration: float = Form(default=0.0),           # 0: ìŒì„± ê¸¸ì´ ì‚¬ìš©, 0 ì´ˆê³¼: ì§€ì • ì‹œê°„ ì‚¬ìš©

    # Job ID (ì„ íƒì )
    job_id: Optional[str] = Form(None),  # Job ID ì¶”ê°€

    # ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œ (ìµœëŒ€ 8ê°œ)
    image_1: Optional[UploadFile] = File(None),
    image_2: Optional[UploadFile] = File(None),
    image_3: Optional[UploadFile] = File(None),
    image_4: Optional[UploadFile] = File(None),
    image_5: Optional[UploadFile] = File(None),
    image_6: Optional[UploadFile] = File(None),
    image_7: Optional[UploadFile] = File(None),
    image_8: Optional[UploadFile] = File(None),
):
    """ë¹„ë™ê¸° ì˜ìƒ ìƒì„± ìš”ì²­ - ì¦‰ì‹œ Job ID ë°˜í™˜"""
    try:
        if not JOB_QUEUE_AVAILABLE:
            raise HTTPException(
                status_code=500,
                detail="ë°°ì¹˜ ì‘ì—… ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”."
            )

        logger.info(f"ğŸš€ ë¹„ë™ê¸° ì˜ìƒ ìƒì„± ìš”ì²­: {user_email}")

        # 1. Job ID ì²˜ë¦¬: ì „ë‹¬ë°›ì€ job_id ì‚¬ìš© ë˜ëŠ” ìƒˆë¡œ ìƒì„±
        if job_id:
            logger.info(f"ğŸ†” ê¸°ì¡´ Job ID ì‚¬ìš©: {job_id}")
        else:
            job_id = str(uuid.uuid4())
            logger.info(f"ğŸ†” ìƒˆ Job ID ìƒì„±: {job_id}")

        # 2. Job í´ë” ì²˜ë¦¬: ê¸°ì¡´ í´ë” ì‚¬ìš© ë˜ëŠ” ìƒˆë¡œ ìƒì„±
        if FOLDER_MANAGER_AVAILABLE:
            try:
                # ê¸°ì¡´ job í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì‚¬ìš©
                try:
                    job_uploads_folder, job_output_folder = folder_manager.get_job_folders(job_id)
                    if os.path.exists(job_uploads_folder):
                        uploads_folder_to_use = job_uploads_folder
                        logger.info(f"ğŸ“ ê¸°ì¡´ Job í´ë” ì‚¬ìš©: {uploads_folder_to_use}")
                    else:
                        # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
                        job_uploads_folder, job_output_folder = folder_manager.create_job_folders(job_id)
                        uploads_folder_to_use = job_uploads_folder
                        logger.info(f"ğŸ“ ìƒˆ Job í´ë” ìƒì„±: {uploads_folder_to_use}")
                except Exception:
                    # get_job_folders ì‹¤íŒ¨ ì‹œ ìƒˆë¡œ ìƒì„±
                    job_uploads_folder, job_output_folder = folder_manager.create_job_folders(job_id)
                    uploads_folder_to_use = job_uploads_folder
                    logger.info(f"ğŸ“ Job í´ë” ìƒì„± ì™„ë£Œ: {uploads_folder_to_use}")
            except Exception as job_error:
                logger.warning(f"âš ï¸ Job í´ë” ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ í´ë” ì‚¬ìš©: {job_error}")
                uploads_folder_to_use = UPLOAD_FOLDER
                # ê¸°ë³¸ í´ë” ì •ë¦¬ ë° ìƒì„±
                if os.path.exists(uploads_folder_to_use):
                    shutil.rmtree(uploads_folder_to_use)
                os.makedirs(uploads_folder_to_use, exist_ok=True)
        else:
            # Folder Manager ë¯¸ì‚¬ìš© ì‹œ ê¸°ë³¸ í´ë”
            uploads_folder_to_use = UPLOAD_FOLDER
            if os.path.exists(uploads_folder_to_use):
                shutil.rmtree(uploads_folder_to_use)
            os.makedirs(uploads_folder_to_use, exist_ok=True)
            logger.info(f"ğŸ“ ê¸°ë³¸ í´ë” ì‚¬ìš©: {uploads_folder_to_use}")

        # ì—…ë¡œë“œëœ íŒŒì¼ë“¤ ì €ì¥
        uploaded_files = [
            ("image_1", image_1), ("image_2", image_2), ("image_3", image_3), ("image_4", image_4),
            ("image_5", image_5), ("image_6", image_6), ("image_7", image_7), ("image_8", image_8)
        ]

        saved_files = []
        for field_name, uploaded_file in uploaded_files:
            if uploaded_file and uploaded_file.filename:
                # íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ (1, 2, 3, 4...)
                file_number = field_name.split('_')[1]
                file_extension = uploaded_file.filename.split('.')[-1].lower()
                save_filename = f"{file_number}.{file_extension}"
                save_path = os.path.join(uploads_folder_to_use, save_filename)

                with open(save_path, "wb") as buffer:
                    shutil.copyfileobj(uploaded_file.file, buffer)

                saved_files.append(save_filename)
                logger.info(f"ğŸ“ íŒŒì¼ ì €ì¥: {save_filename}")

        # 2. ì‘ì—… íŒŒë¼ë¯¸í„° êµ¬ì„±
        video_params = {
            'content_data': content_data,
            'music_mood': music_mood,
            'image_allocation_mode': image_allocation_mode,
            'text_position': text_position,
            'text_style': text_style,
            'title_area_mode': title_area_mode,
            'selected_bgm_path': selected_bgm_path,
            'use_test_files': use_test_files,
            'uploaded_files': saved_files,
            # í°íŠ¸ íŒŒë¼ë¯¸í„° ì¶”ê°€
            'title_font': title_font,
            'body_font': body_font,
            'title_font_size': title_font_size,
            'body_font_size': body_font_size,
            # ìë§‰ ì½ì–´ì£¼ê¸° íŒŒë¼ë¯¸í„° ì¶”ê°€
            'voice_narration': voice_narration,
            # í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ íŒŒë¼ë¯¸í„° ì¶”ê°€
            'cross_dissolve': cross_dissolve,
            # ìë§‰ ì§€ì† ì‹œê°„ íŒŒë¼ë¯¸í„° ì¶”ê°€
            'subtitle_duration': subtitle_duration
        }

        # 3. ì‘ì—…ì„ íì— ì¶”ê°€ (ë¯¸ë¦¬ ìƒì„±ëœ job_id ì‚¬ìš©)
        actual_job_id = job_queue.add_job(user_email, video_params, job_id=job_id)

        # 4. Job ë¡œê¹… ì‹œìŠ¤í…œì— ë¡œê·¸ ìƒì„±
        if JOB_LOGGER_AVAILABLE:
            try:
                # JSON íŒŒì‹±
                reels_content_dict = json.loads(content_data)

                # ë¨¼ì € Job ë¡œê·¸ ìƒì„± (uploaded_filesëŠ” ë‚˜ì¤‘ì— ì—…ë°ì´íŠ¸)
                job_logger.create_job_log(
                    job_id=job_id,
                    user_email=user_email,
                    reels_content=reels_content_dict,
                    music_mood=music_mood,
                    text_position=text_position,
                    image_allocation_mode=image_allocation_mode,
                    metadata={}  # ì¼ë‹¨ ë¹ˆ metadataë¡œ ìƒì„±
                )

                # ë¯¸ë””ì–´ íŒŒì¼ë“¤ì„ assets í´ë”ì— ì €ì¥í•˜ë©´ì„œ ì •ë³´ ìˆ˜ì§‘
                saved_assets_info = []
                for i, filename in enumerate(saved_files, 1):
                    upload_file_path = os.path.join(UPLOAD_FOLDER, filename)
                    if os.path.exists(upload_file_path):
                        # íŒŒì¼ íƒ€ì… í™•ì¸ (í™•ì¥ì ê¸°ë°˜)
                        file_ext = filename.split('.')[-1].lower()
                        video_extensions = ['mp4', 'mov', 'avi', 'webm']
                        file_type = 'video' if file_ext in video_extensions else 'image'

                        # assets í´ë”ì— ì €ì¥
                        asset_path = job_logger.save_media_file(
                            job_id=job_id,
                            original_file_path=upload_file_path,
                            original_filename=filename,
                            file_type=file_type,
                            sequence_number=i
                        )

                        # assets ì •ë³´ ìˆ˜ì§‘
                        saved_assets_info.append({
                            'sequence': i,
                            'original_filename': filename,
                            'asset_path': asset_path,
                            'file_type': file_type,
                            'file_size': os.path.getsize(asset_path) if os.path.exists(asset_path) else 0
                        })

                # metadataì— assets ì •ë³´ì™€ ê¸°íƒ€ ì„¤ì • í¬í•¨
                metadata = {
                    'uploaded_files': saved_assets_info,  # assets ì €ì¥ í›„ ì •ë³´
                    'title_font': title_font,
                    'body_font': body_font,
                    'voice_narration': voice_narration,
                    'title_area_mode': title_area_mode
                }

                # metadata ì—…ë°ì´íŠ¸
                job_logger.update_job_metadata(job_id, metadata)

                logger.info(f"âœ… Job ë¡œê¹… ì‹œìŠ¤í…œì— ê¸°ë¡ ì™„ë£Œ: {job_id}")
            except Exception as log_error:
                logger.error(f"âš ï¸ Job ë¡œê¹… ì‹¤íŒ¨ (ì‘ì—…ì€ ê³„ì† ì§„í–‰): {log_error}")

        logger.info(f"âœ… ì‘ì—… íì— ì¶”ê°€ ì™„ë£Œ: {job_id}")

        return JSONResponse(
            content={
                "status": "success",
                "message": "ì˜ìƒ ìƒì„± ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ì™„ë£Œë˜ë©´ ì´ë©”ì¼ë¡œ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.",
                "job_id": job_id,
                "user_email": user_email,
                "estimated_time": "ì•½ 3-10ë¶„"
            }
        )

    except Exception as e:
        logger.error(f"âŒ ë¹„ë™ê¸° ì˜ìƒ ìƒì„± ìš”ì²­ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail=f"ì‘ì—… ìš”ì²­ ì‹¤íŒ¨: {str(e)}")

@app.get("/job-status/{job_id}")
async def get_job_status(job_id: str):
    """ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    try:
        if not JOB_QUEUE_AVAILABLE:
            raise HTTPException(status_code=500, detail="ë°°ì¹˜ ì‘ì—… ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        job_data = job_queue.get_job(job_id)
        if not job_data:
            raise HTTPException(status_code=404, detail="ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # Job ë¡œê¹… ì •ë³´ë„ í•¨ê»˜ ë°˜í™˜
        response_data = {
            "job_id": job_data['job_id'],
            "status": job_data['status'],
            "created_at": job_data['created_at'],
            "updated_at": job_data['updated_at'],
            "result": job_data.get('result'),
            "error_message": job_data.get('error_message')
        }

        # ë¡œê¹… ì‹œìŠ¤í…œì—ì„œ ì¶”ê°€ ì •ë³´ ì¡°íšŒ (ê°€ëŠ¥í•œ ê²½ìš°)
        if JOB_LOGGER_AVAILABLE:
            try:
                job_log_info = job_logger.get_job_info(job_id)
                if job_log_info:
                    response_data["detailed_info"] = {
                        "media_files": job_log_info.get('media_files', []),
                        "reels_content": job_log_info.get('reels_content', {}),
                        "metadata": job_log_info.get('metadata', {})
                    }
            except Exception as log_error:
                logger.warning(f"Job ë¡œê¹… ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {log_error}")

        return JobStatusResponse(**response_data)

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì‘ì—… ìƒíƒœ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì‘ì—… ìƒíƒœ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@app.get("/download-video")
async def download_video(token: str = Query(...)):
    """ë³´ì•ˆ ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ í†µí•œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ"""
    try:
        logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ìš”ì²­ ì‹œì‘ (ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸): token={token[:20]}...")

        if not JOB_QUEUE_AVAILABLE:
            logger.error("âŒ ë°°ì¹˜ ì‘ì—… ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€")
            raise HTTPException(status_code=500, detail="ë°°ì¹˜ ì‘ì—… ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        # í† í° ê²€ì¦
        logger.info("ğŸ” í† í° ê²€ì¦ ì‹œì‘")
        payload = email_service.verify_download_token(token)
        if not payload:
            logger.error("âŒ í† í° ê²€ì¦ ì‹¤íŒ¨")
            raise HTTPException(status_code=401, detail="ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ë§Œë£Œëœ ë‹¤ìš´ë¡œë“œ ë§í¬ì…ë‹ˆë‹¤.")

        video_path = payload.get('video_path')
        user_email = payload.get('user_email')
        logger.info(f"âœ… í† í° ê²€ì¦ ì„±ê³µ: user={user_email}, video_path={video_path}")

        # íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬ ê°œì„ 
        if os.path.isabs(video_path):
            # ì ˆëŒ€ ê²½ë¡œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            full_video_path = video_path
            logger.info(f"ğŸ“ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©: {full_video_path}")
        else:
            # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° OUTPUT_FOLDERì™€ ê²°í•©
            full_video_path = os.path.join(OUTPUT_FOLDER, video_path)
            logger.info(f"ğŸ“ ìƒëŒ€ ê²½ë¡œ ê²°í•©: {OUTPUT_FOLDER} + {video_path} = {full_video_path}")

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(full_video_path):
            logger.error(f"âŒ ì˜ìƒ íŒŒì¼ ì—†ìŒ: {full_video_path}")
            # ëŒ€ì²´ ê²½ë¡œë“¤ ì‹œë„
            basename = os.path.basename(video_path)
            alternative_path = os.path.join(OUTPUT_FOLDER, basename)
            logger.info(f"ğŸ” ëŒ€ì²´ ê²½ë¡œ í™•ì¸: {alternative_path}")

            if os.path.exists(alternative_path):
                full_video_path = alternative_path
                logger.info(f"âœ… ëŒ€ì²´ ê²½ë¡œì—ì„œ íŒŒì¼ ë°œê²¬: {full_video_path}")
            else:
                # ì¶œë ¥ í´ë”ì˜ ëª¨ë“  íŒŒì¼ ë‚˜ì—´
                try:
                    files_in_output = os.listdir(OUTPUT_FOLDER) if os.path.exists(OUTPUT_FOLDER) else []
                    logger.error(f"âŒ OUTPUT_FOLDER ë‚´ìš©: {files_in_output}")
                except Exception as list_error:
                    logger.error(f"âŒ OUTPUT_FOLDER ì ‘ê·¼ ì‹¤íŒ¨: {list_error}")
                raise HTTPException(status_code=404, detail="ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        file_size = os.path.getsize(full_video_path)
        logger.info(f"ğŸ“¥ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {user_email} â†’ {os.path.basename(video_path)} ({file_size} bytes)")

        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‘ë‹µ
        return FileResponse(
            path=full_video_path,
            filename=os.path.basename(video_path),
            media_type='video/mp4'
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@app.get("/api/download-video")
async def api_download_video(token: str = Query(...)):
    """ë³´ì•ˆ ë‹¤ìš´ë¡œë“œ ë§í¬ë¥¼ í†µí•œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ (nginx ë¼ìš°íŒ…ìš© /api ê²½ë¡œ)"""
    try:
        logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ìš”ì²­ ì‹œì‘: token={token[:20]}...")

        if not JOB_QUEUE_AVAILABLE:
            logger.error("âŒ ë°°ì¹˜ ì‘ì—… ì‹œìŠ¤í…œ ì‚¬ìš© ë¶ˆê°€")
            raise HTTPException(status_code=500, detail="ë°°ì¹˜ ì‘ì—… ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        # í† í° ê²€ì¦
        logger.info("ğŸ” í† í° ê²€ì¦ ì‹œì‘")
        payload = email_service.verify_download_token(token)
        if not payload:
            logger.error("âŒ í† í° ê²€ì¦ ì‹¤íŒ¨")
            raise HTTPException(status_code=401, detail="ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ë§Œë£Œëœ ë‹¤ìš´ë¡œë“œ ë§í¬ì…ë‹ˆë‹¤.")

        video_path = payload.get('video_path')
        user_email = payload.get('user_email')
        logger.info(f"âœ… í† í° ê²€ì¦ ì„±ê³µ: user={user_email}, video_path={video_path}")

        # íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬ ê°œì„ 
        if os.path.isabs(video_path):
            # ì ˆëŒ€ ê²½ë¡œì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ì‚¬ìš©
            full_video_path = video_path
            logger.info(f"ğŸ“ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©: {full_video_path}")
        else:
            # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° OUTPUT_FOLDERì™€ ê²°í•©
            full_video_path = os.path.join(OUTPUT_FOLDER, video_path)
            logger.info(f"ğŸ“ ìƒëŒ€ ê²½ë¡œ ê²°í•©: {OUTPUT_FOLDER} + {video_path} = {full_video_path}")

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(full_video_path):
            logger.error(f"âŒ ì˜ìƒ íŒŒì¼ ì—†ìŒ: {full_video_path}")
            # ëŒ€ì²´ ê²½ë¡œë“¤ ì‹œë„
            basename = os.path.basename(video_path)
            alternative_path = os.path.join(OUTPUT_FOLDER, basename)
            logger.info(f"ğŸ” ëŒ€ì²´ ê²½ë¡œ í™•ì¸: {alternative_path}")

            if os.path.exists(alternative_path):
                full_video_path = alternative_path
                logger.info(f"âœ… ëŒ€ì²´ ê²½ë¡œì—ì„œ íŒŒì¼ ë°œê²¬: {full_video_path}")
            else:
                # ì¶œë ¥ í´ë”ì˜ ëª¨ë“  íŒŒì¼ ë‚˜ì—´
                try:
                    files_in_output = os.listdir(OUTPUT_FOLDER) if os.path.exists(OUTPUT_FOLDER) else []
                    logger.error(f"âŒ OUTPUT_FOLDER ë‚´ìš©: {files_in_output}")
                except Exception as list_error:
                    logger.error(f"âŒ OUTPUT_FOLDER ì ‘ê·¼ ì‹¤íŒ¨: {list_error}")
                raise HTTPException(status_code=404, detail="ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        file_size = os.path.getsize(full_video_path)
        logger.info(f"ğŸ“¥ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹œì‘: {user_email} â†’ {os.path.basename(video_path)} ({file_size} bytes)")

        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì‘ë‹µ
        return FileResponse(
            path=full_video_path,
            filename=os.path.basename(video_path),
            media_type='video/mp4'
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@app.get("/api/test")
async def api_test():
    """nginx /api ë¼ìš°íŒ… í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "success",
        "message": "nginx /api ë¼ìš°íŒ…ì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤",
        "timestamp": datetime.now().isoformat(),
        "endpoint": "/api/test"
    }

@app.get("/queue-stats")
async def get_queue_stats():
    """ì‘ì—… í í†µê³„ ì¡°íšŒ (ê´€ë¦¬ìš©)"""
    try:
        if not JOB_QUEUE_AVAILABLE:
            raise HTTPException(status_code=500, detail="ë°°ì¹˜ ì‘ì—… ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        stats = job_queue.get_job_stats()
        return {"status": "success", "stats": stats}

    except Exception as e:
        logger.error(f"âŒ í í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="í í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# Job ë¡œê¹… ì‹œìŠ¤í…œ API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.get("/job-logs/{job_id}")
async def get_job_logs(job_id: str):
    """íŠ¹ì • Jobì˜ ìƒì„¸ ë¡œê·¸ ì¡°íšŒ"""
    try:
        if not JOB_LOGGER_AVAILABLE:
            raise HTTPException(status_code=500, detail="Job ë¡œê¹… ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        job_info = job_logger.get_job_info(job_id)
        if not job_info:
            raise HTTPException(status_code=404, detail="Job ë¡œê·¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        return {"status": "success", "job_info": job_info}

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Job ë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="Job ë¡œê·¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@app.get("/user-jobs/{user_email}")
async def get_user_jobs(user_email: str, limit: int = 20):
    """ì‚¬ìš©ìë³„ Job ë¡œê·¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        if not JOB_LOGGER_AVAILABLE:
            raise HTTPException(status_code=500, detail="Job ë¡œê¹… ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        jobs = job_logger.get_user_jobs(user_email, limit)
        return {"status": "success", "jobs": jobs, "total": len(jobs)}

    except Exception as e:
        logger.error(f"âŒ ì‚¬ìš©ì Job ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="ì‚¬ìš©ì Job ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@app.get("/job-statistics")
async def get_job_statistics():
    """Job ë¡œê·¸ í†µê³„ ì •ë³´ ì¡°íšŒ (ê´€ë¦¬ìš©)"""
    try:
        if not JOB_LOGGER_AVAILABLE:
            raise HTTPException(status_code=500, detail="Job ë¡œê¹… ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        stats = job_logger.get_job_statistics()
        return {"status": "success", "statistics": stats}

    except Exception as e:
        logger.error(f"âŒ Job í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        raise HTTPException(status_code=500, detail="Job í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# Job í´ë” ê´€ë¦¬ API ì—”ë“œí¬ì¸íŠ¸ë“¤
@app.post("/create-job-folder")
async def create_job_folder(request: CreateJobFolderRequest):
    """Jobë³„ ê²©ë¦¬ëœ í´ë” ìƒì„±"""
    try:
        if not FOLDER_MANAGER_AVAILABLE:
            raise HTTPException(status_code=500, detail="í´ë” ê´€ë¦¬ ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        logger.info(f"ğŸš€ Job í´ë” ìƒì„± ìš”ì²­: {request.job_id}")

        # Job í´ë” ìƒì„±
        uploads_folder, output_folder = folder_manager.create_job_folders(request.job_id)

        logger.info(f"âœ… Job í´ë” ìƒì„± ì™„ë£Œ: {request.job_id}")
        logger.info(f"   ğŸ“ uploads: {uploads_folder}")
        logger.info(f"   ğŸ“ output: {output_folder}")

        return CreateJobFolderResponse(
            status="success",
            message="Job í´ë”ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.",
            job_id=request.job_id,
            uploads_folder=uploads_folder,
            output_folder=output_folder
        )

    except Exception as e:
        logger.error(f"âŒ Job í´ë” ìƒì„± ì‹¤íŒ¨: {request.job_id} - {e}")
        raise HTTPException(status_code=500, detail=f"Job í´ë” ìƒì„± ì‹¤íŒ¨: {str(e)}")

@app.post("/cleanup-job-folder")
async def cleanup_job_folder(request: CleanupJobFolderRequest):
    """Job ì™„ë£Œ í›„ ì„ì‹œ í´ë” ì •ë¦¬"""
    try:
        if not FOLDER_MANAGER_AVAILABLE:
            raise HTTPException(status_code=500, detail="í´ë” ê´€ë¦¬ ì‹œìŠ¤í…œì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")

        logger.info(f"ğŸ—‘ï¸ Job í´ë” ì •ë¦¬ ìš”ì²­: {request.job_id} (keep_output: {request.keep_output})")

        # Job í´ë” ì •ë¦¬
        cleaned = folder_manager.cleanup_job_folders(request.job_id, request.keep_output)

        if cleaned:
            logger.info(f"âœ… Job í´ë” ì •ë¦¬ ì™„ë£Œ: {request.job_id}")
            return CleanupJobFolderResponse(
                status="success",
                message="Job í´ë”ê°€ ì„±ê³µì ìœ¼ë¡œ ì •ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤.",
                job_id=request.job_id,
                cleaned=True
            )
        else:
            logger.warning(f"âš ï¸ Job í´ë” ì •ë¦¬ ë¶€ë¶„ ì‹¤íŒ¨: {request.job_id}")
            return CleanupJobFolderResponse(
                status="warning",
                message="Job í´ë” ì •ë¦¬ê°€ ë¶€ë¶„ì ìœ¼ë¡œë§Œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                job_id=request.job_id,
                cleaned=False
            )

    except Exception as e:
        logger.error(f"âŒ Job í´ë” ì •ë¦¬ ì‹¤íŒ¨: {request.job_id} - {e}")
        raise HTTPException(status_code=500, detail=f"Job í´ë” ì •ë¦¬ ì‹¤íŒ¨: {str(e)}")

# ì •ì  íŒŒì¼ ì„œë¹™
app.mount("/bgm", StaticFiles(directory=BGM_FOLDER), name="bgm")
app.mount("/videos", StaticFiles(directory=OUTPUT_FOLDER), name="videos")

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8080)