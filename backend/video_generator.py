import os
import requests
from PIL import Image, ImageDraw, ImageFont, ImageOps
from moviepy.editor import *
import numpy as np
import uuid
import tempfile
from gtts import gTTS
import re
import base64
import json
import random
import math
import logging
from datetime import datetime

# í†µí•© ë¡œê¹… ì‹œìŠ¤í…œ import
from utils.logger_config import get_logger
logger = get_logger('video_generator')

# HEIC íŒŒì¼ ì§€ì›ì„ ìœ„í•œ pillow-heif
try:
    from pillow_heif import register_heif_opener
    register_heif_opener()
    logger.info("âœ… HEIC íŒŒì¼ ì§€ì› í™œì„±í™”")
except ImportError:
    logger.warning("âš ï¸ pillow-heif ë¯¸ì„¤ì¹˜ - HEIC íŒŒì¼ ì§€ì› ë¶ˆê°€")

class VideoGenerator:
    def __init__(self):
        # í†µí•© ë¡œê¹… ì‹œìŠ¤í…œ ì‚¬ìš© (ë” ì´ìƒ ê°œë³„ ë¡œê·¸ íŒŒì¼ ìƒì„± ì•ˆí•¨)
        logger.info("ğŸ¬ VideoGenerator ì´ˆê¸°í™”")

        self.video_width = 504
        self.video_height = 890  # ì‡¼ì¸ /ë¦´ìŠ¤ í•´ìƒë„ (504x890)
        self.fps = 30
        self.font_path = os.path.join(os.path.dirname(__file__), "font", "BMYEONSUNG_otf.otf")

        # Naver Clova Voice ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        self.naver_client_id = os.getenv('NAVER_CLIENT_ID')
        self.naver_client_secret = os.getenv('NAVER_CLIENT_SECRET')

        # Microsoft Azure Speech ì„¤ì •
        self.azure_speech_key = os.getenv('AZURE_SPEECH_KEY')
        self.azure_speech_region = os.getenv('AZURE_SPEECH_REGION', 'koreacentral')

        # ë°œìŒ ì‚¬ì „ ì´ˆê¸°í™” (ë‹¤êµ­ì–´ â†’ í•œê¸€ ë°œìŒ ë³€í™˜)
        from utils.pronunciation_dict import PronunciationDictionary
        self.pronunciation_dict = PronunciationDictionary()
        logger.info("ğŸ“š ë°œìŒ ì‚¬ì „ ì´ˆê¸°í™” ì™„ë£Œ")

        # ì™¸ë¶€ ì‚¬ì „ íŒŒì¼ì´ ìˆìœ¼ë©´ ë¡œë“œ (ì„ íƒì‚¬í•­)
        custom_dict_path = os.path.join(os.path.dirname(__file__), "pronunciation_dict.json")
        if os.path.exists(custom_dict_path):
            self.pronunciation_dict.load_from_file(custom_dict_path)
            logger.info(f"ğŸ“š ì»¤ìŠ¤í…€ ë°œìŒ ì‚¬ì „ ë¡œë“œ: {custom_dict_path}")
        
    def get_emoji_font(self):
        """ì´ëª¨ì§€ ì§€ì› í°íŠ¸ ê²½ë¡œ ë°˜í™˜"""
        emoji_fonts = [
            "/usr/share/fonts/truetype/noto/NotoColorEmoji.ttf",
            "/System/Library/Fonts/Apple Color Emoji.ttc",
            "/Windows/Fonts/seguiemj.ttf",
            "/usr/share/fonts/truetype/noto/NotoEmoji-Regular.ttf"
        ]
        
        for font_path in emoji_fonts:
            if os.path.exists(font_path):
                return font_path
        return None
    
    def has_emoji(self, text):
        """í…ìŠ¤íŠ¸ì— ì´ëª¨ì§€ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        emoji_pattern = re.compile(
            "[\U0001F600-\U0001F64F"  # ê°ì • í‘œí˜„
            "\U0001F300-\U0001F5FF"  # ê¸°í˜¸ ë° ê·¸ë¦¼ë¬¸ì
            "\U0001F680-\U0001F6FF"  # êµí†µ ë° ì§€ë„ ê¸°í˜¸
            "\U0001F1E0-\U0001F1FF"  # êµ­ê¸°
            "\U00002600-\U000026FF"  # ê¸°íƒ€ ê¸°í˜¸
            "\U00002700-\U000027BF"  # ì¥ì‹ ê¸°í˜¸
            "\U0001F900-\U0001F9FF"  # ì¶”ê°€ ê·¸ë¦¼ë¬¸ì
            "\U0001FA70-\U0001FAFF"  # í™•ì¥ëœ ê·¸ë¦¼ë¬¸ì-A
            "]+", re.UNICODE)
        return emoji_pattern.search(text) is not None
    
    def split_text_and_emoji(self, text):
        """í…ìŠ¤íŠ¸ì™€ ì´ëª¨ì§€ë¥¼ ë¶„ë¦¬"""
        emoji_pattern = re.compile(
            "[\U0001F600-\U0001F64F"
            "\U0001F300-\U0001F5FF"
            "\U0001F680-\U0001F6FF"
            "\U0001F1E0-\U0001F1FF"
            "\U00002600-\U000026FF"
            "\U00002700-\U000027BF"
            "\U0001F900-\U0001F9FF"
            "\U0001FA70-\U0001FAFF"
            "]", re.UNICODE)
        
        parts = []
        last_end = 0
        
        for match in emoji_pattern.finditer(text):
            if match.start() > last_end:
                parts.append(('text', text[last_end:match.start()]))
            parts.append(('emoji', match.group()))
            last_end = match.end()
        
        if last_end < len(text):
            parts.append(('text', text[last_end:]))
        
        return parts
    
    def draw_text_with_emoji(self, draw, text, x, y, text_font, emoji_font, color):
        """í…ìŠ¤íŠ¸ì™€ ì´ëª¨ì§€ë¥¼ í•¨ê»˜ ë Œë”ë§"""
        parts = self.split_text_and_emoji(text)
        current_x = x
        
        for part_type, content in parts:
            if part_type == 'text' and content.strip():
                draw.text((current_x, y), content, font=text_font, fill=color)
                bbox = draw.textbbox((0, 0), content, font=text_font)
                current_x += bbox[2] - bbox[0]
            elif part_type == 'emoji':
                # ì´ëª¨ì§€ í°íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ë¡œ ì‹œë„
                if emoji_font:
                    try:
                        draw.text((current_x, y + 2), content, font=emoji_font, fill=color)
                        bbox = draw.textbbox((0, 0), content, font=emoji_font)
                    except:
                        # ì´ëª¨ì§€ í°íŠ¸ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ í°íŠ¸ë¡œ ì‹œë„
                        draw.text((current_x, y), content, font=text_font, fill=color)
                        bbox = draw.textbbox((0, 0), content, font=text_font)
                else:
                    # ì´ëª¨ì§€ í°íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ë¡œ ì‹œë„
                    draw.text((current_x, y), content, font=text_font, fill=color)
                    bbox = draw.textbbox((0, 0), content, font=text_font)
                
                current_x += bbox[2] - bbox[0]
        
    def create_fallback_image(self, width=1920, height=1080, color_index=0):
        """ì¸í„°ë„· ì—°ê²° ì—†ì´ ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ë‹¤ì–‘í•œ ìƒ‰ìƒ íŒ”ë ˆíŠ¸
            colors = [
                (255, 87, 51),   # ì£¼í™©ìƒ‰
                (51, 255, 87),   # ì´ˆë¡ìƒ‰  
                (51, 87, 255),   # íŒŒë€ìƒ‰
                (255, 51, 245),  # ìì£¼ìƒ‰
                (255, 195, 0),   # ë…¸ë€ìƒ‰
                (0, 195, 255),   # í•˜ëŠ˜ìƒ‰
            ]
            
            color = colors[color_index % len(colors)]
            
            # ì´ë¯¸ì§€ ìƒì„±
            img = Image.new('RGB', (width, height), color=color)
            draw = ImageDraw.Draw(img)
            
            # í…ìŠ¤íŠ¸ ì¶”ê°€
            try:
                font = ImageFont.truetype(self.font_path, 60)
            except:
                font = ImageFont.load_default()
            
            text = f"ë°°ê²½ ì´ë¯¸ì§€ {color_index + 1}"
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            
            x = (width - text_width) // 2
            y = (height - text_height) // 2
            
            # í…ìŠ¤íŠ¸ ê·¸ë¦¼ì
            draw.text((x + 2, y + 2), text, font=font, fill=(0, 0, 0))
            # í°ìƒ‰ í…ìŠ¤íŠ¸
            draw.text((x, y), text, font=font, fill=(255, 255, 255))
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
            img.save(temp_file.name, "JPEG", quality=85)
            temp_file.close()
            
            print(f"ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {temp_file.name}")
            return temp_file.name
            
        except Exception as e:
            print(f"ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def download_image(self, image_url):
        """ì´ë¯¸ì§€ URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (fallback í¬í•¨)"""
        try:
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„: {image_url}")
            
            # íƒ€ì„ì•„ì›ƒê³¼ í—¤ë” ì¶”ê°€
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(image_url, headers=headers, timeout=10)  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
            
            print(f"ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            response.raise_for_status()
            
            # ì´ë¯¸ì§€ ì½˜í…ì¸  ìœ íš¨ì„± ê²€ì‚¬
            if len(response.content) < 1000:
                raise Exception(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {len(response.content)} bytes")
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
            temp_file.write(response.content)
            temp_file.close()
            
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {temp_file.name} ({len(response.content)} bytes)")
            return temp_file.name
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({str(e)}), ê¸°ë³¸ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´")
            # URLì—ì„œ ìƒ‰ìƒ ì¸ë±ìŠ¤ ì¶”ì¶œ ì‹œë„
            color_index = 0
            try:
                if "Image+1" in image_url or "random=1" in image_url:
                    color_index = 0
                elif "Image+2" in image_url or "random=2" in image_url:
                    color_index = 1
                elif "Image+3" in image_url or "random=3" in image_url:
                    color_index = 2
                elif "Image+4" in image_url or "random=4" in image_url:
                    color_index = 3
            except:
                pass
                
            fallback_image = self.create_fallback_image(1920, 1080, color_index)
            if fallback_image:
                return fallback_image
            else:
                raise Exception(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ëª¨ë‘ ì‹¤íŒ¨: {str(e)}")
    
    def create_title_image(self, title, width, height, title_font="BMYEONSUNG_otf.otf", title_font_size=42):
        """ì œëª© ì´ë¯¸ì§€ ìƒì„± - ì§€ì • ì˜ì—­(50,65)~(444,200)ì— ì•„ë˜ ì •ë ¬"""
        # ê²€ì€ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± (ì „ì²´ íƒ€ì´í‹€ ì˜ì—­)
        img = Image.new('RGB', (width, height), color='black')
        draw = ImageDraw.Draw(img)

        # íƒ€ì´í‹€ í…ìŠ¤íŠ¸ ì˜ì—­ ì •ì˜: (50, 65) ~ (444, 200)
        title_left = 50
        title_top = 65
        title_right = 444  # ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­: (50,65) ~ (444,200)
        title_bottom = 200  # í…ìŠ¤íŠ¸ ì˜ì—­ í•˜ë‹¨ì„ 200ìœ¼ë¡œ ì œí•œ (í•˜ë‹¨ 20px ì—¬ë°± í™•ë³´)
        title_width = title_right - title_left  # 394px (444-50)
        title_height = title_bottom - title_top  # 135px (200-65)

        # íƒ€ì´í‹€ í°íŠ¸ ì„¤ì •
        title_font_path = os.path.join(os.path.dirname(__file__), "font", title_font)
        try:
            font = ImageFont.truetype(title_font_path, title_font_size)

            # Variable í°íŠ¸ì˜ ê²½ìš° êµµê¸° ì„¤ì •
            if 'variable' in title_font.lower() or 'vf' in title_font.lower():
                try:
                    weight = 600  # íƒ€ì´í‹€ì€ SemiBold
                    font.set_variation_by_name('wght', weight)
                    print(f"âœ… Variable íƒ€ì´í‹€ í°íŠ¸ ë¡œë“œ ì„±ê³µ: {title_font} ({title_font_size}pt, weight={weight})")
                except Exception as var_error:
                    print(f"âš ï¸ Variable í°íŠ¸ êµµê¸° ì„¤ì • ì‹¤íŒ¨ (ê¸°ë³¸ êµµê¸° ì‚¬ìš©): {var_error}")
            else:
                print(f"âœ… íƒ€ì´í‹€ í°íŠ¸ ë¡œë“œ ì„±ê³µ: {title_font} ({title_font_size}pt)")
        except Exception as e:
            print(f"âŒ íƒ€ì´í‹€ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ({title_font}): {e}")
            # ê¸°ë³¸ í°íŠ¸ë¡œ fallback
            try:
                font = ImageFont.truetype(self.font_path, title_font_size)
                print(f"âœ… ê¸°ë³¸ íƒ€ì´í‹€ í°íŠ¸ë¡œ fallback: {self.font_path}")
            except Exception as e2:
                print(f"âŒ ê¸°ë³¸ íƒ€ì´í‹€ í°íŠ¸ë„ ì‹¤íŒ¨: {e2}")
                try:
                    font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", title_font_size)
                except:
                    font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸° (íƒ€ì´í‹€ ì˜ì—­ í­ì— ë§ì¶°)
        words = title.split(' ')
        lines = []
        current_line = ""
        
        for word in words:
            test_line = current_line + " " + word if current_line else word
            bbox = draw.textbbox((0, 0), test_line, font=font)
            if bbox[2] - bbox[0] < title_width - 20:  # íƒ€ì´í‹€ ì˜ì—­ ë‚´ ì—¬ë°± 10pxì”©
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word
        
        if current_line:
            lines.append(current_line)
        
        # ì´ëª¨ì§€ í°íŠ¸ ì¤€ë¹„ (ì œëª© í°íŠ¸ í¬ê¸°ì— ë§ì¶¤)
        emoji_font_path = self.get_emoji_font()
        emoji_font = None
        if emoji_font_path:
            try:
                emoji_font = ImageFont.truetype(emoji_font_path, 44)  # 22 â†’ 44ë¡œ 2ë°° ì¦ê°€
            except:
                emoji_font = None
        
        # í…ìŠ¤íŠ¸ ì•„ë˜ ì •ë ¬ (íƒ€ì´í‹€ ì˜ì—­ í•˜ë‹¨ì—ì„œ ìœ„ë¡œ ë°°ì¹˜)
        line_height = 50  # 48px í°íŠ¸ì— ë§ì¶˜ ì ì • ì¤„ê°„ê²©
        total_text_height = len(lines) * line_height
        
        # ì•„ë˜ ì •ë ¬: íƒ€ì´í‹€ ì˜ì—­ í•˜ë‹¨ì—ì„œ í…ìŠ¤íŠ¸ ë†’ì´ë§Œí¼ ìœ„ë¡œ
        start_y = title_bottom - total_text_height - 5  # ì•ˆì „ ì—¬ë°± 5px
        
        print(f"ğŸ“ íƒ€ì´í‹€ ë°°ì¹˜: ì˜ì—­({title_left},{title_top})~({title_right},{title_bottom})")
        print(f"ğŸ“ í…ìŠ¤íŠ¸ ì‹œì‘: Y={start_y}, ì¤„ìˆ˜={len(lines)}, ì „ì²´ë†’ì´={total_text_height}px")
        
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            
            # X ì¢Œí‘œ: íƒ€ì´í‹€ ì˜ì—­ ë‚´ ì¤‘ì•™ ì •ë ¬
            x = title_left + (title_width - text_width) // 2
            y = start_y + i * line_height
            
            # íƒ€ì´í‹€ ì˜ì—­ ë²”ìœ„ ì²´í¬
            if y < title_top:
                y = title_top + 10  # ìµœì†Œ ìƒë‹¨ ì—¬ë°± í™•ë³´
            
            # í…ìŠ¤íŠ¸ì˜ ì‹¤ì œ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚° (ë Œë”ë§ ì „ í™•ì¸)
            actual_bbox = draw.textbbox((x, y), line, font=font)
            text_bottom = actual_bbox[3]  # ì‹¤ì œ í…ìŠ¤íŠ¸ í•˜ë‹¨ ìœ„ì¹˜
            
            print(f"ğŸ“ ì¤„ {i+1}: '{line}' at ({x}, {y})")
            print(f"ğŸ“ ì‹¤ì œ í…ìŠ¤íŠ¸ ë°”ìš´ë”©ë°•ìŠ¤: {actual_bbox}")
            print(f"ğŸ“ í…ìŠ¤íŠ¸ í•˜ë‹¨ ìœ„ì¹˜: {text_bottom}, ì˜ì—­ í•˜ë‹¨: {title_bottom}")
            
            if text_bottom > title_bottom:
                print(f"âš ï¸  ê²½ê³ : í…ìŠ¤íŠ¸ê°€ ì˜ì—­ì„ {text_bottom - title_bottom}px ì´ˆê³¼!")
            
            # ì¼ë‹¨ ê¸°ë³¸ í°íŠ¸ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§ (ì´ëª¨ì§€ í¬í•¨)
            try:
                draw.text((x, y), line, font=font, fill='white')
            except Exception as e:
                print(f"í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
                # í´ë°±ìœ¼ë¡œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                default_font = ImageFont.load_default()
                draw.text((x, y), line, font=default_font, fill='white')
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
        img.save(temp_file.name, "PNG")
        temp_file.close()
        
        return temp_file.name
    
    def create_text_image(self, text, width, height, text_position="bottom", text_style="outline", is_title=False, title_font="BMYEONSUNG_otf.otf", body_font="BMYEONSUNG_otf.otf", title_area_mode="keep", title_font_size=42, body_font_size=36):
        """í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (ë°°ê²½ ë°•ìŠ¤ í¬í•¨)"""
        # íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
        img = Image.new('RGBA', (width, height), color=(0, 0, 0, 0))
        draw = ImageDraw.Draw(img)

        # í°íŠ¸ ì„ íƒ (íƒ€ì´í‹€/ë°”ë”” êµ¬ë¶„)
        selected_font = title_font if is_title else body_font
        font_path = os.path.join(os.path.dirname(__file__), "font", selected_font)

        # í°íŠ¸ í¬ê¸° ì„¤ì • (ì‚¬ìš©ì ì§€ì • í¬ê¸° ìš°ì„ , white_backgroundëŠ” 2pt ì‘ê²Œ)
        # ìµœì†Œ 12pt ë³´ì¥í•˜ì—¬ PIL "font size must be greater than 0" ì—ëŸ¬ ë°©ì§€
        if text_style == "white_background":
            # white_background ìŠ¤íƒ€ì¼ì€ 2í¬ì¸íŠ¸ ì‘ê²Œ (ìµœì†Œ 12pt ë³´ì¥)
            font_size = max(12, (title_font_size - 2)) if is_title else max(12, (body_font_size - 2))
        else:
            # ì¼ë°˜ ìŠ¤íƒ€ì¼ì€ ì‚¬ìš©ì ì§€ì • í¬ê¸° ì‚¬ìš© (ìµœì†Œ 12pt ë³´ì¥)
            font_size = max(12, title_font_size) if is_title else max(12, body_font_size)

        # í•œê¸€ í°íŠ¸ ì„¤ì •
        try:
            font = ImageFont.truetype(font_path, font_size)

            # Variable í°íŠ¸ì˜ ê²½ìš° êµµê¸° ì„¤ì • (Pretendard Variable ë“±)
            if 'variable' in selected_font.lower() or 'vf' in selected_font.lower():
                try:
                    # Variable í°íŠ¸ì˜ weight ì„¤ì • (400=Regular, 600=SemiBold, 700=Bold)
                    weight = 600 if is_title else 500  # íƒ€ì´í‹€ì€ SemiBold, ë³¸ë¬¸ì€ Medium
                    font.set_variation_by_name('wght', weight)
                    print(f"âœ… Variable í°íŠ¸ êµµê¸° ì„¤ì •: {selected_font} ({font_size}pt, weight={weight})")
                except Exception as var_error:
                    print(f"âš ï¸ Variable í°íŠ¸ êµµê¸° ì„¤ì • ì‹¤íŒ¨ (ê¸°ë³¸ êµµê¸° ì‚¬ìš©): {var_error}")
            else:
                print(f"âœ… í°íŠ¸ ë¡œë“œ ì„±ê³µ: {selected_font} ({font_size}pt)")
        except Exception as e:
            print(f"âŒ ì‚¬ìš©ì í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ({selected_font}): {e}")
            # ê¸°ë³¸ í°íŠ¸ë¡œ fallback
            try:
                font = ImageFont.truetype(self.font_path, font_size)
                print(f"âœ… ê¸°ë³¸ í°íŠ¸ë¡œ fallback: {self.font_path}")
            except Exception as e2:
                print(f"âŒ ê¸°ë³¸ í°íŠ¸ë„ ì‹¤íŒ¨: {e2}")
                try:
                    font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", font_size)
                except:
                    font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
        # ë³¸ë¬¸ì€ ìº”ë²„ìŠ¤ í­ì˜ 70%ë§Œ ì‚¬ìš© (íƒ€ì´í‹€ì€ ë³„ë„ ì²˜ë¦¬)
        if is_title:
            max_text_width = width - 60  # íƒ€ì´í‹€: ì¢Œìš° 30px ì—¬ë°±
        else:
            max_text_width = int(width * 0.70)  # ë³¸ë¬¸: ìº”ë²„ìŠ¤ í­ì˜ 70%ë§Œ ì‚¬ìš©

        words = text.split(' ')
        lines = []
        current_line = ""

        for word in words:
            test_line = current_line + " " + word if current_line else word
            bbox = draw.textbbox((0, 0), test_line, font=font)
            if bbox[2] - bbox[0] < max_text_width:
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word

        if current_line:
            lines.append(current_line)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ë°•ìŠ¤ í¬ê¸° ê³„ì‚° (í°íŠ¸ í¬ê¸°ì— ë¹„ë¡€í•˜ëŠ” ì¤„ê°„ê²©)
        # í°íŠ¸ í¬ê¸° * 1.11 = 36pt â†’ 40px, 26pt â†’ 29px
        line_height = max(font_size + 4, int(font_size * 1.11))
        total_height = len(lines) * line_height
        padding = 20  # íŒ¨ë”© ì¡°ì •
        
        # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚° (ìƒˆë¡œìš´ ì˜ì—­ êµ¬ì„±)
        # ì „ì²´ í•´ìƒë„: 504x890, íƒ€ì´í‹€ ì˜ì—­: 220px
        # ìƒë‹¨ í…ìŠ¤íŠ¸ ì˜ì—­: 340-520 (ì¤‘ì•™: 430px)
        # í•˜ë‹¨ í…ìŠ¤íŠ¸ ì˜ì—­: 520-700 (ì¤‘ì•™: 610px)

        title_height = 220  # íƒ€ì´í‹€ ì˜ì—­ ë†’ì´ (ê³ ì •)

        if text_position == "top":
            # ìƒë‹¨ í…ìŠ¤íŠ¸ ì˜ì—­ ì¤‘ì•™: 340-520 (ì¤‘ì•™ 430px)
            zone_center_y = 430
            start_y = zone_center_y - (total_height // 2)
        elif text_position == "bottom-edge":
            # ìµœí•˜ë‹¨: ë°”ë‹¥ì—ì„œ 80px ìœ„
            # íƒ€ì´í‹€ ìœ ì§€ ëª¨ë“œ: 890px ê¸°ì¤€ (ì „ì²´ ë†’ì´)
            # íƒ€ì´í‹€ ì œê±° ëª¨ë“œ: 890px ê¸°ì¤€ (ì „ì²´ ë†’ì´ ë™ì¼)
            start_y = 890 - 80 - total_height
        else:  # bottom (middleë„ bottomê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬)
            # í•˜ë‹¨ í…ìŠ¤íŠ¸ ì˜ì—­ ì¤‘ì•™: 520-700 (ì¤‘ì•™ 610px)
            zone_center_y = 610
            start_y = zone_center_y - (total_height // 2)

        # ìµœì†Œê°’ ë³´ì¥ (íƒ€ì´í‹€ ì˜ì—­ ì¹¨ë²” ë°©ì§€) - bottom-edgeëŠ” ì˜ˆì™¸
        if text_position != "bottom-edge":
            start_y = max(start_y, title_height + padding)
        
        # ì´ëª¨ì§€ í°íŠ¸ ì¤€ë¹„ (ë³¸ë¬¸ í°íŠ¸ í¬ê¸°ì— ë§ì¶¤)
        emoji_font_path = self.get_emoji_font()
        emoji_font = None
        if emoji_font_path:
            try:
                emoji_font = ImageFont.truetype(emoji_font_path, 32)  # 36pt ë³¸ë¬¸ì— ë§ì¶˜ ì´ëª¨ì§€ í¬ê¸°
            except:
                emoji_font = None
        
        # text_styleì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ë Œë”ë§ (font_size íŒŒë¼ë¯¸í„° ì „ë‹¬)
        if text_style == "background":
            # ë°˜íˆ¬ëª… ë°°ê²½ ìŠ¤íƒ€ì¼ (í°íŠ¸ í¬ê¸° ë¹„ë¡€ íŒ¨ë”©)
            self._render_text_with_background(draw, lines, font, emoji_font, width, start_y, line_height, font_size)
        elif text_style == "white_background":
            # í°ìƒ‰ ë°˜íˆ¬ëª… ë°°ê²½ + ê²€ì€ìƒ‰ ê¸€ì + ë‘¥ê·¼ ëª¨ì„œë¦¬ (í°íŠ¸ í¬ê¸° ë¹„ë¡€)
            self._render_text_with_white_background(draw, lines, font, emoji_font, width, start_y, line_height, font_size)
        elif text_style == "black_text_white_outline":
            # ê²€ì€ìƒ‰ ê¸€ì”¨ + í°ìƒ‰ ì™¸ê³½ì„ 
            self._render_text_with_black_text_white_outline(draw, lines, font, emoji_font, width, start_y, line_height, font_size)
        else:
            # ì™¸ê³½ì„  ìŠ¤íƒ€ì¼ (ê¸°ë³¸ê°’)
            self._render_text_with_outline(draw, lines, font, emoji_font, width, start_y, line_height, font_size)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
        img.save(temp_file.name, "PNG")
        temp_file.close()
        
        return temp_file.name
    
    def _render_text_with_outline(self, draw, lines, font, emoji_font, width, start_y, line_height, font_size):
        """ì™¸ê³½ì„  ìŠ¤íƒ€ì¼ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§ (ê¸°ì¡´ ë°©ì‹)"""
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (width - text_width) // 2
            y = start_y + i * line_height
            
            # í…ìŠ¤íŠ¸ ë Œë”ë§ (ë¶€ë“œëŸ¬ìš´ ì™¸ê³½ì„  íš¨ê³¼)
            try:
                # ë” ë¶€ë“œëŸ¬ìš´ ì™¸ê³½ì„  (3px ë‘ê»˜, 1.5ë°° ê°•í™”)
                outline_positions = [
                    (-3, -3), (-3, -2), (-3, -1), (-3, 0), (-3, 1), (-3, 2), (-3, 3),
                    (-2, -3), (-2, -2), (-2, -1), (-2, 0), (-2, 1), (-2, 2), (-2, 3),
                    (-1, -3), (-1, -2), (-1, -1), (-1, 0), (-1, 1), (-1, 2), (-1, 3),
                    (0, -3), (0, -2), (0, -1),            (0, 1), (0, 2), (0, 3),
                    (1, -3), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3),
                    (2, -3), (2, -2), (2, -1), (2, 0), (2, 1), (2, 2), (2, 3),
                    (3, -3), (3, -2), (3, -1), (3, 0), (3, 1), (3, 2), (3, 3)
                ]
                
                # ê²€ì€ìƒ‰ ì™¸ê³½ì„  ê·¸ë¦¬ê¸°
                for dx, dy in outline_positions:
                    draw.text((x + dx, y + dy), line, font=font, fill='black')
                
                # í°ìƒ‰ í…ìŠ¤íŠ¸ (ì¤‘ì•™)
                draw.text((x, y), line, font=font, fill='white')
                
            except Exception as e:
                print(f"ë³¸ë¬¸ í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
                # í´ë°±: ê¸°ë³¸ ì™¸ê³½ì„ 
                for dx in [-1, 0, 1]:
                    for dy in [-1, 0, 1]:
                        if dx != 0 or dy != 0:
                            draw.text((x + dx, y + dy), line, font=font, fill='black')
                draw.text((x, y), line, font=font, fill='white')
    
    def _render_text_with_background(self, draw, lines, font, emoji_font, width, start_y, line_height, font_size):
        """ë°˜íˆ¬ëª… ë°°ê²½ ìŠ¤íƒ€ì¼ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§ (í°íŠ¸ í¬ê¸° ë¹„ë¡€ íŒ¨ë”©)"""
        # ì „ì²´ í…ìŠ¤íŠ¸ ì˜ì—­ í¬ê¸° ê³„ì‚°
        max_text_width = 0
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            if text_width > max_text_width:
                max_text_width = text_width

        # ë°°ê²½ ë°•ìŠ¤ í¬ê¸°ì™€ ìœ„ì¹˜ ê³„ì‚° (í°íŠ¸ í¬ê¸°ì— ë¹„ë¡€)
        # 36pt ê¸°ì¤€: padding_x=15px (36*0.42=15.12), padding_y=8px (36*0.22=7.92)
        padding_x = max(10, int(font_size * 0.42))  # ìµœì†Œ 10px
        padding_y = max(6, int(font_size * 0.22))   # ìµœì†Œ 6px
        background_width = max_text_width + padding_x * 2
        background_height = len(lines) * line_height + padding_y * 2
        
        background_x = (width - background_width) // 2
        background_y = start_y - padding_y
        
        # ë°˜íˆ¬ëª… ê²€ì€ ë°°ê²½ ì§ì ‘ ê·¸ë¦¬ê¸°
        draw.rectangle(
            [background_x, background_y, background_x + background_width, background_y + background_height],
            fill=(0, 0, 0, 178)  # ê²€ì€ìƒ‰ 70% íˆ¬ëª…ë„
        )
        
        # í…ìŠ¤íŠ¸ ë Œë”ë§ (ë°°ê²½ ìœ„ì— í°ìƒ‰ í…ìŠ¤íŠ¸)
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            # ë°°ê²½ ë°•ìŠ¤ ë‚´ë¶€ ì¤‘ì•™ ì •ë ¬
            x = background_x + (background_width - text_width) // 2
            y = start_y + i * line_height

            # í°ìƒ‰ í…ìŠ¤íŠ¸ (ë°°ê²½ì´ ìˆìœ¼ë¯€ë¡œ ì™¸ê³½ì„  ë¶ˆí•„ìš”)
            draw.text((x, y), line, font=font, fill='white')

    def _render_text_with_white_background(self, draw, lines, font, emoji_font, width, start_y, line_height, font_size):
        """í°ìƒ‰ ë°˜íˆ¬ëª… ë°°ê²½ + ê²€ì€ìƒ‰ ê¸€ì + ë‘¥ê·¼ ëª¨ì„œë¦¬ ìŠ¤íƒ€ì¼ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§ (í°íŠ¸ í¬ê¸° ë¹„ë¡€)"""
        # ì „ì²´ í…ìŠ¤íŠ¸ ì˜ì—­ í¬ê¸° ê³„ì‚°
        max_text_width = 0
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            if text_width > max_text_width:
                max_text_width = text_width

        # ë°°ê²½ ë°•ìŠ¤ í¬ê¸°ì™€ ìœ„ì¹˜ ê³„ì‚° (í°íŠ¸ í¬ê¸°ì— ë¹„ë¡€)
        # 36pt ê¸°ì¤€: padding_x=15px, padding_y=8px
        padding_x = max(10, int(font_size * 0.42))  # ìµœì†Œ 10px
        padding_y = max(6, int(font_size * 0.22))   # ìµœì†Œ 6px
        background_width = max_text_width + padding_x * 2
        background_height = len(lines) * line_height + padding_y * 2

        background_x = (width - background_width) // 2
        background_y = start_y - padding_y

        # ë‘¥ê·¼ ëª¨ì„œë¦¬ í°ìƒ‰ ë°˜íˆ¬ëª… ë°°ê²½ ê·¸ë¦¬ê¸°
        # ë‘¥ê·¼ ëª¨ì„œë¦¬ ë°˜ì§€ë¦„ (í°íŠ¸ í¬ê¸°ì— ë¹„ë¡€: 36pt â†’ 12px)
        corner_radius = max(8, int(font_size * 0.33))

        # ë°˜íˆ¬ëª… í°ìƒ‰ ë°°ê²½ (íˆ¬ëª…ë„ 80%)
        # PILì—ì„œ ë‘¥ê·¼ ì‚¬ê°í˜•ì„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜
        def draw_rounded_rectangle(draw, xy, radius, fill):
            x1, y1, x2, y2 = xy
            # ë„¤ ëª¨ì„œë¦¬ì˜ ì› ê·¸ë¦¬ê¸°
            draw.ellipse([x1, y1, x1 + radius*2, y1 + radius*2], fill=fill)  # ì™¼ìª½ ìœ„
            draw.ellipse([x2 - radius*2, y1, x2, y1 + radius*2], fill=fill)  # ì˜¤ë¥¸ìª½ ìœ„
            draw.ellipse([x1, y2 - radius*2, x1 + radius*2, y2], fill=fill)  # ì™¼ìª½ ì•„ë˜
            draw.ellipse([x2 - radius*2, y2 - radius*2, x2, y2], fill=fill)  # ì˜¤ë¥¸ìª½ ì•„ë˜

            # ì¤‘ì•™ ì‚¬ê°í˜•ë“¤ ê·¸ë¦¬ê¸°
            draw.rectangle([x1 + radius, y1, x2 - radius, y2], fill=fill)  # ê°€ë¡œ ì¤‘ì•™
            draw.rectangle([x1, y1 + radius, x2, y2 - radius], fill=fill)  # ì„¸ë¡œ ì¤‘ì•™

        # ë‘¥ê·¼ ëª¨ì„œë¦¬ í°ìƒ‰ ë°˜íˆ¬ëª… ë°°ê²½ ê·¸ë¦¬ê¸°
        draw_rounded_rectangle(
            draw,
            [background_x, background_y, background_x + background_width, background_y + background_height],
            corner_radius,
            (255, 255, 255, 204)  # í°ìƒ‰ 80% íˆ¬ëª…ë„
        )

        # í…ìŠ¤íŠ¸ ë Œë”ë§ (ë°°ê²½ ë°•ìŠ¤ ë‚´ë¶€ì— ê²€ì€ìƒ‰ í…ìŠ¤íŠ¸)
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            # ë°°ê²½ ë°•ìŠ¤ ë‚´ë¶€ ì¤‘ì•™ ì •ë ¬
            x = background_x + (background_width - text_width) // 2
            y = start_y + i * line_height

            # ê²€ì€ìƒ‰ í…ìŠ¤íŠ¸ (ë°°ê²½ì´ ìˆìœ¼ë¯€ë¡œ ì™¸ê³½ì„  ë¶ˆí•„ìš”)
            draw.text((x, y), line, font=font, fill='black')

    def _render_text_with_black_text_white_outline(self, draw, lines, font, emoji_font, width, start_y, line_height, font_size):
        """ê²€ì€ìƒ‰ ê¸€ì”¨ + í°ìƒ‰ ì™¸ê³½ì„  ìŠ¤íƒ€ì¼ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§"""
        # ê° ì¤„ë³„ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (width - text_width) // 2
            y = start_y + i * line_height

            try:
                # ë” ë¶€ë“œëŸ¬ìš´ í°ìƒ‰ ì™¸ê³½ì„  (3px ë‘ê»˜)
                outline_positions = [
                    (-3, -3), (-3, -2), (-3, -1), (-3, 0), (-3, 1), (-3, 2), (-3, 3),
                    (-2, -3), (-2, -2), (-2, -1), (-2, 0), (-2, 1), (-2, 2), (-2, 3),
                    (-1, -3), (-1, -2), (-1, -1), (-1, 0), (-1, 1), (-1, 2), (-1, 3),
                    (0, -3), (0, -2), (0, -1),            (0, 1), (0, 2), (0, 3),
                    (1, -3), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3),
                    (2, -3), (2, -2), (2, -1), (2, 0), (2, 1), (2, 2), (2, 3),
                    (3, -3), (3, -2), (3, -1), (3, 0), (3, 1), (3, 2), (3, 3)
                ]

                # í°ìƒ‰ ì™¸ê³½ì„  ê·¸ë¦¬ê¸°
                for dx, dy in outline_positions:
                    draw.text((x + dx, y + dy), line, font=font, fill='white')

                # ê²€ì€ìƒ‰ í…ìŠ¤íŠ¸ (ì¤‘ì•™)
                draw.text((x, y), line, font=font, fill='black')

            except Exception as e:
                print(f"ë³¸ë¬¸ í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
                # í´ë°±: ê¸°ë³¸ ì™¸ê³½ì„ 
                for dx in [-1, 0, 1]:
                    for dy in [-1, 0, 1]:
                        if dx != 0 or dy != 0:
                            draw.text((x + dx, y + dy), line, font=font, fill='white')
                draw.text((x, y), line, font=font, fill='black')

    def crop_to_square(self, image_path):
        """ì´ë¯¸ì§€ë¥¼ ì¤‘ì•™ ê¸°ì¤€ ì •ì‚¬ê°í˜•ìœ¼ë¡œ í¬ë¡­í•˜ì—¬ 716x716ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ"""
        try:
            with Image.open(image_path) as img:
                # âœ… EXIF orientation ì ìš© (ì•„ì´í° ì‚¬ì§„ íšŒì „ ë¬¸ì œ í•´ê²°)
                img = ImageOps.exif_transpose(img) or img
                width, height = img.size
                print(f"ğŸ”³ ì´ë¯¸ì§€ ë¡œë“œ: {image_path} ({width}x{height})")
                
                # ì´ë¯¸ 716x716ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
                if width == 716 and height == 716:
                    print(f"ğŸ”³ ì´ë¯¸ 716x716: ë³€í™˜ ë¶ˆí•„ìš”")
                    return image_path
                
                # ì§§ì€ ë³€ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ì‚¬ê°í˜• í¬ê¸° ê²°ì •
                crop_size = min(width, height)
                
                # ì¤‘ì•™ ê¸°ì¤€ í¬ë¡­ ì¢Œí‘œ ê³„ì‚°
                left = (width - crop_size) // 2
                top = (height - crop_size) // 2
                right = left + crop_size
                bottom = top + crop_size
                
                # í¬ë¡­ ì‹¤í–‰ (ì •ì‚¬ê°í˜•ì´ ì•„ë‹Œ ê²½ìš°ë§Œ)
                if width != height:
                    cropped_img = img.crop((left, top, right, bottom))
                    print(f"ğŸ”³ í¬ë¡­ ì‹¤í–‰: {width}x{height} â†’ {crop_size}x{crop_size}")
                else:
                    cropped_img = img.copy()
                    print(f"ğŸ”³ ì •ì‚¬ê°í˜• ì´ë¯¸ì§€: í¬ë¡­ ìƒëµ")
                
                # í•­ìƒ 716x716ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (PIL ë²„ì „ í˜¸í™˜ì„± ê³ ë ¤)
                try:
                    # Pillow 10.0.0+ ë²„ì „
                    resized_img = cropped_img.resize((716, 716), Image.Resampling.LANCZOS)
                except AttributeError:
                    # ì´ì „ ë²„ì „ í˜¸í™˜ì„±
                    resized_img = cropped_img.resize((716, 716), Image.LANCZOS)
                
                # RGBA ëª¨ë“œì¸ ê²½ìš° RGBë¡œ ë³€í™˜ (JPEG ì €ì¥ ìœ„í•´)
                if resized_img.mode in ('RGBA', 'LA', 'P'):
                    # í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ ë³€í™˜
                    background = Image.new('RGB', resized_img.size, (255, 255, 255))
                    if resized_img.mode == 'P':
                        resized_img = resized_img.convert('RGBA')
                    background.paste(resized_img, mask=resized_img.split()[-1] if resized_img.mode in ('RGBA', 'LA') else None)
                    resized_img = background
                    print(f"ğŸ”³ RGBA â†’ RGB ë³€í™˜ ì™„ë£Œ")
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
                resized_img.save(temp_file.name, 'JPEG', quality=95)
                
                print(f"ğŸ”³ ìµœì¢… ë¦¬ì‚¬ì´ì¦ˆ: â†’ 716x716")
                print(f"ğŸ”³ ì„ì‹œ íŒŒì¼ ìƒì„±: {temp_file.name}")
                
                return temp_file.name
                
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì—ëŸ¬: {image_path}")
            print(f"âŒ ì—ëŸ¬ ë‚´ìš©: {str(e)}")
            # ì—ëŸ¬ ë°œìƒì‹œ ì›ë³¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return image_path

    def easing_function(self, p):
        """ë”ìš± ë¶€ë“œëŸ¬ìš´ ì´ì§• í•¨ìˆ˜ (cubic ease-in-out)"""
        if p < 0.5:
            return 4 * p * p * p
        else:
            return 1 - pow(-2 * p + 2, 3) / 2
    
    def linear_easing_function(self, p):
        """ì¼ì •í•œ ì†ë„ì˜ ì„ í˜• ì´ì§• í•¨ìˆ˜ (íŒ¨ë‹ ì „ìš©)"""
        return p

    def create_background_clip(self, image_path, duration, enable_panning=True, title_area_mode="keep"):
        """ìƒˆë¡œìš´ ì˜ìƒ/ì´ë¯¸ì§€ ë°°ì¹˜ ë° íŒ¨ë‹ ê·œì¹™ ì ìš© (EXIF + ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì¦ˆ)

        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            duration: í´ë¦½ ì§€ì† ì‹œê°„
            enable_panning: íŒ¨ë‹ íš¨ê³¼ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            title_area_mode: íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œ ("keep" ë˜ëŠ” "remove")
        """
        panning_status = "íŒ¨ë‹ ì ìš©" if enable_panning else "íŒ¨ë‹ ì—†ìŒ"
        print(f"ğŸ¬ ë°°ê²½ í´ë¦½ ìƒì„± ì‹œì‘: {image_path} (duration: {duration:.1f}s, {panning_status})")
        logger.debug(f"ğŸ” [DEBUG] create_background_clip() í•¨ìˆ˜ ì§„ì… (ì´ë¯¸ì§€ ì²˜ë¦¬)")
        logger.debug(f"ğŸ” [DEBUG] ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(image_path)}")

        try:
            # ì´ë¯¸ì§€ ë¡œë“œ + EXIF ì ìš© + ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì¦ˆ
            with Image.open(image_path) as img:
                # âœ… EXIF orientation ì ìš© (ì•„ì´í°/HEIC ì‚¬ì§„ íšŒì „ ë¬¸ì œ í•´ê²°)
                img = ImageOps.exif_transpose(img) or img
                orig_width, orig_height = img.size
                print(f"ğŸ“ ì´ë¯¸ì§€ ì›ë³¸: {orig_width}x{orig_height}")

                # ì‘ì—… ì˜ì—­ ì •ì˜: íƒ€ì´í‹€ ëª¨ë“œì— ë”°ë¼ ê²°ì •
                work_width = 504
                if title_area_mode == "keep":
                    work_height = 670  # 890 - 220
                    y_offset = 220  # íƒ€ì´í‹€ ì•„ë˜ ì‹œì‘
                else:
                    work_height = 890  # ì „ì²´ ë†’ì´
                    y_offset = 0  # ë§¨ ìœ„ë¶€í„° ì‹œì‘

                work_aspect_ratio = work_width / work_height
                image_aspect_ratio = orig_width / orig_height

                print(f"ğŸ“Š ì¢…íš¡ë¹„ ë¹„êµ: ì´ë¯¸ì§€ {image_aspect_ratio:.3f} vs ì‘ì—…ì˜ì—­ {work_aspect_ratio:.3f}")

                # íŒ¨ë‹ ì˜µì…˜ì— ë”°ë¥¸ ë¦¬ì‚¬ì´ì¦ˆ ì „ëµ ê²°ì •
                if enable_panning:
                    # íŒ¨ë‹ í™œì„±í™”: ê¸°ì¡´ ë¡œì§ (í•œ ìª½ì„ ê½‰ ì±„ìš°ê³  ì—¬ìœ  ê³µê°„ í™•ë³´)
                    if image_aspect_ratio > work_aspect_ratio:
                        # ê°€ë¡œí˜•: ì„¸ë¡œë¥¼ work_heightì— ë§ì¶¤
                        new_height = work_height
                        new_width = int(orig_width * work_height / orig_height)
                        print(f"ğŸ”„ ê°€ë¡œí˜• ì´ë¯¸ì§€ (íŒ¨ë‹ìš©): ë¦¬ì‚¬ì´ì¦ˆ {new_width}x{new_height}")
                    else:
                        # ì„¸ë¡œí˜•: ê°€ë¡œë¥¼ work_widthì— ë§ì¶¤
                        new_width = work_width
                        new_height = int(orig_height * work_width / orig_width)
                        print(f"ğŸ”„ ì„¸ë¡œí˜• ì´ë¯¸ì§€ (íŒ¨ë‹ìš©): ë¦¬ì‚¬ì´ì¦ˆ {new_width}x{new_height}")
                else:
                    # íŒ¨ë‹ ë¹„í™œì„±í™”: ê°€ë¡œ(width)ë¥¼ ìº”ë²„ìŠ¤ì— ê½‰ ì±„ìš°ê¸°
                    # ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ê°€ë¡œ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ìœ„ì•„ë˜ ê²€ì€ íŒ¨ë”©)
                    new_width = work_width  # 504px ê³ ì •
                    new_height = int(orig_height * work_width / orig_width)
                    print(f"{'='*60}")
                    print(f"ğŸ”„ [íŒ¨ë‹ OFF] ì´ë¯¸ì§€ ê°€ë¡œ ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ")
                    print(f"   ì›ë³¸ ì´ë¯¸ì§€: {orig_width}x{orig_height}")
                    print(f"   ìº”ë²„ìŠ¤ í­: {work_width}px (504px ê³ ì •)")
                    print(f"   ë¦¬ì‚¬ì´ì¦ˆ ê²°ê³¼: {new_width}x{new_height}")
                    print(f"   ì¢…íš¡ë¹„: {orig_width/orig_height:.3f} â†’ {new_width/new_height:.3f}")
                    print(f"   ìœ„ì•„ë˜ ê²€ì€ íŒ¨ë”©: {max(0, work_height - new_height)}px")
                    print(f"{'='*60}")

                # PIL ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì¦ˆ (LANCZOS)
                try:
                    resized_img = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                except AttributeError:
                    resized_img = img.resize((new_width, new_height), Image.LANCZOS)

                print(f"âœ¨ ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ: LANCZOS ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©")

                # RGBA â†’ RGB ë³€í™˜
                if resized_img.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', resized_img.size, (0, 0, 0))
                    if resized_img.mode == 'P':
                        resized_img = resized_img.convert('RGBA')
                    background.paste(resized_img, mask=resized_img.split()[-1] if resized_img.mode in ('RGBA', 'LA') else None)
                    resized_img = background
                    print(f"ğŸ”³ RGBA â†’ RGB ë³€í™˜ ì™„ë£Œ")

                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (ê³ í’ˆì§ˆ)
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
                resized_img.save(temp_file.name, 'JPEG', quality=95)
                processed_image_path = temp_file.name
                print(f"ğŸ’¾ ê³ í’ˆì§ˆ ì„ì‹œ íŒŒì¼ ìƒì„±: {processed_image_path}")

            # MoviePyë¡œ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ë¡œë“œ
            bg_clip = ImageClip(processed_image_path).set_duration(duration)
            resized_width = new_width
            resized_height = new_height
            image_aspect_ratio = orig_width / orig_height

            if enable_panning:
                # === íŒ¨ë‹ í™œì„±í™”: ê¸°ì¡´ íŒ¨ë‹ ë¡œì§ ===
                if image_aspect_ratio > work_aspect_ratio:
                    # ê°€ë¡œí˜• ì´ë¯¸ì§€: ì¢Œìš° íŒ¨ë‹
                    pan_range = min(60, (resized_width - work_width) // 2)
                    pattern = random.randint(1, 2)

                    if pattern == 1:
                        # íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹
                        def left_to_right(t):
                            progress = self.linear_easing_function(t / duration)
                            x_offset = -((resized_width - work_width) // 2 - pan_range * progress)
                            return (x_offset, y_offset)

                        bg_clip = bg_clip.set_position(left_to_right)
                        print(f"ğŸ¬ íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹ ({pan_range}px ì´ë™)")
                    else:
                        # íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹
                        def right_to_left(t):
                            progress = self.linear_easing_function(t / duration)
                            x_offset = -((resized_width - work_width) // 2 - pan_range * (1 - progress))
                            return (x_offset, y_offset)

                        bg_clip = bg_clip.set_position(right_to_left)
                        print(f"ğŸ¬ íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹ ({pan_range}px ì´ë™)")
                else:
                    # ì„¸ë¡œí˜• ì´ë¯¸ì§€: ìƒí•˜ íŒ¨ë‹
                    pan_range = min(60, (resized_height - work_height) // 2)
                    pattern = random.randint(3, 4)

                    if pattern == 3:
                        # íŒ¨í„´ 3: ìœ„ â†’ ì•„ë˜ íŒ¨ë‹
                        def top_to_bottom(t):
                            progress = self.linear_easing_function(t / duration)
                            y_offset_dynamic = y_offset - ((resized_height - work_height) // 2 - pan_range * progress)
                            return (0, y_offset_dynamic)

                        bg_clip = bg_clip.set_position(top_to_bottom)
                        print(f"ğŸ¬ íŒ¨í„´ 3: ìœ„ â†’ ì•„ë˜ íŒ¨ë‹ ({pan_range}px ì´ë™)")
                    else:
                        # íŒ¨í„´ 4: ì•„ë˜ â†’ ìœ„ íŒ¨ë‹
                        def bottom_to_top(t):
                            progress = self.linear_easing_function(t / duration)
                            y_offset_dynamic = y_offset - ((resized_height - work_height) // 2 - pan_range * (1 - progress))
                            return (0, y_offset_dynamic)

                        bg_clip = bg_clip.set_position(bottom_to_top)
                        print(f"ğŸ¬ íŒ¨í„´ 4: ì•„ë˜ â†’ ìœ„ íŒ¨ë‹ ({pan_range}px ì´ë™)")
            else:
                # === íŒ¨ë‹ ë¹„í™œì„±í™”: ìœ„ë¡œ ë¶™ì´ê¸° + ì•„ë˜ ê²€ì€ìƒ‰ íŒ¨ë”© ===
                # ì´ë¯¸ì§€ë¥¼ ì‘ì—…ì˜ì—­ ìœ„ìª½ì— ë¶™ì„ (ì•„ë˜ ë‚¨ëŠ” ì˜ì—­ì€ ê²€ê²Œ ë³´ì„)
                x_pos = 0  # ê°€ë¡œëŠ” ê½‰ ì±„ì›€ (width=504)
                y_pos = y_offset  # ìœ„ë¡œ ë¶™ì„

                bg_clip = bg_clip.set_position((x_pos, y_pos))
                print(f"ğŸ“ íŒ¨ë‹ ì—†ìŒ: ìœ„ë¡œ ë¶™ì„ ({x_pos}, {y_pos})")
                print(f"   ì´ë¯¸ì§€ í¬ê¸°: {resized_width}x{resized_height}")
                print(f"   ì‘ì—… ì˜ì—­: {work_width}x{work_height} (Y offset: {y_offset})")
                print(f"   ì•„ë˜ ê²€ì€ íŒ¨ë”©: {max(0, work_height - resized_height)}px")

                # ê²€ì€ìƒ‰ ë°°ê²½ìœ¼ë¡œ ë‚¨ëŠ” ì˜ì—­ ì±„ìš°ê¸°
                black_bg = ColorClip(size=(work_width, work_height), color=(0, 0, 0))
                black_bg = black_bg.set_duration(duration).set_position((0, y_offset))

                # ê²€ì€ ë°°ê²½ ìœ„ì— ì´ë¯¸ì§€ í•©ì„±
                bg_clip = CompositeVideoClip([black_bg, bg_clip])
                print(f"âœ… ê²€ì€ìƒ‰ ë°°ê²½ ì¶”ê°€ ì™„ë£Œ")

            return bg_clip
                
        except Exception as e:
            print(f"âŒ ë°°ê²½ í´ë¦½ ìƒì„± ì—ëŸ¬: {str(e)}")
            # ì—ëŸ¬ ë°œìƒì‹œ ê¸°ë³¸ í´ë¦½ ë°˜í™˜ (PILë¡œ ì•ˆì „í•˜ê²Œ ë¦¬ì‚¬ì´ì¦ˆ)
            try:
                fallback_img = Image.open(image_path)
                orig_w, orig_h = fallback_img.size
                new_h = 670
                new_w = int(orig_w * new_h / orig_h)

                try:
                    resized_fallback = fallback_img.resize((new_w, new_h), Image.Resampling.LANCZOS)
                except AttributeError:
                    resized_fallback = fallback_img.resize((new_w, new_h), Image.LANCZOS)

                fallback_temp = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
                resized_fallback.save(fallback_temp.name, 'JPEG', quality=95)
                fallback_clip = ImageClip(fallback_temp.name).set_duration(duration).set_position((0, 220))
                os.unlink(fallback_temp.name)
            except:
                # ìµœì¢… fallback: ì›ë³¸ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                fallback_clip = ImageClip(image_path).set_duration(duration).set_position((0, 220))
            return fallback_clip


    
    def create_continuous_background_clip(self, image_path, total_duration, start_offset=0.0, enable_panning=True, title_area_mode="keep"):
        """2ê°œ body ë™ì•ˆ ì—°ì†ì ìœ¼ë¡œ ì›€ì§ì´ëŠ” ë°°ê²½ í´ë¦½ ìƒì„± (EXIF + ê³ í’ˆì§ˆ ì ìš©)

        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            total_duration: ì „ì²´ í´ë¦½ ì§€ì† ì‹œê°„
            start_offset: ì‹œì‘ ì˜¤í”„ì…‹ (í˜„ì¬ ë¯¸ì‚¬ìš©)
            enable_panning: íŒ¨ë‹ íš¨ê³¼ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            title_area_mode: íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œ ("keep" ë˜ëŠ” "remove")
        """
        panning_status = "íŒ¨ë‹ ì ìš©" if enable_panning else "íŒ¨ë‹ ì—†ìŒ"
        print(f"ğŸ¬ ì—°ì† ë°°ê²½ í´ë¦½ ìƒì„±: {image_path} (duration: {total_duration:.1f}s, {panning_status})")
        logger.debug(f"ğŸ” [DEBUG] create_continuous_background_clip() í•¨ìˆ˜ ì§„ì…")
        logger.debug(f"ğŸ” [DEBUG] ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(image_path)}")

        # ì´ë¯¸ì§€ë¥¼ ì •ì‚¬ê°í˜•ìœ¼ë¡œ í¬ë¡­ í›„ 716x716ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        # âœ… crop_to_square()ì—ì„œ EXIF orientation + LANCZOS ë¦¬ì‚¬ì´ì¦ˆ ì ìš©ë¨
        square_image_path = self.crop_to_square(image_path)

        try:
            # ë°°ê²½ í´ë¦½ ìƒì„±
            bg_clip = ImageClip(square_image_path).set_duration(total_duration)

            # íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œì— ë”°ë¥¸ Y ì˜¤í”„ì…‹ ê²°ì •
            if title_area_mode == "keep":
                y_offset = 220  # íƒ€ì´í‹€ ì•„ë˜ ì‹œì‘
                work_height = 670
            else:
                y_offset = 0  # ë§¨ ìœ„ë¶€í„° ì‹œì‘
                work_height = 890

            if enable_panning:
                # === íŒ¨ë‹ í™œì„±í™”: ê¸°ì¡´ íŒ¨ë‹ ë¡œì§ ===
                # 2ê°€ì§€ íŒ¨ë‹ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ
                pattern = random.randint(1, 2)

                if pattern == 1:
                    # íŒ¨í„´ 1: ì—°ì† ì¢Œ â†’ ìš° íŒ¨ë‹ (Linear ì´ì§• + 60px ì´ë™)
                    def continuous_left_to_right(t):
                        progress = self.linear_easing_function(t / total_duration)
                        x_offset = -(151 - 60 * progress)
                        return (x_offset, y_offset)

                    bg_clip = bg_clip.set_position(continuous_left_to_right)
                    print(f"ğŸ¬ ì—°ì† íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹ (duration: {total_duration:.1f}s)")

                else:
                    # íŒ¨í„´ 2: ì—°ì† ìš° â†’ ì¢Œ íŒ¨ë‹ (Linear ì´ì§• + 60px ì´ë™)
                    def continuous_right_to_left(t):
                        progress = self.linear_easing_function(t / total_duration)
                        x_offset = -(151 - 60 * (1 - progress))
                        return (x_offset, y_offset)

                    bg_clip = bg_clip.set_position(continuous_right_to_left)
                    print(f"ğŸ¬ ì—°ì† íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹ (duration: {total_duration:.1f}s)")
            else:
                # === íŒ¨ë‹ ë¹„í™œì„±í™”: ê°€ë¡œ ê½‰ ì±„ìš°ê¸° + ìœ„ì•„ë˜ ê²€ì€ìƒ‰ íŒ¨ë”© ===
                # ì •ì‚¬ê°í˜• ì´ë¯¸ì§€ (716x716)ë¥¼ ì‘ì—…ì˜ì—­ ê°€ë¡œì— ë§ì¶¤
                work_width = 504
                img_width = 716
                img_height = 716

                # íŒ¨ë‹ ë¹„í™œì„±í™” ì‹œ: í•­ìƒ ê°€ë¡œë¥¼ ìº”ë²„ìŠ¤ í­(504px)ì— ë§ì¶¤
                new_width = work_width  # 504px ê³ ì •
                new_height = int(img_height * work_width / img_width)

                print(f"{'='*60}")
                print(f"ğŸ”„ [ì—°ì† í´ë¦½ - íŒ¨ë‹ OFF] ì´ë¯¸ì§€ ê°€ë¡œ ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ")
                print(f"   ì›ë³¸ ì´ë¯¸ì§€: {img_width}x{img_height}")
                print(f"   ìº”ë²„ìŠ¤ í­: {work_width}px (504px ê³ ì •)")
                print(f"   ë¦¬ì‚¬ì´ì¦ˆ ê²°ê³¼: {new_width}x{new_height}")
                print(f"   ì¢…íš¡ë¹„: {img_width/img_height:.3f} â†’ {new_width/new_height:.3f}")
                print(f"   ìœ„ì•„ë˜ ê²€ì€ íŒ¨ë”©: {max(0, work_height - new_height)}px")
                print(f"{'='*60}")

                # ì •ì‚¬ê°í˜• ì´ë¯¸ì§€ íŒŒì¼ì—ì„œ PILë¡œ ë¡œë“œ
                pil_img = Image.open(square_image_path)

                # PIL ë¦¬ì‚¬ì´ì¦ˆ (í˜¸í™˜ì„± ì²˜ë¦¬)
                try:
                    resized_pil = pil_img.resize((new_width, new_height), Image.Resampling.LANCZOS)
                except AttributeError:
                    resized_pil = pil_img.resize((new_width, new_height), Image.LANCZOS)

                # RGBA â†’ RGB ë³€í™˜
                if resized_pil.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', resized_pil.size, (0, 0, 0))
                    if resized_pil.mode == 'P':
                        resized_pil = resized_pil.convert('RGBA')
                    background.paste(resized_pil, mask=resized_pil.split()[-1] if resized_pil.mode in ('RGBA', 'LA') else None)
                    resized_pil = background

                # ìƒˆ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                resized_temp_file = tempfile.NamedTemporaryFile(suffix='.jpg', delete=False)
                resized_pil.save(resized_temp_file.name, format='JPEG', quality=95)
                resized_temp_file.close()

                # ìƒˆ ImageClip ìƒì„± (global import ì‚¬ìš©)
                bg_clip = ImageClip(resized_temp_file.name).set_duration(total_duration)

                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                try:
                    os.unlink(resized_temp_file.name)
                except:
                    pass

                # ìœ„ë¡œ ë¶™ì´ê¸° ì¢Œí‘œ ê³„ì‚° (ì•„ë˜ ê²€ì€ íŒ¨ë”©)
                x_pos = 0  # ê°€ë¡œëŠ” ê½‰ ì±„ì›€ (width=504)
                y_pos = y_offset  # ìœ„ë¡œ ë¶™ì„

                bg_clip = bg_clip.set_position((x_pos, y_pos))
                print(f"ğŸ“ ì—°ì† íŒ¨ë‹ ì—†ìŒ: ìœ„ë¡œ ë¶™ì„ ({x_pos}, {y_pos})")
                print(f"   ì´ë¯¸ì§€ í¬ê¸°: {new_width}x{new_height}")
                print(f"   ì‘ì—… ì˜ì—­: {work_width}x{work_height}")
                print(f"   ì•„ë˜ ê²€ì€ íŒ¨ë”©: {max(0, work_height - new_height)}px")

                # ê²€ì€ìƒ‰ ë°°ê²½ìœ¼ë¡œ ë‚¨ëŠ” ì˜ì—­ ì±„ìš°ê¸°
                black_bg = ColorClip(size=(work_width, work_height), color=(0, 0, 0))
                black_bg = black_bg.set_duration(total_duration).set_position((0, y_offset))

                # ê²€ì€ ë°°ê²½ ìœ„ì— ì´ë¯¸ì§€ í•©ì„±
                bg_clip = CompositeVideoClip([black_bg, bg_clip])
                print(f"âœ… ì—°ì† í´ë¦½ ê²€ì€ìƒ‰ ë°°ê²½ ì¶”ê°€ ì™„ë£Œ")

            return bg_clip
                
        except Exception as e:
            print(f"âŒ ì—°ì† ë°°ê²½ í´ë¦½ ì—ëŸ¬: {str(e)}")
            # ì—ëŸ¬ ë°œìƒì‹œ ê¸°ë³¸ í´ë¦½ ë°˜í™˜
            fallback_clip = ImageClip(image_path).set_duration(total_duration)
            try:
                from moviepy.video.fx.all import resize as fx_resize
                fallback_clip = fallback_clip.fx(fx_resize, height=670).set_position((0, 0))
            except:
                fallback_clip = fallback_clip.resize(height=670).set_position((0, 0))
            return fallback_clip
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if square_image_path != image_path and os.path.exists(square_image_path):
                try:
                    os.unlink(square_image_path)
                    print(f"ğŸ—‘ï¸ ì—°ì† ì„ì‹œ íŒŒì¼ ì •ë¦¬: {square_image_path}")
                except:
                    pass

    
    def create_video_background_clip(self, video_path, duration, enable_panning=True):
        """ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ë°°ì¹˜ ë° íŒ¨ë‹ ê·œì¹™ ì ìš©

        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            duration: í´ë¦½ ì§€ì† ì‹œê°„
            enable_panning: íŒ¨ë‹ í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        from moviepy.editor import VideoFileClip, ColorClip, CompositeVideoClip

        print(f"ğŸ¬ ë¹„ë””ì˜¤ ë°°ê²½ í´ë¦½ ìƒì„± ì‹œì‘: {video_path} (duration: {duration:.1f}s, panning: {enable_panning})")
        logger.debug(f"ğŸ” [DEBUG] create_video_background_clip() í•¨ìˆ˜ ì§„ì…")
        logger.debug(f"ğŸ” [DEBUG] ë¹„ë””ì˜¤ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(video_path)}")

        try:
            # ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œ
            logger.debug(f"ğŸ” [DEBUG] VideoFileClip() í˜¸ì¶œ ì‹œì‘")
            video_clip = VideoFileClip(video_path)
            logger.debug(f"ğŸ” [DEBUG] VideoFileClip() í˜¸ì¶œ ì„±ê³µ")

            # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ê²€ì¦
            if video_clip.duration is None or video_clip.duration <= 0:
                raise Exception(f"ë¹„ë””ì˜¤ íŒŒì¼ì˜ ì§€ì† ì‹œê°„ ì •ë³´ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {video_clip.duration}")

            # ë¹„ë””ì˜¤ ì›ë³¸ í¬ê¸°
            orig_width = video_clip.w
            orig_height = video_clip.h
            print(f"ğŸ“ ë¹„ë””ì˜¤ ì›ë³¸: {orig_width}x{orig_height}")

            # ë¹„ë””ì˜¤ íŒŒì¼ ì •ë³´ ê²€ì¦
            if orig_width <= 0 or orig_height <= 0:
                raise Exception(f"ë¹„ë””ì˜¤ í•´ìƒë„ ì •ë³´ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {orig_width}x{orig_height}")
            
            # ì‘ì—… ì˜ì—­ ì •ì˜: (0, 220) ~ (504, 890)
            work_width = 504
            work_height = 670  # 890 - 220
            work_aspect_ratio = work_width / work_height  # 252:335 = 0.751
            video_aspect_ratio = orig_width / orig_height
            
            print(f"ğŸ“Š ì¢…íš¡ë¹„ ë¹„êµ: ë¹„ë””ì˜¤ {video_aspect_ratio:.3f} vs ì‘ì—…ì˜ì—­ {work_aspect_ratio:.3f}")
            
            # ë¹„ë””ì˜¤ ê¸¸ì´ ì¡°ì • (ì•ˆì „í•œ ì²˜ë¦¬)
            original_duration = video_clip.duration
            print(f"ğŸ“ ë¹„ë””ì˜¤ ì›ë³¸ ê¸¸ì´: {original_duration:.2f}ì´ˆ, ëª©í‘œ ê¸¸ì´: {duration:.2f}ì´ˆ")

            if original_duration > duration:
                # ë¹„ë””ì˜¤ê°€ ê¸´ ê²½ìš°: ì•ˆì „í•˜ê²Œ ìë¥´ê¸° (ì•½ê°„ì˜ ì—¬ìœ ë¥¼ ë‘ )
                logger.debug(f"ğŸ” [DEBUG] ë¹„ë””ì˜¤ ê¸¸ì´ ì¡°ì • ë¶„ê¸°: ê¸´ ë¹„ë””ì˜¤ ìë¥´ê¸° (original={original_duration:.2f}s > target={duration:.2f}s)")
                safe_duration = min(duration, original_duration - 0.2)  # 0.2ì´ˆ ì—¬ìœ 
                safe_duration = max(safe_duration, 0.5)  # ìµœì†Œ 0.5ì´ˆëŠ” ë³´ì¥
                print(f"â‚ ë¹„ë””ì˜¤ ê¸¸ì´ ì¡°ì •: {safe_duration:.2f}ì´ˆë¡œ ì•ˆì „í•˜ê²Œ ì˜ë¼ëƒ„")
                video_clip = video_clip.subclip(0, safe_duration)
            elif original_duration < duration:
                logger.debug(f"ğŸ” [DEBUG] ë¹„ë””ì˜¤ ê¸¸ì´ ì¡°ì • ë¶„ê¸°: ì§§ì€ ë¹„ë””ì˜¤ ë°˜ë³µ/ì—°ì¥ (original={original_duration:.2f}s < target={duration:.2f}s)")
                # ë¹„ë””ì˜¤ê°€ ì§§ì€ ê²½ìš°: ë°˜ë³µ ì¬ìƒìœ¼ë¡œ ê¸¸ì´ ë§ì¶¤
                try:
                    # ì•ˆì „í•œ ë°˜ë³µ ì²˜ë¦¬
                    loop_count = int(duration // original_duration) + 1
                    print(f"ğŸ” ë¹„ë””ì˜¤ ë°˜ë³µ ì²˜ë¦¬: {loop_count}íšŒ ë°˜ë³µí•˜ì—¬ {duration}ì´ˆ ë‹¬ì„±")

                    # ê°œë³„ í´ë¦½ë“¤ì„ ìƒì„±í•´ì„œ ì—°ê²°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½
                    clips = []
                    current_time = 0

                    while current_time < duration:
                        remaining_time = duration - current_time
                        if remaining_time >= original_duration:
                            # ì „ì²´ í´ë¦½ ì¶”ê°€
                            clips.append(video_clip)
                            current_time += original_duration
                        else:
                            # ë¶€ë¶„ í´ë¦½ ì¶”ê°€ (ì•ˆì „í•˜ê²Œ)
                            safe_remaining = min(remaining_time, original_duration - 0.2)
                            if safe_remaining > 0.2:  # ìµœì†Œ 0.2ì´ˆëŠ” ìˆì–´ì•¼ í•¨
                                print(f"ğŸ“ ë¶€ë¶„ í´ë¦½ ìƒì„±: 0ì´ˆ ~ {safe_remaining:.2f}ì´ˆ")
                                clips.append(video_clip.subclip(0, safe_remaining))
                            current_time = duration  # ë£¨í”„ ì¢…ë£Œ

                    if clips:
                        from moviepy.editor import concatenate_videoclips
                        video_clip = concatenate_videoclips(clips)
                        print(f"âœ… ë¹„ë””ì˜¤ ë°˜ë³µ ì™„ì„±: ìµœì¢… ê¸¸ì´ {video_clip.duration:.2f}ì´ˆ")

                except Exception as e:
                    print(f"âš ï¸ ë¹„ë””ì˜¤ ë°˜ë³µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    logger.error(f"ğŸ” [DEBUG] ============ ì˜ˆì™¸ ì²˜ë¦¬ ë¸”ë¡ ì§„ì… ============")
                    logger.error(f"ğŸ” [DEBUG] ì˜ˆì™¸ íƒ€ì…: {type(e).__name__}")
                    logger.error(f"ğŸ” [DEBUG] ì˜ˆì™¸ ë©”ì‹œì§€: {str(e)}")

                    # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¹„ë””ì˜¤ë¥¼ ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì—°ì¥
                    print("ğŸ“¸ ëŒ€ì•ˆ: ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì—°ì¥ ì²˜ë¦¬")
                    logger.debug(f"ğŸ” [DEBUG] ë§ˆì§€ë§‰ í”„ë ˆì„ ì—°ì¥ ì²˜ë¦¬ ì‹œì‘")

                    # ì›ë³¸ ë¹„ë””ì˜¤ + ë§ˆì§€ë§‰ í”„ë ˆì„ ì •ì§€ ì´ë¯¸ì§€ (global import ì‚¬ìš©)
                    safe_frame_time = max(0, min(original_duration - 0.3, original_duration * 0.9))
                    print(f"ğŸ“¸ ì•ˆì „í•œ í”„ë ˆì„ ì¶”ì¶œ ì‹œê°„: {safe_frame_time:.2f}ì´ˆ")

                    logger.debug(f"ğŸ” [DEBUG] video_clip.to_ImageClip() í˜¸ì¶œ ì§ì „")
                    logger.debug(f"ğŸ” [DEBUG] video_clip íƒ€ì…: {type(video_clip)}")
                    logger.debug(f"ğŸ” [DEBUG] ImageClip íƒ€ì…: {type(ImageClip)}")
                    last_frame = video_clip.to_ImageClip(t=safe_frame_time)
                    logger.debug(f"ğŸ” [DEBUG] video_clip.to_ImageClip() í˜¸ì¶œ ì™„ë£Œ")

                    extension_duration = duration - original_duration
                    extension_clip = last_frame.set_duration(extension_duration)

                    video_clip = concatenate_videoclips([video_clip, extension_clip])
                    print(f"ğŸ–¼ï¸ ë§ˆì§€ë§‰ í”„ë ˆì„ ì—°ì¥: {extension_duration:.2f}ì´ˆ ì¶”ê°€")
                    logger.debug(f"ğŸ” [DEBUG] ============ ì˜ˆì™¸ ì²˜ë¦¬ ë¸”ë¡ ì¢…ë£Œ ============")
            
            if video_aspect_ratio > work_aspect_ratio:
                # ê°€ë¡œí˜• ë¹„ë””ì˜¤: ì„¸ë¡œ ë†’ì´ë¥¼ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë°°ì¹˜í•˜ê³  ì¢Œìš° íŒ¨ë‹
                print(f"ğŸ”„ ê°€ë¡œí˜• ë¹„ë””ì˜¤ ì²˜ë¦¬: ì„¸ë¡œ ë†’ì´ë¥¼ {work_height}ì— ë§ì¶¤")

                # ì„¸ë¡œë¥¼ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ
                resized_width = int(orig_width * work_height / orig_height)

                try:
                    # MoviePy resize with newer API
                    from moviepy.video.fx.all import resize as fx_resize
                    video_clip = video_clip.fx(fx_resize, height=work_height)
                except:
                    # Fallback to direct resize
                    try:
                        video_clip = video_clip.resize(height=work_height)
                    except AttributeError as e:
                        # PIL ANTIALIAS ì´ìŠˆ - í”„ë ˆì„ ì¶”ì¶œ í›„ ìˆ˜ë™ ë¦¬ì‚¬ì´ì¦ˆ
                        print(f"âš ï¸ MoviePy resize ì‹¤íŒ¨ (PIL í˜¸í™˜ì„±): {e}")
                        print(f"ğŸ”„ í”„ë ˆì„ ì¶”ì¶œ ë°©ì‹ìœ¼ë¡œ ì „í™˜")

                        fps = 30
                        duration_temp = video_clip.duration
                        frames = []

                        for t in [i/fps for i in range(int(duration_temp * fps))]:
                            if t <= duration_temp:
                                frame = video_clip.get_frame(t)
                                pil_frame = Image.fromarray(frame)

                                try:
                                    resized_frame = pil_frame.resize((resized_width, work_height), Image.Resampling.LANCZOS)
                                except AttributeError:
                                    resized_frame = pil_frame.resize((resized_width, work_height), Image.LANCZOS)

                                frames.append(np.array(resized_frame))

                        from moviepy.editor import ImageSequenceClip
                        video_clip = ImageSequenceClip(frames, fps=fps)

                print(f"ğŸ”§ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ: {resized_width}x{work_height}")

                # ğŸ¨ íŒ¨ë‹ ì˜µì…˜ì— ë”°ë¥¸ ì²˜ë¦¬
                if enable_panning:
                    # ì¢Œìš° íŒ¨ë‹ ë²”ìœ„ ê³„ì‚°
                    pan_range = min(60, (resized_width - work_width) // 2)  # ìµœëŒ€ 60px ë˜ëŠ” ì—¬ìœ  ê³µê°„ì˜ ì ˆë°˜

                    # 2ê°€ì§€ ì¢Œìš° íŒ¨ë‹ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ
                    pattern = random.randint(1, 2)

                    if pattern == 1:
                        # íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹
                        def left_to_right(t):
                            progress = self.linear_easing_function(t / duration)
                            x_offset = -((resized_width - work_width) // 2 - pan_range * progress)
                            return (x_offset, 220)  # YëŠ” íƒ€ì´í‹€ ë°”ë¡œ ì•„ë˜

                        video_clip = video_clip.set_position(left_to_right)
                        print(f"ğŸ¬ íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹ ({pan_range}px ì´ë™)")

                    else:
                        # íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹
                        def right_to_left(t):
                            progress = self.linear_easing_function(t / duration)
                            x_offset = -((resized_width - work_width) // 2 - pan_range * (1 - progress))
                            return (x_offset, 220)  # YëŠ” íƒ€ì´í‹€ ë°”ë¡œ ì•„ë˜

                        video_clip = video_clip.set_position(right_to_left)
                        print(f"ğŸ¬ íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹ ({pan_range}px ì´ë™)")
                else:
                    # íŒ¨ë‹ ë¹„í™œì„±í™”: ì¤‘ì•™ ê³ ì • ë°°ì¹˜
                    x_offset = -((resized_width - work_width) // 2)
                    video_clip = video_clip.set_position((x_offset, 220))
                    print(f"ğŸ¨ íŒ¨ë‹ ë¹„í™œì„±í™”: ì¤‘ì•™ ê³ ì • ë°°ì¹˜ (x_offset: {x_offset})")
                    
            else:
                # ì„¸ë¡œí˜• ë¹„ë””ì˜¤: ê°€ë¡œ í­ì„ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë°°ì¹˜í•˜ê³  ìƒí•˜ íŒ¨ë‹
                print(f"ğŸ”„ ì„¸ë¡œí˜• ë¹„ë””ì˜¤ ì²˜ë¦¬: ê°€ë¡œ í­ì„ {work_width}ì— ë§ì¶¤")

                # ê°€ë¡œë¥¼ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ
                resized_height = int(orig_height * work_width / orig_width)

                try:
                    # MoviePy resize with newer API
                    from moviepy.video.fx.all import resize as fx_resize
                    video_clip = video_clip.fx(fx_resize, width=work_width)
                except:
                    # Fallback to direct resize
                    try:
                        video_clip = video_clip.resize(width=work_width)
                    except AttributeError as e:
                        # PIL ANTIALIAS ì´ìŠˆ - í”„ë ˆì„ ì¶”ì¶œ í›„ ìˆ˜ë™ ë¦¬ì‚¬ì´ì¦ˆ
                        print(f"âš ï¸ MoviePy resize ì‹¤íŒ¨ (PIL í˜¸í™˜ì„±): {e}")
                        print(f"ğŸ”„ í”„ë ˆì„ ì¶”ì¶œ ë°©ì‹ìœ¼ë¡œ ì „í™˜")

                        fps = 30
                        duration_temp = video_clip.duration
                        frames = []

                        for t in [i/fps for i in range(int(duration_temp * fps))]:
                            if t <= duration_temp:
                                frame = video_clip.get_frame(t)
                                pil_frame = Image.fromarray(frame)

                                try:
                                    resized_frame = pil_frame.resize((work_width, resized_height), Image.Resampling.LANCZOS)
                                except AttributeError:
                                    resized_frame = pil_frame.resize((work_width, resized_height), Image.LANCZOS)

                                frames.append(np.array(resized_frame))

                        from moviepy.editor import ImageSequenceClip
                        video_clip = ImageSequenceClip(frames, fps=fps)

                print(f"ğŸ”§ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ: {work_width}x{resized_height}")

                # ğŸ¨ íŒ¨ë‹ ì˜µì…˜ì— ë”°ë¥¸ ì²˜ë¦¬
                if enable_panning:
                    # ìƒí•˜ íŒ¨ë‹ ë²”ìœ„ ê³„ì‚°
                    pan_range = min(60, (resized_height - work_height) // 2)  # ìµœëŒ€ 60px ë˜ëŠ” ì—¬ìœ  ê³µê°„ì˜ ì ˆë°˜

                    # 2ê°€ì§€ ìƒí•˜ íŒ¨ë‹ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ
                    pattern = random.randint(3, 4)  # íŒ¨í„´ 3, 4ë¡œ êµ¬ë¶„

                    if pattern == 3:
                        # íŒ¨í„´ 3: ìœ„ â†’ ì•„ë˜ íŒ¨ë‹
                        def top_to_bottom(t):
                            progress = self.linear_easing_function(t / duration)
                            y_offset = 220 - ((resized_height - work_height) // 2 - pan_range * progress)
                            return (0, y_offset)  # XëŠ” ì¤‘ì•™

                        video_clip = video_clip.set_position(top_to_bottom)
                        print(f"ğŸ¬ íŒ¨í„´ 3: ìœ„ â†’ ì•„ë˜ íŒ¨ë‹ ({pan_range}px ì´ë™)")

                    else:
                        # íŒ¨í„´ 4: ì•„ë˜ â†’ ìœ„ íŒ¨ë‹
                        def bottom_to_top(t):
                            progress = self.linear_easing_function(t / duration)
                            y_offset = 220 - ((resized_height - work_height) // 2 - pan_range * (1 - progress))
                            return (0, y_offset)  # XëŠ” ì¤‘ì•™

                        video_clip = video_clip.set_position(bottom_to_top)
                        print(f"ğŸ¬ íŒ¨í„´ 4: ì•„ë˜ â†’ ìœ„ íŒ¨ë‹ ({pan_range}px ì´ë™)")
                else:
                    # íŒ¨ë‹ ë¹„í™œì„±í™”: ì¤‘ì•™ ê³ ì • ë°°ì¹˜
                    y_offset = 220 - ((resized_height - work_height) // 2)
                    video_clip = video_clip.set_position((0, y_offset))
                    print(f"ğŸ¨ íŒ¨ë‹ ë¹„í™œì„±í™”: ì¤‘ì•™ ê³ ì • ë°°ì¹˜ (y_offset: {y_offset})")

            logger.debug(f"ğŸ” [DEBUG] create_video_background_clip() ì •ìƒ ì¢…ë£Œ")
            return video_clip

        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ë°°ê²½ í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")
            logger.error(f"ğŸ” [DEBUG] ============ ìµœìƒìœ„ ì˜ˆì™¸ ì²˜ë¦¬ ë¸”ë¡ ============")
            logger.error(f"ğŸ” [DEBUG] ì˜ˆì™¸ íƒ€ì…: {type(e).__name__}")
            logger.error(f"ğŸ” [DEBUG] ì˜ˆì™¸ ë©”ì‹œì§€: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # ì‹¤íŒ¨ ì‹œ ê²€ì€ í™”ë©´ìœ¼ë¡œ ëŒ€ì²´
            fallback_clip = ColorClip(size=(504, 670), color=(0,0,0), duration=duration)
            fallback_clip = fallback_clip.set_position((0, 220))
            print(f"ğŸ”„ ê²€ì€ í™”ë©´ìœ¼ë¡œ ëŒ€ì²´: 504x670")
            return fallback_clip
    
    def create_tts_with_naver(self, text):
        """ë„¤ì´ë²„ Clova Voice TTS ìƒì„±"""
        if not self.naver_client_id or not self.naver_client_secret:
            return None
            
        try:
            print(f"ë„¤ì´ë²„ TTS ìƒì„± ì¤‘: {text[:50]}...")
            
            # Naver Clova Voice API í˜¸ì¶œ
            url = "https://naveropenapi.apigw.ntruss.com/tts-premium/v1/tts"
            headers = {
                "X-NCP-APIGW-API-KEY-ID": self.naver_client_id,
                "X-NCP-APIGW-API-KEY": self.naver_client_secret,
                "Content-Type": "application/x-www-form-urlencoded"
            }
            
            data = {
                "speaker": "nara",  # ì—¬ì„± ìŒì„± (clara, matt, shinji, nara ë“± ì„ íƒ ê°€ëŠ¥)
                "volume": "0",      # ë³¼ë¥¨ (-5~5)
                "speed": "0",       # ì†ë„ (-5~5)
                "pitch": "0",       # ìŒë†’ì´ (-5~5)
                "format": "mp3",    # ì¶œë ¥ í¬ë§·
                "text": text
            }
            
            response = requests.post(url, headers=headers, data=data)
            
            if response.status_code == 200:
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
                temp_file.write(response.content)
                temp_file.close()
                print(f"ë„¤ì´ë²„ TTS ìƒì„± ì™„ë£Œ: {temp_file.name}")
                return temp_file.name
            else:
                print(f"ë„¤ì´ë²„ TTS API ì˜¤ë¥˜: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"ë„¤ì´ë²„ TTS ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def create_tts_with_azure(self, text):
        """Microsoft Azure Cognitive Services TTS ìƒì„±"""
        if not self.azure_speech_key:
            return None
            
        try:
            print(f"Azure TTS ìƒì„± ì¤‘: {text[:50]}...")
            
            # Azure Cognitive Services Speech API í˜¸ì¶œ
            url = f"https://{self.azure_speech_region}.tts.speech.microsoft.com/cognitiveservices/v1"
            headers = {
                "Ocp-Apim-Subscription-Key": self.azure_speech_key,
                "Content-Type": "application/ssml+xml",
                "X-Microsoft-OutputFormat": "audio-24khz-48kbitrate-mono-mp3"
            }
            
            # SSML í˜•ì‹ìœ¼ë¡œ ìš”ì²­ ìƒì„± (í•œêµ­ì–´ ì—¬ì„± ìŒì„±)
            ssml = f"""<speak version='1.0' xml:lang='ko-KR'>
                <voice xml:lang='ko-KR' xml:gender='Female' name='ko-KR-SunHiNeural'>
                    <prosody rate='medium' pitch='medium'>
                        {text}
                    </prosody>
                </voice>
            </speak>"""
            
            response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
            
            if response.status_code == 200:
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
                temp_file.write(response.content)
                temp_file.close()
                print(f"Azure TTS ìƒì„± ì™„ë£Œ: {temp_file.name}")
                return temp_file.name
            else:
                print(f"Azure TTS API ì˜¤ë¥˜: {response.status_code}, {response.text}")
                return None
                
        except Exception as e:
            print(f"Azure TTS ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def create_tts_audio(self, text, lang='ko'):
        """Google TTSë¡œ ìµœì í™”ëœ í•œêµ­ì–´ ìŒì„± ìƒì„± - 1.7ë°° ë¹ ë¥¸ ì†ë„ ì ìš©"""
        try:
            print(f"Google TTS ìƒì„± ì¤‘: {text[:50]}...")
            
            # í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ë” ìì—°ìŠ¤ëŸ½ê²Œ)
            processed_text = self.preprocess_korean_text(text)
            
            # ìµœì í™”ëœ í•œêµ­ì–´ Google TTS ì„¤ì •
            tts = gTTS(
                text=processed_text, 
                lang='ko',  # ëª…ì‹œì ìœ¼ë¡œ í•œêµ­ì–´ ì„¤ì •
                slow=False,
                tld='com'   # êµ¬ê¸€ ë„ë©”ì¸ ìµœì í™”
            )
            
            # ì„ì‹œ íŒŒì¼ì— ì €ì¥ (ì›ë³¸ ì†ë„)
            original_temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
            tts.save(original_temp_file.name)
            original_temp_file.close()
            print(f"Google TTS ì›ë³¸ ìƒì„± ì™„ë£Œ: {original_temp_file.name}")
            
            # 70% ë¹ ë¥´ê²Œ ì†ë„ ì¡°ì • (1.7ë°°ì†)
            speed_adjusted_file = self.speed_up_audio(original_temp_file.name, speed_factor=1.7)
            
            # ì†ë„ ì¡°ì •ì´ ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ íŒŒì¼ ì‚¬ìš©, ì„±ê³µí•˜ë©´ ì›ë³¸ íŒŒì¼ë§Œ ì •ë¦¬
            if speed_adjusted_file != original_temp_file.name and os.path.exists(speed_adjusted_file):
                # ì†ë„ ì¡°ì • ì„±ê³µ: ìƒˆë¡œìš´ íŒŒì¼ì´ ìƒì„±ë¨, ì›ë³¸ íŒŒì¼ë§Œ ì •ë¦¬
                if os.path.exists(original_temp_file.name):
                    os.unlink(original_temp_file.name)
                    print(f"ğŸ—‘ï¸ ì›ë³¸ TTS íŒŒì¼ ì •ë¦¬: {original_temp_file.name}")
                print(f"Google TTS ìƒì„± ì™„ë£Œ (70% ê³ ì†í™”): {speed_adjusted_file}")
            else:
                # ì†ë„ ì¡°ì • ì‹¤íŒ¨: ì›ë³¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì‚­ì œí•˜ì§€ ì•ŠìŒ)
                print(f"Google TTS ìƒì„± ì™„ë£Œ (ì›ë³¸ ì†ë„): {speed_adjusted_file}")
            
            return speed_adjusted_file
            
        except Exception as e:
            print(f"TTS ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def speed_up_audio(self, audio_path, speed_factor=1.5):
        """ê³ ê¸‰ ì˜¤ë””ì˜¤ ì†ë„ ì¡°ì • (ë‹¤ì¤‘ ì•Œê³ ë¦¬ì¦˜ ì§€ì›)"""
        try:
            print(f"ğŸµ ê³ ê¸‰ ì˜¤ë””ì˜¤ ì†ë„ ì¡°ì • ì‹œì‘: {speed_factor}x ì†ë„")
            
            # ë°©ë²• 1: FFmpeg ì§ì ‘ ì‚¬ìš© (ê°€ì¥ ì•ˆì •ì )
            try:
                return self._speed_up_with_ffmpeg(audio_path, speed_factor)
            except Exception as e:
                print(f"âš ï¸ FFmpeg ë°©ë²• ì‹¤íŒ¨: {e}")
            
            # ë°©ë²• 2: MoviePy ë‹¤ì¤‘ ë°©ì‹
            try:
                return self._speed_up_with_moviepy(audio_path, speed_factor)
            except Exception as e:
                print(f"âš ï¸ MoviePy ë°©ë²• ì‹¤íŒ¨: {e}")
            
            # ë°©ë²• 3: Pydub ì‚¬ìš©
            try:
                return self._speed_up_with_pydub(audio_path, speed_factor)
            except Exception as e:
                print(f"âš ï¸ Pydub ë°©ë²• ì‹¤íŒ¨: {e}")
            
            # ë°©ë²• 4: ìƒ˜í”Œë§ ê¸°ë°˜ ê°„ë‹¨í•œ ì†ë„ ì¡°ì •
            try:
                return self._speed_up_with_sampling(audio_path, speed_factor)
            except Exception as e:
                print(f"âš ï¸ ìƒ˜í”Œë§ ë°©ë²• ì‹¤íŒ¨: {e}")
            
            print(f"âŒ ëª¨ë“  ì†ë„ ì¡°ì • ë°©ë²• ì‹¤íŒ¨, ì›ë³¸ íŒŒì¼ ì‚¬ìš©: {audio_path}")
            return audio_path
            
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì†ë„ ì¡°ì • ì „ì²´ ì‹¤íŒ¨: {e}")
            return audio_path

    def _speed_up_with_ffmpeg(self, audio_path, speed_factor):
        """ë°©ë²• 1: FFmpegë¥¼ ì§ì ‘ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ì†ë„ ì¡°ì •"""
        print(f"ğŸ”§ FFmpeg ë°©ì‹ ì†ë„ ì¡°ì • ì‹œë„...")
        
        import subprocess
        import shutil
        
        # FFmpeg ì„¤ì¹˜ í™•ì¸
        if not shutil.which('ffmpeg'):
            raise Exception("FFmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ì¶œë ¥ íŒŒì¼ ìƒì„±
        speed_adjusted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
        speed_adjusted_file.close()
        
        # FFmpeg ëª…ë ¹ì–´ë¡œ ì†ë„ ì¡°ì • (atempo í•„í„° ì‚¬ìš©)
        # atempoëŠ” í”¼ì¹˜ ë³€ê²½ ì—†ì´ ì†ë„ë§Œ ì¡°ì • (ìµœëŒ€ 2.0ë°°ê¹Œì§€)
        if speed_factor <= 2.0:
            atempo_filter = f"atempo={speed_factor}"
        else:
            # 2.0ë°° ì´ˆê³¼ì‹œ ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ë‚˜ëˆ”
            atempo_filter = "atempo=2.0,atempo=" + str(speed_factor / 2.0)
        
        cmd = [
            'ffmpeg', '-y',  # ë®ì–´ì“°ê¸° í—ˆìš©
            '-i', audio_path,
            '-filter:a', atempo_filter,
            '-loglevel', 'error',  # ì—ëŸ¬ë§Œ ì¶œë ¥
            speed_adjusted_file.name
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… FFmpeg ì†ë„ ì¡°ì • ì„±ê³µ: {speed_factor}x")
            return speed_adjusted_file.name
        else:
            raise Exception(f"FFmpeg ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
    
    def _speed_up_with_moviepy(self, audio_path, speed_factor):
        """ë°©ë²• 2: MoviePy ë‹¤ì¤‘ ë°©ì‹ ì‹œë„"""
        print(f"ğŸ¬ MoviePy ë°©ì‹ ì†ë„ ì¡°ì • ì‹œë„...")
        
        from moviepy.editor import AudioFileClip
        
        audio_clip = AudioFileClip(audio_path)
        original_duration = audio_clip.duration
        
        # ì‹œë„ 1: speedx import
        try:
            from moviepy.audio.fx import speedx
            speed_adjusted_clip = audio_clip.fx(speedx.speedx, speed_factor)
        except ImportError:
            try:
                from moviepy.audio.fx.speedx import speedx
                speed_adjusted_clip = audio_clip.fx(speedx, speed_factor)
            except ImportError:
                # ì‹œë„ 2: ì§ì ‘ ì‹œê°„ ë§¤í•‘
                print("ğŸ“ ì§ì ‘ ì‹œê°„ ë§¤í•‘ìœ¼ë¡œ ì†ë„ ì¡°ì •...")
                def speed_function(get_frame, t):
                    return get_frame(t * speed_factor)
                
                speed_adjusted_clip = audio_clip.fl(speed_function, apply_to=['mask'])
                speed_adjusted_clip = speed_adjusted_clip.set_duration(audio_clip.duration / speed_factor)
        
        new_duration = speed_adjusted_clip.duration
        
        # íŒŒì¼ ì €ì¥
        speed_adjusted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
        speed_adjusted_clip.write_audiofile(
            speed_adjusted_file.name, 
            verbose=False, 
            logger=None,
            temp_audiofile=None  # ì„ì‹œ íŒŒì¼ ê²½ë¡œ ë¬¸ì œ ë°©ì§€
        )
        speed_adjusted_file.close()
        
        # ë¦¬ì†ŒìŠ¤ í•´ì œ
        audio_clip.close()
        speed_adjusted_clip.close()
        
        print(f"âœ… MoviePy ì†ë„ ì¡°ì • ì™„ë£Œ: {original_duration:.1f}ì´ˆ â†’ {new_duration:.1f}ì´ˆ")
        return speed_adjusted_file.name
    
    def _speed_up_with_pydub(self, audio_path, speed_factor):
        """ë°©ë²• 3: Pydubë¥¼ ì‚¬ìš©í•œ ì†ë„ ì¡°ì •"""
        print(f"ğŸµ Pydub ë°©ì‹ ì†ë„ ì¡°ì • ì‹œë„...")
        
        try:
            from pydub import AudioSegment
            from pydub.playback import play
        except ImportError:
            raise Exception("pydub ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = AudioSegment.from_mp3(audio_path)
        
        # ì†ë„ ì¡°ì • (ì¬ìƒ ì†ë„ ë³€ê²½)
        # frame_rateë¥¼ ì¦ê°€ì‹œì¼œ ì†ë„ë¥¼ ë¹ ë¥´ê²Œ í•¨
        new_sample_rate = int(audio.frame_rate * speed_factor)
        speed_adjusted_audio = audio._spawn(audio.raw_data, overrides={"frame_rate": new_sample_rate})
        speed_adjusted_audio = speed_adjusted_audio.set_frame_rate(audio.frame_rate)
        
        # íŒŒì¼ ì €ì¥
        speed_adjusted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
        speed_adjusted_audio.export(speed_adjusted_file.name, format="mp3")
        speed_adjusted_file.close()
        
        print(f"âœ… Pydub ì†ë„ ì¡°ì • ì™„ë£Œ: {len(audio)}ms â†’ {len(speed_adjusted_audio)}ms")
        return speed_adjusted_file.name
    
    def _speed_up_with_sampling(self, audio_path, speed_factor):
        """ë°©ë²• 4: ê°„ë‹¨í•œ ìƒ˜í”Œë§ ê¸°ë°˜ ì†ë„ ì¡°ì •"""
        print(f"ğŸ“Š ìƒ˜í”Œë§ ë°©ì‹ ì†ë„ ì¡°ì • ì‹œë„...")
        
        try:
            import numpy as np
            import wave
        except ImportError:
            raise Exception("numpy ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # WAVë¡œ ë¨¼ì € ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
        from moviepy.editor import AudioFileClip
        temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        temp_wav.close()
        
        audio_clip = AudioFileClip(audio_path)
        audio_clip.write_audiofile(temp_wav.name, verbose=False, logger=None)
        audio_clip.close()
        
        # WAV íŒŒì¼ ì½ê¸°
        with wave.open(temp_wav.name, 'rb') as wav_file:
            frames = wav_file.readframes(-1)
            sound_info = wav_file.getparams()
            audio_data = np.frombuffer(frames, dtype=np.int16)
        
        # ìƒ˜í”Œë§ìœ¼ë¡œ ì†ë„ ì¡°ì • (ê°„ë‹¨í•œ ë°©ë²•)
        step = int(1 / speed_factor * len(audio_data))
        if step > 0:
            speed_adjusted_data = audio_data[::int(1/speed_factor)]
        else:
            speed_adjusted_data = audio_data
        
        # ìƒˆë¡œìš´ WAV íŒŒì¼ ìƒì„±
        speed_adjusted_wav = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        with wave.open(speed_adjusted_wav.name, 'wb') as new_wav:
            new_wav.setparams(sound_info)
            new_wav.writeframes(speed_adjusted_data.tobytes())
        speed_adjusted_wav.close()
        
        # MP3ë¡œ ë³€í™˜
        speed_adjusted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
        converted_clip = AudioFileClip(speed_adjusted_wav.name)
        converted_clip.write_audiofile(speed_adjusted_file.name, verbose=False, logger=None)
        converted_clip.close()
        speed_adjusted_file.close()
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        os.unlink(temp_wav.name)
        os.unlink(speed_adjusted_wav.name)
        
        print(f"âœ… ìƒ˜í”Œë§ ì†ë„ ì¡°ì • ì™„ë£Œ")
        return speed_adjusted_file.name
    
    def convert_foreign_to_korean(self, text: str) -> str:
        """
        í…ìŠ¤íŠ¸ ë‚´ ì™¸êµ­ì–´(ì˜ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ ë“±)ë¥¼ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜
        ì™¸êµ­ì–´ ë’¤ì— í•œê¸€ì´ ë¶™ì–´ìˆì–´ë„ ì™¸êµ­ì–´ ë¶€ë¶„ë§Œ ì •í™•íˆ ì¶”ì¶œí•˜ì—¬ ë³€í™˜

        ì˜ˆì‹œ:
        - "LASì´ì™¸ì˜" â†’ "ë¼ìŠ¤ì´ì™¸ì˜" (LASë§Œ ê²€ìƒ‰)
        - "AIê°€" â†’ "ì—ì´ì•„ì´ê°€"
        - "YouTubeë¥¼" â†’ "ìœ íŠœë¸Œë¥¼"

        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸

        Returns:
            ì™¸êµ­ì–´ê°€ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜ëœ í…ìŠ¤íŠ¸
        """
        import re

        # ì™¸êµ­ì–´ íŒ¨í„´ + ë’¤ì— ë¶™ì€ í•œê¸€ (0ê°œ ì´ìƒ)
        # ê·¸ë£¹1: ì™¸êµ­ì–´ ë¶€ë¶„ (ì˜ì–´+ìˆ«ì, ì¼ë³¸ì–´, ì¤‘êµ­ì–´)
        # ê·¸ë£¹2: ë’¤ì— ë¶™ì€ í•œê¸€ ë¶€ë¶„ (ì¡°ì‚¬, ë³µí•©ëª…ì‚¬ ë“±)
        foreign_pattern = re.compile(
            r'([A-Za-z0-9]+|[ã-ã‚”ã‚¡-ãƒ´ãƒ¼]+|[\u4e00-\u9fff]+)'  # ì™¸êµ­ì–´
            r'([ê°€-í£]*)'  # ë’¤ì— ë¶™ì€ í•œê¸€ (0ê°œ ì´ìƒ)
        )

        def replace_word(match):
            foreign_part = match.group(1)  # ì™¸êµ­ì–´ ë¶€ë¶„ (ì˜ˆ: "LAS", "AI", "YouTube")
            korean_part = match.group(2)   # ë’¤ì— ë¶™ì€ í•œê¸€ (ì˜ˆ: "ì´ì™¸ì˜", "ê°€", "ë¥¼", "")

            # ìˆœìˆ˜ í•œê¸€ë§Œ ìˆëŠ” ê²½ìš° ìŠ¤í‚µ
            if re.match(r'^[ê°€-í£]+$', foreign_part):
                return match.group(0)  # ì›ë³¸ ê·¸ëŒ€ë¡œ

            # ë”•ì…”ë„ˆë¦¬ì—ì„œ ì™¸êµ­ì–´ ë¶€ë¶„ë§Œ ê²€ìƒ‰
            if self.pronunciation_dict.has_pronunciation(foreign_part):
                korean_pronunciation = self.pronunciation_dict.get_pronunciation(foreign_part)
                logger.info(f"ğŸ”„ ì™¸êµ­ì–´â†’í•œê¸€ ë³€í™˜: {foreign_part}{korean_part} â†’ {korean_pronunciation}{korean_part}")
                return korean_pronunciation + korean_part  # ë³€í™˜ëœ ë°œìŒ + ì›ë³¸ í•œê¸€
            else:
                # ì‚¬ì „ì— ì—†ìœ¼ë©´ ì›ë³¸ ìœ ì§€
                logger.debug(f"ğŸ“– ì‚¬ì „ ë¯¸ë“±ë¡: {foreign_part}")
                return match.group(0)  # ì›ë³¸ ê·¸ëŒ€ë¡œ

        # ëª¨ë“  ì™¸êµ­ì–´ ë‹¨ì–´ë¥¼ í•œê¸€ ë°œìŒìœ¼ë¡œ ë³€í™˜
        converted_text = foreign_pattern.sub(replace_word, text)

        return converted_text

    def preprocess_korean_text(self, text):
        """í•œêµ­ì–´ TTS í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ì™¸êµ­ì–´ ë³€í™˜ + ê´„í˜¸ ì œê±° í¬í•¨)"""
        try:
            import re
            processed = text.strip()

            # 1. ì™¸êµ­ì–´ â†’ í•œê¸€ ë°œìŒ ë³€í™˜ (ì˜ì–´, ì¼ë³¸ì–´, ì¤‘êµ­ì–´ ë“±)
            processed = self.convert_foreign_to_korean(processed)

            # 2. ê´„í˜¸ ë‚´ìš© ì œê±° (ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ëª¨ë“  ë‚´ìš©)
            processed = re.sub(r'\([^)]*\)', '', processed)

            # 3. ì´ëª¨ì§€ ì œê±° (í•œê¸€ í…ìŠ¤íŠ¸ëŠ” ë³´ì¡´)
            emoji_pattern = re.compile("["
                u"\U0001F600-\U0001F64F"  # emoticons
                u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                u"\U0001F680-\U0001F6FF"  # transport & map symbols
                u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                "]+", flags=re.UNICODE)
            processed = emoji_pattern.sub(' ', processed)

            # 4. ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ, ë¬¼ê²°í‘œì‹œë¥¼ ë§ˆì¹¨í‘œë¡œ ë³€í™˜
            processed = re.sub(r'[?!~]+', '.', processed)

            # 5. ê³µë°± ì •ë¦¬
            processed = re.sub(r'\s+', ' ', processed).strip()
            if processed and not processed.endswith('.'):
                processed += '.'

            logger.info(f"TTS ì „ì²˜ë¦¬ ì „: {text}")
            logger.info(f"TTS ì „ì²˜ë¦¬ í›„: {processed}")

            return processed

        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return text  # ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
    
    def get_audio_duration(self, audio_path):
        """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì‹¤ì œ ì¬ìƒ ì‹œê°„ ë°˜í™˜"""
        try:
            audio = AudioFileClip(audio_path)
            duration = audio.duration
            audio.close()
            return duration
        except Exception as e:
            print(f"ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨: {e}")
            return 3.0  # ê¸°ë³¸ê°’
    
    def get_local_images(self, test_folder="./test"):
        """test í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì´ë¦„ìˆœìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        import glob
        
        # ì´ë¯¸ì§€ í™•ì¥ì íŒ¨í„´ (webp ì¶”ê°€)
        image_patterns = ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.gif", "*.webp"]
        image_files = []
        
        for pattern in image_patterns:
            files = glob.glob(os.path.join(test_folder, pattern))
            files.extend(glob.glob(os.path.join(test_folder, pattern.upper())))
            image_files.extend(files)
        
        # ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬ (1.png, 2.png, 3.png, 4.png)
        import re
        def natural_sort_key(path):
            filename = os.path.basename(path).lower()
            # ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
            numbers = re.findall(r'\d+', filename)
            if numbers:
                return int(numbers[0])  # ì²« ë²ˆì§¸ ìˆ«ìë¡œ ì •ë ¬
            else:
                return float('inf')  # ìˆ«ìê°€ ì—†ìœ¼ë©´ ë§¨ ë’¤ë¡œ
        
        image_files.sort(key=natural_sort_key)
        
        print(f"ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {len(image_files)}ê°œ (ìˆ«ì ìˆœì„œëŒ€ë¡œ)")
        for i, file in enumerate(image_files):
            print(f"  {i+1}. {os.path.basename(file)}")
        
        if len(image_files) == 0:
            print("âŒ test í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            print(f"âœ… ì´ë¯¸ì§€ ì‚¬ìš© ìˆœì„œ: {' â†’ '.join([os.path.basename(f) for f in image_files])}")
        
        return image_files
    
    def create_video_with_local_images(self, content, music_path, output_folder, image_allocation_mode="2_per_image", text_position="bottom", text_style="outline", title_area_mode="keep", title_font="BMYEONSUNG_otf.otf", body_font="BMYEONSUNG_otf.otf", title_font_size=42, body_font_size=36, music_mood="bright", media_files=None, voice_narration="enabled", cross_dissolve="enabled", subtitle_duration=0.0, image_panning_options=None):
        """ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì‚¬ìš©í•œ ë¦´ìŠ¤ ì˜ìƒ ìƒì„±

        Args:
            image_panning_options: ì´ë¯¸ì§€ë³„ íŒ¨ë‹ ì˜µì…˜ ë”•ì…”ë„ˆë¦¬ (ì˜ˆ: {0: True, 1: False, 2: True})
                                   Noneì´ë©´ ëª¨ë“  ì´ë¯¸ì§€ì— íŒ¨ë‹ ì ìš© (ê¸°ë³¸ê°’)
        """
        try:
            # ë””ë²„ê¹…: íŒŒë¼ë¯¸í„° í™•ì¸
            print(f"ğŸ” create_video_with_local_images í˜¸ì¶œë¨!")
            print(f"ğŸ” cross_dissolve íŒŒë¼ë¯¸í„°: '{cross_dissolve}' (íƒ€ì…: {type(cross_dissolve)})")
            print(f"ğŸ” image_panning_options: {image_panning_options}")
            logging.info(f"ğŸ” create_video_with_local_images í˜¸ì¶œë¨!")
            logging.info(f"ğŸ” cross_dissolve íŒŒë¼ë¯¸í„°: '{cross_dissolve}' (íƒ€ì…: {type(cross_dissolve)})")
            logging.info(f"ğŸ” image_panning_options: {image_panning_options}")
            # ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
            local_images = self.get_local_images()

            if not local_images:
                raise Exception("test í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")

            print(f"ë¡œì»¬ ì´ë¯¸ì§€ {len(local_images)}ê°œë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ìƒì„±")

            # media_filesê°€ ì—†ëŠ” ê²½ìš° ë¡œì»¬ íŒŒì¼ë“¤ì˜ íƒ€ì… ì •ë³´ ìƒì„±
            if media_files is None:
                logging.info("ğŸ” media_filesê°€ Noneì´ë¯€ë¡œ ìë™ ìƒì„±í•©ë‹ˆë‹¤...")
                print("ğŸ” media_filesê°€ Noneì´ë¯€ë¡œ ìë™ ìƒì„±í•©ë‹ˆë‹¤...")
                media_files = []
                video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                for i, image_path in enumerate(local_images):
                    # íŒŒì¼ í™•ì¥ìë¡œ íƒ€ì… íŒë‹¨
                    is_video = any(image_path.lower().endswith(ext) for ext in video_extensions)
                    file_type = "video" if is_video else "image"
                    media_files.append((image_path, file_type))
                    msg = f"  ğŸ“ ìë™ ê°ì§€ [{i}]: {os.path.basename(image_path)} -> {file_type}"
                    print(msg)
                    logging.info(msg)
            else:
                msg = f"ğŸ” media_filesê°€ ì´ë¯¸ ì œê³µë¨: {len(media_files)}ê°œ"
                print(msg)
                logging.info(msg)

            msg = f"ğŸ’½ ìµœì¢… ë¯¸ë””ì–´ íŒŒì¼ ì •ë³´: {len(media_files)}ê°œ"
            print(msg)
            logging.info(msg)
            for i, (path, file_type) in enumerate(media_files):
                msg = f"  [{i}] {os.path.basename(path)} -> {file_type}"
                print(msg)
                logging.info(msg)
            print(f"ğŸ  íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œ: {title_area_mode}")

            # íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬
            title_image_path = None
            if title_area_mode == "keep":
                # ê¸°ì¡´ ë°©ì‹: íƒ€ì´í‹€ ì˜ì—­ ìœ ì§€ (504x220)
                title_image_path = self.create_title_image(
                    content['title'],
                    self.video_width,
                    220,
                    title_font,
                    title_font_size
                )
                print("âœ… íƒ€ì´í‹€ ì˜ì—­ í™•ë³´: 220px íƒ€ì´í‹€ + 670px ë¯¸ë””ì–´")
            else:
                # remove ëª¨ë“œ: íƒ€ì´í‹€ ì œê±°, ì „ì²´ í™”ë©´ ë¯¸ë””ì–´
                print("âœ… íƒ€ì´í‹€ ì˜ì—­ ì œê±°: ì „ì²´ 890px ë¯¸ë””ì–´")
            
            # ê° bodyë³„ë¡œ ê°œë³„ TTS ìƒì„± (ë¹ˆ ê°’ ì œì™¸, ìˆœì„œ ë³´ì¥)
            body_keys = [key for key in content.keys() if key.startswith('body') and content[key].strip()]
            body_keys.sort(key=lambda x: int(x.replace('body', '')))  # body1, body2, ... ìˆœì„œë¡œ ì •ë ¬
            logger.info(f"ğŸ¯ body ìˆœì„œ í™•ì¸: {body_keys}")
            logger.info(f"ğŸ” [ë””ë²„ê¹…] voice_narration='{voice_narration}' (íƒ€ì…: {type(voice_narration).__name__})")
            logger.info(f"ğŸ” [ë””ë²„ê¹…] subtitle_duration={subtitle_duration} (íƒ€ì…: {type(subtitle_duration).__name__})")
            logger.info(f"ğŸ” [ë””ë²„ê¹…] ì¡°ê±´ ì²´í¬: voice_narration == 'disabled' = {voice_narration == 'disabled'}")
            logger.info(f"ğŸ” [ë””ë²„ê¹…] ì¡°ê±´ ì²´í¬: subtitle_duration > 0 = {subtitle_duration > 0}")
            tts_files = []

            for body_key in body_keys:
                # ìë§‰ ì§€ì† ì‹œê°„ ìµœì í™”: voice_narration=disabledì´ê³  subtitle_duration > 0ì´ë©´ TTS ìƒì„± ê±´ë„ˆëœ€
                if voice_narration == "disabled" and subtitle_duration > 0:
                    logger.info(f"â±ï¸ {body_key} TTS ê±´ë„ˆëœ€ (ìë§‰ ì§€ì† ì‹œê°„ {subtitle_duration}ì´ˆ ì‚¬ìš©)")
                    tts_files.append((body_key, None, subtitle_duration))
                else:
                    logger.info(f"ğŸ™ï¸ {body_key} TTS ìƒì„± ì¤‘... ë‚´ìš©: '{content[body_key][:50]}...'")
                    body_tts = self.create_tts_audio(content[body_key])
                    if body_tts:
                        body_duration = self.get_audio_duration(body_tts)
                        tts_files.append((body_key, body_tts, body_duration))
                        logger.info(f"âœ… {body_key} TTS ì™„ë£Œ: {body_duration:.1f}ì´ˆ")
                    else:
                        logger.error(f"âŒ {body_key} TTS ìƒì„± ì‹¤íŒ¨")
            
            # ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
            print(f"ğŸ¬ ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ: {image_allocation_mode}")
            
            group_clips = []
            audio_segments = []
            
            if image_allocation_mode == "1_per_image":
                # Mode 2: body 1ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (1:1 ë§¤ì¹­)
                print("ğŸ–¼ï¸ 1:1 ë§¤ì¹­ ëª¨ë“œ: bodyë³„ë¡œ ê°ê° ë‹¤ë¥¸ ì´ë¯¸ì§€ ì‚¬ìš©")
                
                for i, body_key in enumerate(body_keys):
                    # bodyë³„ë¡œ ê°œë³„ ì´ë¯¸ì§€ í• ë‹¹ (ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ì‚¬ìš©)
                    image_index = min(i, len(local_images) - 1)
                    current_image_path = local_images[image_index]
                    print(f"ğŸ¯ ë§¤ì¹­ ë””ë²„ê·¸: i={i}, body_key={body_key}, image_index={image_index}, image={os.path.basename(current_image_path)}")
                    
                    # í•´ë‹¹ bodyì˜ TTS ì •ë³´ ì°¾ê¸°
                    body_tts_info = None
                    body_duration = 3.0
                    for tts_key, tts_path, tts_duration in tts_files:
                        if tts_key == body_key:
                            body_tts_info = (body_key, content[body_key], tts_path, tts_duration)
                            body_duration = tts_duration
                            break
                    else:
                        body_tts_info = (body_key, content[body_key], None, 3.0)
                    
                    # íŒŒì¼ íƒ€ì… í™•ì¸ (ë¹„ë””ì˜¤ vs ì´ë¯¸ì§€)
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                    is_video = any(current_image_path.lower().endswith(ext) for ext in video_extensions)
                    file_type = "ë¹„ë””ì˜¤" if is_video else "ì´ë¯¸ì§€"
                    
                    print(f"ğŸ“¸ {body_key}: {file_type} {image_index + 1}/{len(local_images)} â†’ '{os.path.basename(current_image_path)}' ({body_duration:.1f}ì´ˆ)")
                    
                    # ì´ë¯¸ì§€ë³„ íŒ¨ë‹ ì˜µì…˜ í™•ì¸
                    enable_panning = True  # ê¸°ë³¸ê°’
                    if image_panning_options is not None and image_index in image_panning_options:
                        enable_panning = image_panning_options[image_index]
                        print(f"ğŸ¨ ì´ë¯¸ì§€ {image_index}: íŒ¨ë‹ ì˜µì…˜ = {enable_panning}")

                    # íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œì— ë”°ë¥¸ ë°°ê²½ í´ë¦½ ìƒì„±
                    if title_area_mode == "keep":
                        # ê¸°ì¡´ ë°©ì‹: íƒ€ì´í‹€ ì˜ì—­ + ë¯¸ë””ì–´ ì˜ì—­
                        if is_video:
                            # ë¹„ë””ì˜¤ëŠ” í•­ìƒ íŒ¨ë‹ off (ì¤‘ì•™ ê³ ì • ë°°ì¹˜)
                            bg_clip = self.create_video_background_clip(current_image_path, body_duration, enable_panning=False)
                        else:
                            bg_clip = self.create_background_clip(current_image_path, body_duration, enable_panning=enable_panning, title_area_mode=title_area_mode)
                        black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(body_duration).set_position((0, 0))
                        title_clip = ImageClip(title_image_path).set_duration(body_duration).set_position((0, 0))

                        # í…ìŠ¤íŠ¸ í´ë¦½ (ê¸°ì¡´ ìœ„ì¹˜)
                        text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font, title_area_mode=title_area_mode, title_font_size=title_font_size, body_font_size=body_font_size)
                        text_clip = ImageClip(text_image_path).set_duration(body_duration).set_position((0, 0))

                        # ê¸°ì¡´ ë°©ì‹ í•©ì„±
                        individual_clip = CompositeVideoClip([bg_clip, black_top, title_clip, text_clip], size=(self.video_width, self.video_height))
                    else:
                        # remove ëª¨ë“œ: ì „ì²´ í™”ë©´ ë¯¸ë””ì–´ + ë™ì¼í•œ í…ìŠ¤íŠ¸ ìœ„ì¹˜
                        if is_video:
                            # ë¹„ë””ì˜¤ëŠ” í•­ìƒ íŒ¨ë‹ off (ì¤‘ì•™ ê³ ì • ë°°ì¹˜)
                            bg_clip = self.create_fullscreen_video_clip(current_image_path, body_duration, enable_panning=False)
                        else:
                            bg_clip = self.create_fullscreen_background_clip(current_image_path, body_duration, enable_panning=enable_panning)

                        # í…ìŠ¤íŠ¸ í´ë¦½ (ê¸°ì¡´ê³¼ ë™ì¼í•œ ìœ„ì¹˜ ìœ ì§€)
                        text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font, title_area_mode=title_area_mode, title_font_size=title_font_size, body_font_size=body_font_size)
                        text_clip = ImageClip(text_image_path).set_duration(body_duration).set_position((0, 0))

                        # ì „ì²´ í™”ë©´ í•©ì„± (íƒ€ì´í‹€ ì—†ìŒ)
                        individual_clip = CompositeVideoClip([bg_clip, text_clip], size=(self.video_width, self.video_height))
                    group_clips.append(individual_clip)
                    print(f"    âœ… {body_key} ì™„ë£Œ: ê°œë³„ ì´ë¯¸ì§€ ì ìš©")
                    
                    # ì˜¤ë””ì˜¤ ì¶”ê°€ (voice_narrationì´ enabledì¼ ë•Œë§Œ)
                    if body_tts_info[2] and voice_narration == "enabled":  # tts_pathê°€ ìˆê³  ìë§‰ ì½ì–´ì£¼ê¸°ê°€ í™œì„±í™”ëœ ê²½ìš°ì—ë§Œ
                        audio_segments.append(AudioFileClip(body_tts_info[2]))

            elif image_allocation_mode == "2_per_image":
                # Mode 1: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (ê·¸ë£¹ ë°©ì‹)
                print("ğŸ–¼ï¸ 2:1 ë§¤ì¹­ ëª¨ë“œ: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ ì‚¬ìš©")
                
                for group_idx in range(0, len(body_keys), 2):
                    group_bodies = body_keys[group_idx:group_idx + 2]
                    # ê·¸ë£¹ ìˆœì„œëŒ€ë¡œ ì´ë¯¸ì§€ ì‚¬ìš© (body1,2 â†’ image0, body3,4 â†’ image1)
                    image_index = min(group_idx // 2, len(local_images) - 1)
                    current_image_path = local_images[image_index]
                    print(f"ê·¸ë£¹ {group_idx//2 + 1}: ì´ë¯¸ì§€ ì¸ë±ìŠ¤ {image_index}, íŒŒì¼: {os.path.basename(current_image_path)}")
                    
                    # ê·¸ë£¹ TTS ì •ë³´ ìˆ˜ì§‘
                    group_tts_info = []
                    group_total_duration = 0.0
                    
                    for body_key in group_bodies:
                        for tts_key, tts_path, tts_duration in tts_files:
                            if tts_key == body_key:
                                group_tts_info.append((body_key, content[body_key], tts_path, tts_duration))
                                group_total_duration += tts_duration
                                break
                        else:
                            group_tts_info.append((body_key, content[body_key], None, 3.0))
                            group_total_duration += 3.0
                    
                    # íŒŒì¼ íƒ€ì… í™•ì¸ (ë¹„ë””ì˜¤ vs ì´ë¯¸ì§€)
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                    is_video = any(current_image_path.lower().endswith(ext) for ext in video_extensions)
                    file_type = "ë¹„ë””ì˜¤" if is_video else "ì´ë¯¸ì§€"
                    
                    print(f"ğŸ“¸ ê·¸ë£¹ {group_idx//2 + 1}: {[info[0] for info in group_tts_info]} â†’ '{os.path.basename(current_image_path)}' ({file_type}, {group_total_duration:.1f}ì´ˆ)")

                    # ì´ë¯¸ì§€ë³„ íŒ¨ë‹ ì˜µì…˜ í™•ì¸
                    enable_panning = True  # ê¸°ë³¸ê°’
                    if image_panning_options is not None and image_index in image_panning_options:
                        enable_panning = image_panning_options[image_index]
                        print(f"ğŸ¨ ì´ë¯¸ì§€ {image_index}: íŒ¨ë‹ ì˜µì…˜ = {enable_panning}")

                    # íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œì— ë”°ë¥¸ ë°°ê²½ í´ë¦½ ìƒì„±
                    if title_area_mode == "keep":
                        # ê¸°ì¡´ ë°©ì‹: íƒ€ì´í‹€ ì˜ì—­ + ë¯¸ë””ì–´ ì˜ì—­
                        if is_video:
                            # ë¹„ë””ì˜¤ëŠ” í•­ìƒ íŒ¨ë‹ off (ì¤‘ì•™ ê³ ì • ë°°ì¹˜)
                            bg_clip = self.create_video_background_clip(current_image_path, group_total_duration, enable_panning=False)
                        else:
                            bg_clip = self.create_continuous_background_clip(current_image_path, group_total_duration, 0.0, enable_panning=enable_panning, title_area_mode=title_area_mode)
                        black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(group_total_duration)
                        title_clip = ImageClip(title_image_path).set_duration(group_total_duration).set_position((0, 0))

                        # í…ìŠ¤íŠ¸ í´ë¦½ë“¤ (ê¸°ì¡´ ìœ„ì¹˜)
                        text_clips = []
                        current_time = 0.0
                        for body_key, body_text, tts_path, duration in group_tts_info:
                            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font, title_area_mode=title_area_mode, title_font_size=title_font_size, body_font_size=body_font_size)
                            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(duration).set_position((0, 0))
                            text_clips.append(text_clip)
                            print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                            current_time += duration

                        # ê¸°ì¡´ ë°©ì‹ í•©ì„±
                        group_clip = CompositeVideoClip([bg_clip, black_top, title_clip] + text_clips, size=(self.video_width, self.video_height))
                    else:
                        # remove ëª¨ë“œ: ì „ì²´ í™”ë©´ ë¯¸ë””ì–´ + ë™ì¼í•œ í…ìŠ¤íŠ¸ ìœ„ì¹˜
                        if is_video:
                            # ë¹„ë””ì˜¤ëŠ” í•­ìƒ íŒ¨ë‹ off (ì¤‘ì•™ ê³ ì • ë°°ì¹˜)
                            bg_clip = self.create_fullscreen_video_clip(current_image_path, group_total_duration, enable_panning=False)
                        else:
                            bg_clip = self.create_fullscreen_background_clip(current_image_path, group_total_duration, enable_panning=enable_panning)

                        # í…ìŠ¤íŠ¸ í´ë¦½ë“¤ (ê¸°ì¡´ê³¼ ë™ì¼í•œ ìœ„ì¹˜ ìœ ì§€)
                        text_clips = []
                        current_time = 0.0
                        for body_key, body_text, tts_path, duration in group_tts_info:
                            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font, title_area_mode=title_area_mode, title_font_size=title_font_size, body_font_size=body_font_size)
                            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(duration).set_position((0, 0))
                            text_clips.append(text_clip)
                            print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                            current_time += duration

                        # ì „ì²´ í™”ë©´ í•©ì„± (íƒ€ì´í‹€ ì—†ìŒ)
                        group_clip = CompositeVideoClip([bg_clip] + text_clips, size=(self.video_width, self.video_height))
                    group_clips.append(group_clip)
                    print(f"    âœ… ê·¸ë£¹ {group_idx//2 + 1} ì™„ë£Œ: ë°°ê²½ ì—°ì† ë³´ì¥")
                    
                    # ì˜¤ë””ì˜¤ ì¶”ê°€ (voice_narrationì´ enabledì¼ ë•Œë§Œ)
                    for _, _, tts_path, _ in group_tts_info:
                        if tts_path and voice_narration == "enabled":
                            audio_segments.append(AudioFileClip(tts_path))

            else:  # image_allocation_mode == "single_for_all"
                # Mode 3: ëª¨ë“  ëŒ€ì‚¬ì— ë¯¸ë””ì–´ 1ê°œ (ë‹¨ì¼ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì—°ì† ì‚¬ìš©)
                print("ğŸ–¼ï¸ 1:ALL ë§¤ì¹­ ëª¨ë“œ: ëª¨ë“  ëŒ€ì‚¬ì— ë™ì¼í•œ ë¯¸ë””ì–´ 1ê°œ ì—°ì† ì‚¬ìš©")
                logger.debug(f"ğŸ” [DEBUG] single_for_all ëª¨ë“œ ì§„ì… - body ê°œìˆ˜: {len(body_keys)}")

                # ì²« ë²ˆì§¸ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ë§Œ ì‚¬ìš©
                if local_images:
                    single_media_path = local_images[0]
                    print(f"ì‚¬ìš©í•  ë¯¸ë””ì–´: {os.path.basename(single_media_path)}")
                    logger.debug(f"ğŸ” [DEBUG] ë¯¸ë””ì–´ íŒŒì¼ ê²½ë¡œ: {single_media_path}")
                    logger.debug(f"ğŸ” [DEBUG] íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(single_media_path)}")

                    # ëª¨ë“  ëŒ€ì‚¬ì˜ TTS ì •ë³´ ìˆ˜ì§‘
                    all_tts_info = []
                    total_duration = 0.0

                    for body_key in body_keys:
                        for tts_key, tts_path, tts_duration in tts_files:
                            if tts_key == body_key:
                                all_tts_info.append((body_key, content[body_key], tts_path, tts_duration))
                                total_duration += tts_duration
                                break
                        else:
                            all_tts_info.append((body_key, content[body_key], None, 3.0))
                            total_duration += 3.0

                    # íŒŒì¼ íƒ€ì… í™•ì¸ (ë¹„ë””ì˜¤ vs ì´ë¯¸ì§€)
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                    is_video = any(single_media_path.lower().endswith(ext) for ext in video_extensions)
                    file_type = "ë¹„ë””ì˜¤" if is_video else "ì´ë¯¸ì§€"
                    logger.debug(f"ğŸ” [DEBUG] íŒŒì¼ íƒ€ì… íŒë³„: is_video={is_video}, file_type={file_type}")

                    print(f"ğŸ“ ëª¨ë“  ëŒ€ì‚¬ ({len(body_keys)}ê°œ): {file_type} ì—°ì† ì‚¬ìš© - {os.path.basename(single_media_path)} (ì´ {total_duration:.1f}ì´ˆ)")

                    # ì´ë¯¸ì§€ë³„ íŒ¨ë‹ ì˜µì…˜ í™•ì¸ (ë‹¨ì¼ ì´ë¯¸ì§€ëŠ” ì¸ë±ìŠ¤ 0)
                    enable_panning = True  # ê¸°ë³¸ê°’
                    if image_panning_options is not None and 0 in image_panning_options:
                        enable_panning = image_panning_options[0]
                        print(f"ğŸ¨ ë‹¨ì¼ ì´ë¯¸ì§€: íŒ¨ë‹ ì˜µì…˜ = {enable_panning}")

                    # íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œì— ë”°ë¥¸ ë°°ê²½ í´ë¦½ ìƒì„±
                    logger.debug(f"ğŸ” [DEBUG] title_area_mode={title_area_mode}, is_video={is_video}")
                    if title_area_mode == "keep":
                        # ê¸°ì¡´ ë°©ì‹: íƒ€ì´í‹€ ì˜ì—­ + ë¯¸ë””ì–´ ì˜ì—­
                        if is_video:
                            # ë¹„ë””ì˜¤ëŠ” í•­ìƒ íŒ¨ë‹ off (ì¤‘ì•™ ê³ ì • ë°°ì¹˜)
                            logger.debug(f"ğŸ” [DEBUG] create_video_background_clip() í˜¸ì¶œ ì‹œì‘ (keep ëª¨ë“œ)")
                            bg_clip = self.create_video_background_clip(single_media_path, total_duration, enable_panning=False)
                            logger.debug(f"ğŸ” [DEBUG] create_video_background_clip() í˜¸ì¶œ ì™„ë£Œ (keep ëª¨ë“œ)")
                        else:
                            bg_clip = self.create_continuous_background_clip(single_media_path, total_duration, 0.0, enable_panning=enable_panning, title_area_mode=title_area_mode)
                        black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(total_duration)
                        title_clip = ImageClip(title_image_path).set_duration(total_duration).set_position((0, 0))

                        # í…ìŠ¤íŠ¸ í´ë¦½ë“¤ (ê¸°ì¡´ ìœ„ì¹˜)
                        text_clips = []
                        current_time = 0.0
                        for body_key, body_text, tts_path, duration in all_tts_info:
                            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font, title_area_mode=title_area_mode, title_font_size=title_font_size, body_font_size=body_font_size)
                            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(duration).set_position((0, 0))
                            text_clips.append(text_clip)
                            print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                            current_time += duration

                        # ê¸°ì¡´ ë°©ì‹ í•©ì„±
                        single_clip = CompositeVideoClip([bg_clip, black_top, title_clip] + text_clips, size=(self.video_width, self.video_height))
                    else:
                        # remove ëª¨ë“œ: ì „ì²´ í™”ë©´ ë¯¸ë””ì–´ + ë™ì¼í•œ í…ìŠ¤íŠ¸ ìœ„ì¹˜
                        if is_video:
                            # ë¹„ë””ì˜¤ëŠ” í•­ìƒ íŒ¨ë‹ off (ì¤‘ì•™ ê³ ì • ë°°ì¹˜)
                            logger.debug(f"ğŸ” [DEBUG] create_fullscreen_video_clip() í˜¸ì¶œ ì‹œì‘ (remove ëª¨ë“œ)")
                            bg_clip = self.create_fullscreen_video_clip(single_media_path, total_duration, enable_panning=False)
                            logger.debug(f"ğŸ” [DEBUG] create_fullscreen_video_clip() í˜¸ì¶œ ì™„ë£Œ (remove ëª¨ë“œ)")
                        else:
                            bg_clip = self.create_fullscreen_background_clip(single_media_path, total_duration, enable_panning=enable_panning)

                        # í…ìŠ¤íŠ¸ í´ë¦½ë“¤ (ê¸°ì¡´ê³¼ ë™ì¼í•œ ìœ„ì¹˜ ìœ ì§€)
                        text_clips = []
                        current_time = 0.0
                        for body_key, body_text, tts_path, duration in all_tts_info:
                            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font, title_area_mode=title_area_mode, title_font_size=title_font_size, body_font_size=body_font_size)
                            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(duration).set_position((0, 0))
                            text_clips.append(text_clip)
                            print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                            current_time += duration

                        # ì „ì²´ í™”ë©´ í•©ì„± (íƒ€ì´í‹€ ì—†ìŒ)
                        single_clip = CompositeVideoClip([bg_clip] + text_clips, size=(self.video_width, self.video_height))

                    group_clips.append(single_clip)
                    print(f"    âœ… ëª¨ë“  ëŒ€ì‚¬ ì™„ë£Œ: ë‹¨ì¼ ë¯¸ë””ì–´ ì—°ì† ì ìš© ({total_duration:.1f}ì´ˆ)")

                    # ì˜¤ë””ì˜¤ ì¶”ê°€ (voice_narrationì´ enabledì¼ ë•Œë§Œ)
                    for _, _, tts_path, _ in all_tts_info:
                        if tts_path and voice_narration == "enabled":
                            audio_segments.append(AudioFileClip(tts_path))

            # ê·¸ë£¹ë“¤ ì—°ê²° (í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì˜µì…˜ì— ë”°ë¼ ì²˜ë¦¬)
            print(f"ğŸ¬ ì˜ìƒ í´ë¦½ë“¤ ì—°ê²°: {len(group_clips)}ê°œ í´ë¦½")
            print(f"ğŸ” [ê·¸ë£¹ëª¨ë“œ] cross_dissolve ê°’: '{cross_dissolve}' (íƒ€ì…: {type(cross_dissolve)})")
            logging.info(f"ğŸ¬ ì˜ìƒ í´ë¦½ë“¤ ì—°ê²°: {len(group_clips)}ê°œ í´ë¦½")
            logging.info(f"ğŸ” [ê·¸ë£¹ëª¨ë“œ] cross_dissolve ê°’: '{cross_dissolve}' (íƒ€ì…: {type(cross_dissolve)})")
            if cross_dissolve == "enabled":
                print("ğŸ¨ [ê·¸ë£¹ëª¨ë“œ] í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ íš¨ê³¼ ì ìš©")
                logging.info("ğŸ¨ [ê·¸ë£¹ëª¨ë“œ] í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ íš¨ê³¼ ì ìš©")
                final_video = self.apply_smart_crossfade_transitions(group_clips, media_files, image_allocation_mode)
            else:
                print("ğŸ¬ [ê·¸ë£¹ëª¨ë“œ] ê¸°ë³¸ ì—°ê²° ë°©ì‹ ì‚¬ìš© (í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ë¯¸ì ìš©)")
                logging.info("ğŸ¬ [ê·¸ë£¹ëª¨ë“œ] ê¸°ë³¸ ì—°ê²° ë°©ì‹ ì‚¬ìš© (í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ë¯¸ì ìš©)")
                final_video = concatenate_videoclips(group_clips, method="compose")
            
            # 8. TTS ì˜¤ë””ì˜¤ë“¤ ì—°ê²°
            final_audio = None
            if audio_segments:
                final_audio = concatenate_audioclips(audio_segments)

                # ìë§‰ ì½ì–´ì£¼ê¸° ì„¤ì •ì— ë”°ë¥¸ TTS ë³¼ë¥¨ ì¡°ì ˆ
                if voice_narration == "disabled":
                    print("ğŸ”‡ ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: TTS ë³¼ë¥¨ì„ 0ìœ¼ë¡œ ì„¤ì •")
                    final_audio = final_audio.volumex(0)  # TTS ìŒì„± ë¬´ìŒ ì²˜ë¦¬
            else:
                print("ğŸ“¢ TTS ì˜¤ë””ì˜¤ ì—†ìŒ (ìë§‰ ì§€ì† ì‹œê°„ ëª¨ë“œ ë˜ëŠ” ìƒì„± ì‹¤íŒ¨)")

            # 9. ë°°ê²½ìŒì•… ë˜ëŠ” ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ê°€
            if music_mood == "none":
                # ìŒì•… ì„ íƒ ì•ˆí•¨: ë¹„ë””ì˜¤ ì›ë³¸ ì†Œë¦¬ ì‚¬ìš©
                print("ğŸ”‡ ìŒì•… ì„ íƒ ì•ˆí•¨ ëª¨ë“œ: ë¹„ë””ì˜¤ ì›ë³¸ ì†Œë¦¬ ì‚¬ìš©")
                video_audio_segments = []

                # ê° í´ë¦½ì—ì„œ ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì¶”ì¶œ
                for i, group_clip in enumerate(group_clips):
                    try:
                        # ë¹„ë””ì˜¤ í´ë¦½ì— ì˜¤ë””ì˜¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                        if hasattr(group_clip, 'audio') and group_clip.audio is not None:
                            video_audio = group_clip.audio
                            video_audio_segments.append(video_audio)
                            print(f"ğŸ“¹ í´ë¦½ {i+1}: ë¹„ë””ì˜¤ ì›ë³¸ ì˜¤ë””ì˜¤ ì¶”ì¶œë¨")
                        else:
                            # ì˜¤ë””ì˜¤ê°€ ì—†ëŠ” ê²½ìš° ë¬´ìŒ ì¶”ê°€
                            silent_audio = AudioFileClip(None).set_duration(group_clip.duration) if hasattr(group_clip, 'duration') else None
                            if silent_audio:
                                video_audio_segments.append(silent_audio)
                            print(f"ğŸ“¸ í´ë¦½ {i+1}: ì´ë¯¸ì§€ - ë¬´ìŒ ì²˜ë¦¬")
                    except Exception as e:
                        print(f"âš ï¸ í´ë¦½ {i+1} ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

                # ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ì™€ TTS í•©ì„±
                if video_audio_segments:
                    combined_video_audio = concatenate_audioclips(video_audio_segments)

                    if voice_narration == "disabled" or final_audio is None:
                        # ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ 100%
                        final_audio = combined_video_audio.volumex(1.0)  # ë¹„ë””ì˜¤ ì›ë³¸ ì†Œë¦¬ 100%
                        print("ğŸ”‡ ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ 100%")
                    else:
                        # ìë§‰ ì½ì–´ì£¼ê¸° ì¶”ê°€: TTS(70%) + ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬(30%) ë¯¹ì‹±
                        final_audio = CompositeAudioClip([
                            final_audio.volumex(0.7),  # TTS ë³¼ë¥¨ 70%
                            combined_video_audio.volumex(0.3)  # ë¹„ë””ì˜¤ ì›ë³¸ ì†Œë¦¬ 30%
                        ])
                        print("ğŸµ TTS + ë¹„ë””ì˜¤ ì›ë³¸ ì˜¤ë””ì˜¤ í•©ì„± ì™„ë£Œ")
                else:
                    if voice_narration == "disabled" or final_audio is None:
                        # ìë§‰ ì½ì–´ì£¼ê¸° ì œê±° + ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì—†ìŒ: ì™„ì „ ë¬´ìŒ
                        print("ğŸ”‡ ìë§‰ ì½ì–´ì£¼ê¸° ì œê±° + ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì—†ìŒ: ì™„ì „ ë¬´ìŒ")
                    else:
                        print("ğŸ”‡ ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì—†ìŒ: TTSë§Œ ì‚¬ìš©")

            elif music_path and os.path.exists(music_path):
                # ë°°ê²½ìŒì•… ì‚¬ìš©
                background_music = AudioFileClip(music_path)

                # ë°°ê²½ìŒì•… ê¸¸ì´ ì¡°ì • ê¸°ì¤€: final_audioê°€ ìˆìœ¼ë©´ ê·¸ ê¸¸ì´, ì—†ìœ¼ë©´ ì˜ìƒ ê¸¸ì´
                target_duration = final_audio.duration if final_audio else final_video.duration

                # ë°°ê²½ìŒì•…ì´ ì˜ìƒë³´ë‹¤ ì§§ìœ¼ë©´ ë°˜ë³µ, ê¸¸ë©´ ìë¥´ê¸°
                if background_music.duration < target_duration:
                    background_music = background_music.loop(duration=target_duration)
                else:
                    background_music = background_music.subclip(0, target_duration)

                if voice_narration == "disabled" or final_audio is None:
                    # ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: ë°°ê²½ìŒì•… 100%
                    final_audio = background_music.volumex(1.0)  # ë°°ê²½ìŒì•… ë³¼ë¥¨ 100%
                    print("ğŸ”‡ ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: ë°°ê²½ìŒì•… 100%")
                else:
                    # ìë§‰ ì½ì–´ì£¼ê¸° ì¶”ê°€: TTS + ë°°ê²½ìŒì•… í•©ì„±
                    background_music = background_music.volumex(0.17)  # ë³¼ë¥¨ 17%
                    final_audio = CompositeAudioClip([final_audio, background_music])
                    print("ğŸµ TTS + ë°°ê²½ìŒì•… í•©ì„± ì™„ë£Œ")

            if final_audio:
                final_video = final_video.set_audio(final_audio)
            else:
                print("ğŸ”‡ ìµœì¢… ì˜¤ë””ì˜¤ ì—†ìŒ: ë¬´ìŒ ì˜ìƒ ìƒì„±")
            
            # 10. ìµœì¢… ì˜ìƒ ì €ì¥
            video_id = str(uuid.uuid4())[:8]
            output_filename = f"reels_{video_id}.mp4"
            output_path = os.path.join(output_folder, output_filename)
            
            print(f"ìµœì¢… ì˜ìƒ ë Œë”ë§ ì‹œì‘: {output_path}")
            final_video.write_videofile(
                output_path,
                fps=self.fps,
                codec='libx264',
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True,
                verbose=False,
                logger=None
            )
            
            print(f"ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_path}")
            return output_path
            
        except Exception as e:
            raise Exception(f"ë¡œì»¬ ì´ë¯¸ì§€ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def create_video(self, content, image_urls, music_path, output_folder, image_allocation_mode="2_per_image", text_position="bottom", text_style="outline"):
        """ë¦´ìŠ¤ ì˜ìƒ ìƒì„± (414x896 í•´ìƒë„, ì—¬ëŸ¬ ì´ë¯¸ì§€ ì§€ì›)"""
        try:
            # ì—¬ëŸ¬ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            image_paths = []
            for i, image_url in enumerate(image_urls):
                print(f"ì´ë¯¸ì§€ {i+1}/{len(image_urls)} ë‹¤ìš´ë¡œë“œ ì¤‘: {image_url}")
                image_path = self.download_image(image_url)
                image_paths.append(image_path)
            
            # ì œëª© ì´ë¯¸ì§€ ìƒì„± (504x220, ì •í™•í•œ íƒ€ì´í‹€ ì˜ì—­)
            title_image_path = self.create_title_image(
                content['title'],
                self.video_width,
                220,
                title_font
            )
            
            # ê° bodyë³„ë¡œ ê°œë³„ TTS ìƒì„± (ë¹ˆ ê°’ ì œì™¸, ìˆœì„œ ë³´ì¥)
            body_keys = [key for key in content.keys() if key.startswith('body') and content[key].strip()]
            body_keys.sort(key=lambda x: int(x.replace('body', '')))  # body1, body2, ... ìˆœì„œë¡œ ì •ë ¬
            print(f"ğŸ¯ body ìˆœì„œ í™•ì¸: {body_keys}")
            tts_files = []
            
            # ì œëª© TTS ìƒì„±
            print("ì œëª© TTS ìƒì„± ì¤‘...")
            title_tts = self.create_tts_audio(content['title'])
            if title_tts:
                title_duration = self.get_audio_duration(title_tts)
                tts_files.append(('title', title_tts, title_duration))
                print(f"ì œëª© TTS ì™„ë£Œ: {title_duration:.1f}ì´ˆ")
            
            # ê° body TTS ìƒì„±
            logger.info(f"ğŸ” [ë””ë²„ê¹…-1per] voice_narration='{voice_narration}' (íƒ€ì…: {type(voice_narration).__name__})")
            logger.info(f"ğŸ” [ë””ë²„ê¹…-1per] subtitle_duration={subtitle_duration} (íƒ€ì…: {type(subtitle_duration).__name__})")
            for body_key in body_keys:
                # ìë§‰ ì§€ì† ì‹œê°„ ìµœì í™”: voice_narration=disabledì´ê³  subtitle_duration > 0ì´ë©´ TTS ìƒì„± ê±´ë„ˆëœ€
                if voice_narration == "disabled" and subtitle_duration > 0:
                    logger.info(f"â±ï¸ {body_key} TTS ê±´ë„ˆëœ€ (ìë§‰ ì§€ì† ì‹œê°„ {subtitle_duration}ì´ˆ ì‚¬ìš©)")
                    tts_files.append((body_key, None, subtitle_duration))
                else:
                    logger.info(f"ğŸ™ï¸ {body_key} TTS ìƒì„± ì¤‘... ë‚´ìš©: '{content[body_key][:50]}...'")
                    body_tts = self.create_tts_audio(content[body_key])
                    if body_tts:
                        body_duration = self.get_audio_duration(body_tts)
                        tts_files.append((body_key, body_tts, body_duration))
                        logger.info(f"âœ… {body_key} TTS ì™„ë£Œ: {body_duration:.1f}ì´ˆ")
                    else:
                        logger.error(f"âŒ {body_key} TTS ìƒì„± ì‹¤íŒ¨")
            
            # ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
            print(f"ğŸ¬ ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ: {image_allocation_mode}")
            body_clips = []
            audio_segments = []  # TTS ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë“¤
            
            if image_allocation_mode == "1_per_image":
                # Mode 2: body 1ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (1:1 ë§¤ì¹­)
                print("ğŸ–¼ï¸ 1:1 ë§¤ì¹­ ëª¨ë“œ: bodyë³„ë¡œ ê°ê° ë‹¤ë¥¸ ì´ë¯¸ì§€ ì‚¬ìš©")

                for i, body_key in enumerate(body_keys):
                    print(f"ğŸ¯ ë””ë²„ê·¸ 2: i={i}, body_key={body_key} (create_video_with_local_images)")
                    # í•´ë‹¹ bodyì˜ TTS ì •ë³´ ì°¾ê¸°
                    body_tts_info = None
                    for tts_key, tts_path, tts_duration in tts_files:
                        if tts_key == body_key:
                            body_tts_info = (tts_path, tts_duration)
                            break
                    
                    if not body_tts_info:
                        print(f"{body_key}ì˜ TTSë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œê°„ ì‚¬ìš©.")
                        clip_duration = 3.0
                        tts_path = None
                    else:
                        tts_path, clip_duration = body_tts_info
                    
                    # bodyë³„ë¡œ ê°œë³„ ì´ë¯¸ì§€ í• ë‹¹ (ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ì‚¬ìš©)
                    image_index = min(i, len(image_paths) - 1)  # body1 â†’ image0, body2 â†’ image1, body3 â†’ image2
                    current_image_path = image_paths[image_index]
                    
                    print(f"{body_key} í´ë¦½ ìƒì„±: {clip_duration:.1f}ì´ˆ, ì´ë¯¸ì§€: {image_index + 1}/{len(image_paths)} (1:1 ë§¤ì¹­)")
                    
                    # ê°œë³„ body í´ë¦½ ìƒì„±
                    bg_clip = self.create_background_clip(current_image_path, clip_duration)
                    black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(clip_duration).set_position((0, 0))
                    title_clip = ImageClip(title_image_path).set_duration(clip_duration).set_position((0, 0))

                    text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font, title_area_mode=title_area_mode)
                    text_clip = ImageClip(text_image_path).set_duration(clip_duration).set_position((0, 0))
                    
                    # ê°œë³„ í´ë¦½ í•©ì„±
                    combined_clip = CompositeVideoClip([bg_clip, black_top, title_clip, text_clip], size=(self.video_width, self.video_height))
                    body_clips.append(combined_clip)
                    
                    # ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
                    if tts_path and os.path.exists(tts_path):
                        body_audio = AudioFileClip(tts_path)
                        audio_segments.append(body_audio)
                        print(f"{body_key} ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€")
                        
            elif image_allocation_mode == "2_per_image":
                # Mode 1: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (ê·¸ë£¹ ë°©ì‹)
                print("ğŸ–¼ï¸ 2:1 ë§¤ì¹­ ëª¨ë“œ: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ ì‚¬ìš©")

                for i, body_key in enumerate(body_keys):
                    print(f"ğŸ¯ ë””ë²„ê·¸ 3: i={i}, body_key={body_key} (2_per_image mode)")
                    # í•´ë‹¹ bodyì˜ TTS ì •ë³´ ì°¾ê¸°
                    body_tts_info = None
                    for tts_key, tts_path, tts_duration in tts_files:
                        if tts_key == body_key:
                            body_tts_info = (tts_path, tts_duration)
                            break
                    
                    if not body_tts_info:
                        print(f"{body_key}ì˜ TTSë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œê°„ ì‚¬ìš©.")
                        clip_duration = 3.0
                        tts_path = None
                    else:
                        tts_path, clip_duration = body_tts_info
                    
                    # body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ í• ë‹¹ (body1,2 â†’ image0, body3,4 â†’ image1)
                    image_index = min(i // 2, len(image_paths) - 1)
                    current_image_path = image_paths[image_index]
                    
                    print(f"{body_key} í´ë¦½ ìƒì„±: {clip_duration:.1f}ì´ˆ, ì´ë¯¸ì§€: {image_index + 1}/{len(image_paths)} (2:1 ë§¤ì¹­)")
                    
                    # ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ í´ë¦½ ìƒì„±
                    bg_clip = self.create_background_clip(current_image_path, clip_duration)
                    black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(clip_duration).set_position((0, 0))
                    title_clip = ImageClip(title_image_path).set_duration(clip_duration).set_position((0, 0))

                    text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font, title_area_mode=title_area_mode)
                    text_clip = ImageClip(text_image_path).set_duration(clip_duration).set_position((0, 0))
                    
                    # í´ë¦½ í•©ì„±
                    combined_clip = CompositeVideoClip([bg_clip, black_top, title_clip, text_clip], size=(self.video_width, self.video_height))
                    body_clips.append(combined_clip)
                    
                    # ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
                    if tts_path and os.path.exists(tts_path):
                        body_audio = AudioFileClip(tts_path)
                        audio_segments.append(body_audio)
                        print(f"{body_key} ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€")

            else:  # image_allocation_mode == "single_for_all"
                # Mode 3: ëª¨ë“  ëŒ€ì‚¬ì— ë¯¸ë””ì–´ 1ê°œ (ë‹¨ì¼ ì´ë¯¸ì§€ ì—°ì† ì‚¬ìš©)
                print("ğŸ–¼ï¸ 1:ALL ë§¤ì¹­ ëª¨ë“œ: ëª¨ë“  ëŒ€ì‚¬ì— ë™ì¼í•œ ì´ë¯¸ì§€ 1ê°œ ì—°ì† ì‚¬ìš©")

                # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©
                if image_paths:
                    single_image_path = image_paths[0]
                    print(f"ì‚¬ìš©í•  ì´ë¯¸ì§€: {single_image_path}")

                    # ëª¨ë“  ëŒ€ì‚¬ì˜ TTS ì •ë³´ ìˆ˜ì§‘
                    all_tts_info = []
                    total_duration = 0.0

                    for body_key in body_keys:
                        body_tts_info = None
                        for tts_key, tts_path, tts_duration in tts_files:
                            if tts_key == body_key:
                                body_tts_info = (tts_path, tts_duration)
                                break

                        if not body_tts_info:
                            print(f"{body_key}ì˜ TTSë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œê°„ ì‚¬ìš©.")
                            all_tts_info.append((body_key, None, 3.0))
                            total_duration += 3.0
                        else:
                            tts_path, clip_duration = body_tts_info
                            all_tts_info.append((body_key, tts_path, clip_duration))
                            total_duration += clip_duration

                    print(f"ğŸ“ ëª¨ë“  ëŒ€ì‚¬ ({len(body_keys)}ê°œ): ì´ë¯¸ì§€ ì—°ì† ì‚¬ìš© - {single_image_path} (ì´ {total_duration:.1f}ì´ˆ)")

                    # ì—°ì†ëœ ë°°ê²½ í´ë¦½ ìƒì„±
                    bg_clip = self.create_continuous_background_clip(single_image_path, total_duration, 0.0)
                    black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(total_duration)

                    # íƒ€ì´í‹€ í´ë¦½ ìƒì„±
                    title_image_path = self.create_text_image(content['title'], self.video_width, 220, text_position, text_style, title_font)
                    title_clip = ImageClip(title_image_path).set_duration(total_duration).set_position((0, 0))

                    # í…ìŠ¤íŠ¸ í´ë¦½ë“¤ ìƒì„± (ì‹œê°„ì— ë”°ë¼ ìˆœì°¨ í‘œì‹œ)
                    text_clips = []
                    current_time = 0.0
                    for body_key, tts_path, duration in all_tts_info:
                        body_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height, text_position, text_style, body_font)
                        text_clip = ImageClip(body_image_path).set_start(current_time).set_duration(duration).set_position((0, 0))
                        text_clips.append(text_clip)
                        print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                        current_time += duration

                    # í•˜ë‚˜ì˜ ì—°ì†ëœ í´ë¦½ìœ¼ë¡œ í•©ì„±
                    single_continuous_clip = CompositeVideoClip([bg_clip, black_top, title_clip] + text_clips, size=(self.video_width, self.video_height))
                    body_clips.append(single_continuous_clip)

                    # ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
                    for body_key, tts_path, duration in all_tts_info:
                        if tts_path and os.path.exists(tts_path):
                            body_audio = AudioFileClip(tts_path)
                            audio_segments.append(body_audio)
                            print(f"{body_key} ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€")

                    print(f"    âœ… ëª¨ë“  ëŒ€ì‚¬ ì™„ë£Œ: ë‹¨ì¼ ì´ë¯¸ì§€ ì—°ì† ì ìš© ({total_duration:.1f}ì´ˆ)")

            # ì „ì²´ ì˜ìƒ ì—°ê²° (í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì˜µì…˜ì— ë”°ë¼ ì²˜ë¦¬)
            print(f"ğŸ¬ ë³¸ë¬¸ í´ë¦½ë“¤ ì—°ê²°: {len(body_clips)}ê°œ í´ë¦½")
            print(f"ğŸ” [ì¼ë°˜ëª¨ë“œ] cross_dissolve ê°’: '{cross_dissolve}' (íƒ€ì…: {type(cross_dissolve)})")
            logging.info(f"ğŸ¬ ë³¸ë¬¸ í´ë¦½ë“¤ ì—°ê²°: {len(body_clips)}ê°œ í´ë¦½")
            logging.info(f"ğŸ” [ì¼ë°˜ëª¨ë“œ] cross_dissolve ê°’: '{cross_dissolve}' (íƒ€ì…: {type(cross_dissolve)})")
            if cross_dissolve == "enabled":
                print("ğŸ¨ [ì¼ë°˜ëª¨ë“œ] í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ íš¨ê³¼ ì ìš©")
                logging.info("ğŸ¨ [ì¼ë°˜ëª¨ë“œ] í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ íš¨ê³¼ ì ìš©")
                final_video = self.apply_smart_crossfade_transitions(body_clips, media_files, image_allocation_mode)
            else:
                print("ğŸ¬ [ì¼ë°˜ëª¨ë“œ] ê¸°ë³¸ ì—°ê²° ë°©ì‹ ì‚¬ìš© (í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ë¯¸ì ìš©)")
                logging.info("ğŸ¬ [ì¼ë°˜ëª¨ë“œ] ê¸°ë³¸ ì—°ê²° ë°©ì‹ ì‚¬ìš© (í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ë¯¸ì ìš©)")
                final_video = concatenate_videoclips(body_clips, method="compose")
            print(f"ìµœì¢… ë¹„ë””ì˜¤ ê¸¸ì´: {final_video.duration:.1f}ì´ˆ")
            
            # TTS ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì—°ê²°
            combined_tts = None
            if audio_segments:
                print(f"TTS ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ê°œìˆ˜: {len(audio_segments)}")
                combined_tts = concatenate_audioclips(audio_segments)
                print(f"ê²°í•©ëœ TTS ê¸¸ì´: {combined_tts.duration:.1f}ì´ˆ")

                # ìë§‰ ì½ì–´ì£¼ê¸° ì„¤ì •ì— ë”°ë¥¸ TTS ë³¼ë¥¨ ì¡°ì ˆ
                if voice_narration == "disabled":
                    print("ğŸ”‡ ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: TTS ë³¼ë¥¨ì„ 0ìœ¼ë¡œ ì„¤ì •")
                    combined_tts = combined_tts.volumex(0)  # TTS ìŒì„± ë¬´ìŒ ì²˜ë¦¬

                # ë°°ê²½ìŒì•… ë˜ëŠ” ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ê°€
                audio_tracks = [combined_tts]
            else:
                print("ğŸ“¢ TTS ì˜¤ë””ì˜¤ ì—†ìŒ (ìë§‰ ì§€ì† ì‹œê°„ ëª¨ë“œ ë˜ëŠ” ìƒì„± ì‹¤íŒ¨)")
                audio_tracks = []

                if music_mood == "none":
                    print("ìŒì•… ì„ íƒ ì•ˆí•¨ - ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ì¶œ ë° ì¶”ê°€ ì¤‘...")
                    # ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ì¶œ
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                    if media_files:
                        for media_file in media_files:
                            media_path, file_type = media_file
                            if file_type == "video" and any(media_path.lower().endswith(ext) for ext in video_extensions):
                                try:
                                    video_audio = VideoFileClip(media_path).audio
                                    if video_audio is not None:
                                        # ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ê¸¸ì´ ì¡°ì •: TTSê°€ ìˆìœ¼ë©´ TTS ê¸¸ì´ì—, ì—†ìœ¼ë©´ ì˜ìƒ ê¸¸ì´ì— ë§ì¶¤
                                        target_duration = combined_tts.duration if combined_tts else final_video.duration
                                        if video_audio.duration < target_duration:
                                            video_audio = video_audio.loop(duration=target_duration)
                                        else:
                                            video_audio = video_audio.subclip(0, target_duration)
                                        # ìë§‰ ì½ì–´ì£¼ê¸° ì„¤ì •ì— ë”°ë¥¸ ë¹„ë””ì˜¤ ë³¼ë¥¨ ì¡°ì ˆ
                                        if voice_narration == "disabled":
                                            # TTS ìŒì„±ì´ êº¼ì§„ ê²½ìš° ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ë¥¼ 100%ë¡œ ì„¤ì •
                                            video_audio = video_audio.volumex(1.0)
                                            print("ğŸ”Š ìë§‰ ì½ì–´ì£¼ê¸° êº¼ì§ - ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ 100%")
                                        else:
                                            # TTSì™€ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•´ 50% ë³¼ë¥¨ìœ¼ë¡œ ì„¤ì •
                                            video_audio = video_audio.volumex(0.5)
                                            print("ğŸ”Š ìë§‰ ì½ì–´ì£¼ê¸° ì¼œì§ - ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ 50%")
                                        audio_tracks.append(video_audio)
                                        print(f"ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ê°€: {media_path}")
                                        break  # ì²« ë²ˆì§¸ ë¹„ë””ì˜¤ì˜ ì†Œë¦¬ë§Œ ì‚¬ìš©
                                except Exception as e:
                                    print(f"ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨ ({media_path}): {e}")
                                    continue
                    else:
                        print("âš ï¸ ë¯¸ë””ì–´ íŒŒì¼ ì •ë³´ ì—†ìŒ - ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì‚¬ìš© ë¶ˆê°€")
                elif os.path.exists(music_path):
                    print("ë°°ê²½ìŒì•… ì¶”ê°€ ì¤‘...")
                    # ìë§‰ ì½ì–´ì£¼ê¸° ì„¤ì •ì— ë”°ë¥¸ ë°°ê²½ìŒì•… ë³¼ë¥¨ ì¡°ì ˆ
                    if voice_narration == "disabled" or combined_tts is None:
                        # TTS ìŒì„±ì´ êº¼ì§„ ê²½ìš° ë˜ëŠ” TTS ì—†ëŠ” ê²½ìš° ë°°ê²½ìŒì•…ì„ 100%ë¡œ ì„¤ì •
                        bg_music = AudioFileClip(music_path).volumex(1.0)
                        print("ğŸµ ìë§‰ ì½ì–´ì£¼ê¸° êº¼ì§ - ë°°ê²½ìŒì•… 100%")
                    else:
                        # TTSê°€ ë” ì˜ ë“¤ë¦¬ë„ë¡ 17%ë¡œ ë‚®ì¶¤
                        bg_music = AudioFileClip(music_path).volumex(0.17)
                        print("ğŸµ ìë§‰ ì½ì–´ì£¼ê¸° ì¼œì§ - ë°°ê²½ìŒì•… 17%")

                    # ë°°ê²½ìŒì•… ê¸¸ì´ ì¡°ì •: TTSê°€ ìˆìœ¼ë©´ TTS ê¸¸ì´ì—, ì—†ìœ¼ë©´ ì˜ìƒ ê¸¸ì´ì— ë§ì¶¤
                    target_duration = combined_tts.duration if combined_tts else final_video.duration
                    if bg_music.duration < target_duration:
                        bg_music = bg_music.loop(duration=target_duration)
                    else:
                        bg_music = bg_music.subclip(0, target_duration)
                    audio_tracks.append(bg_music)
                
                # ì˜¤ë””ì˜¤ í•©ì„±
                if len(audio_tracks) > 1:
                    print("TTS + ë°°ê²½ìŒì•… í•©ì„± ì¤‘...")
                    final_audio = CompositeAudioClip(audio_tracks)
                    final_video = final_video.set_audio(final_audio)
                    print("ìµœì¢… ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ ì¶”ê°€ ì™„ë£Œ")
                elif len(audio_tracks) == 1:
                    print("ë‹¨ì¼ ì˜¤ë””ì˜¤ íŠ¸ë™ ì‚¬ìš©")
                    final_audio = audio_tracks[0]
                    final_video = final_video.set_audio(final_audio)
                    print("ìµœì¢… ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ ì¶”ê°€ ì™„ë£Œ")
                else:
                    print("ğŸ”‡ ì˜¤ë””ì˜¤ íŠ¸ë™ ì—†ìŒ: ë¬´ìŒ ì˜ìƒ ìƒì„±")

            # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ìƒì„±
            output_filename = f"reels_{uuid.uuid4().hex[:8]}.mp4"
            output_path = os.path.join(output_folder, output_filename)
            
            # ì˜ìƒ ë Œë”ë§ (ì´ë¯¸ 414x896ìœ¼ë¡œ êµ¬ì„±ë¨)
            final_video.write_videofile(
                output_path,
                fps=self.fps,
                codec='libx264',
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True,
                verbose=False,
                logger=None
            )
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(image_path):
                os.unlink(image_path)
            if os.path.exists(title_image_path):
                os.unlink(title_image_path)
            
            # ëª¨ë“  TTS íŒŒì¼ ì •ë¦¬
            for tts_key, tts_path, tts_duration in tts_files:
                if os.path.exists(tts_path):
                    os.unlink(tts_path)
                    print(f"{tts_key} TTS íŒŒì¼ ì •ë¦¬: {tts_path}")
            
            return output_path
            
        except Exception as e:
            raise Exception(f"Video generation failed: {str(e)}")
    
    def scan_uploads_folder(self, uploads_folder="uploads"):
        """uploads í´ë”ë¥¼ ìŠ¤ìº”í•˜ì—¬ íŒŒì¼ë“¤ì„ ì°¾ê³  ë¶„ë¥˜"""
        scan_result = {
            'json_file': None,
            'image_files': [],  # í˜¸í™˜ì„± ìœ ì§€
            'media_files': []   # ìƒˆë¡œìš´ ë¯¸ë””ì–´ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
        }
        
        if not os.path.exists(uploads_folder):
            print(f"âŒ {uploads_folder} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return scan_result
        
        # JSON íŒŒì¼ ì°¾ê¸° (text.json)
        json_path = os.path.join(uploads_folder, "text.json")
        if os.path.exists(json_path):
            scan_result['json_file'] = json_path
            print(f"âœ… JSON íŒŒì¼ ë°œê²¬: {json_path}")
        
        # ìŒì•… íŒŒì¼ì€ ë” ì´ìƒ uploadsì—ì„œ ì°¾ì§€ ì•ŠìŒ (bgm í´ë” ì§ì ‘ ì‚¬ìš©)
        
        # ë¯¸ë””ì–´ íŒŒì¼ë“¤ ì°¾ê¸° (ì´ë¯¸ì§€ + ë¹„ë””ì˜¤)
        image_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.webp', '.bmp', '.heic', '.heif']
        video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
        all_extensions = image_extensions + video_extensions
        
        # ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ë¯¸ë””ì–´ íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ì •ë ¬
        media_files = []
        image_files = []  # í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
        
        # re ëª¨ë“ˆ import (íŒ¨í„´ 2ì—ì„œ ì‚¬ìš©)
        import re

        for filename in os.listdir(uploads_folder):
            if any(filename.lower().endswith(ext) for ext in all_extensions):
                # íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì—„ê²©í•œ íŒ¨í„´ë§Œ í—ˆìš©)
                name_without_ext = os.path.splitext(filename)[0]
                file_number = None

                # íŒ¨í„´ 1: ìˆœìˆ˜ ìˆ«ì (ì˜ˆ: "1.jpg", "10.png", "25.webp")
                if name_without_ext.isdigit():
                    file_number = int(name_without_ext)
                    print(f"âœ… íŒ¨í„´ 1 ë§¤ì¹­: {filename} â†’ {file_number}")
                # íŒ¨í„´ 2: ìˆ«ìë¡œ ì‹œì‘ + ì–¸ë”ìŠ¤ì½”ì–´ (ì˜ˆ: "1_image.jpg", "10_video.mp4")
                elif re.match(r'^(\d+)_', name_without_ext):
                    match = re.match(r'^(\d+)_', name_without_ext)
                    file_number = int(match.group(1))
                    print(f"âœ… íŒ¨í„´ 2 ë§¤ì¹­: {filename} â†’ {file_number}")
                # ê·¸ ì™¸ ëª¨ë“  íŒŒì¼ì€ ë¬´ì‹œ (preview_, screenshot_, generated_image_pair_ ë“±)
                else:
                    print(f"â­ï¸ ë¬´ì‹œ: {filename} (ì—…ë¡œë“œ íŒŒì¼ íŒ¨í„´ ì•„ë‹˜)")
                    continue

                # file_numberê°€ ì¶”ì¶œëœ ê²½ìš°ë§Œ ì²˜ë¦¬
                if file_number is not None:
                    full_path = os.path.join(uploads_folder, filename)

                    # íŒŒì¼ íƒ€ì… ê²°ì •
                    is_video = any(filename.lower().endswith(ext) for ext in video_extensions)
                    file_type = "video" if is_video else "image"

                    media_files.append((file_number, full_path, file_type))

                    # í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ image_filesì—ë„ ì¶”ê°€
                    image_files.append((file_number, full_path))
        
        # ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬
        media_files.sort(key=lambda x: x[0])
        image_files.sort(key=lambda x: x[0])
        
        # ê²°ê³¼ ì €ì¥
        scan_result['media_files'] = [(path, file_type) for _, path, file_type in media_files]
        scan_result['image_files'] = [path for _, path in image_files]  # í˜¸í™˜ì„± ìœ ì§€
        
        print(f"ğŸ“Š ë¯¸ë””ì–´ íŒŒì¼ {len(scan_result['media_files'])}ê°œ ë°œê²¬:")
        for i, (media_path, file_type) in enumerate(scan_result['media_files'], 1):
            print(f"   {i}. {os.path.basename(media_path)} ({file_type})")
        
        return scan_result
    
    def create_video_from_uploads(self, output_folder, bgm_file_path=None, image_allocation_mode="2_per_image", text_position="bottom", text_style="outline", title_area_mode="keep", title_font="BMYEONSUNG_otf.otf", body_font="BMYEONSUNG_otf.otf", title_font_size=42, body_font_size=36, uploads_folder="uploads", music_mood="bright", voice_narration="enabled", cross_dissolve="enabled", subtitle_duration=0.0, image_panning_options=None):
        """uploads í´ë”ì˜ íŒŒì¼ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ìƒì„± (ê¸°ì¡´ ë©”ì„œë“œ ì¬ì‚¬ìš©)

        Args:
            image_panning_options: ì´ë¯¸ì§€ë³„ íŒ¨ë‹ ì˜µì…˜ ë”•ì…”ë„ˆë¦¬ (ì˜ˆ: {0: True, 1: False})
        """
        try:
            print("ğŸš€ uploads í´ë” ê¸°ë°˜ ì˜ìƒ ìƒì„± ì‹œì‘")

            # uploads í´ë” ìŠ¤ìº”
            scan_result = self.scan_uploads_folder(uploads_folder)

            # í•„ìˆ˜ íŒŒì¼ ê²€ì¦
            if not scan_result['json_file']:
                raise Exception("text.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")

            if not scan_result['image_files']:
                raise Exception("ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")

            # JSON ë‚´ìš© ë¡œë“œ
            with open(scan_result['json_file'], 'r', encoding='utf-8') as f:
                content = json.load(f)
            print(f"âœ… JSON ë‚´ìš© ë¡œë“œ: {scan_result['json_file']}")

            # ìŒì•… íŒŒì¼ ì„¤ì • (bgm_file_path ì§ì ‘ ì‚¬ìš©)
            music_path = bgm_file_path or ""
            if music_path and os.path.exists(music_path):
                print(f"âœ… ìŒì•… íŒŒì¼ ì‚¬ìš©: {music_path}")
            else:
                print("âš ï¸  ìŒì•… íŒŒì¼ ì—†ìŒ - ìŒì„±ë§Œ ì‚¬ìš©")
                music_path = ""

            # ê¸°ì¡´ create_video_with_local_images ë°©ì‹ ì¬ì‚¬ìš©
            # ìŠ¤ìº”ëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ë¡œ ë¡œì»¬ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ëŒ€ì²´
            self._temp_local_images = scan_result['image_files']

            # ê¸°ì¡´ ë©”ì„œë“œ í˜¸ì¶œ (ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ, í…ìŠ¤íŠ¸ ìœ„ì¹˜, í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼, íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œ, í°íŠ¸ ì„¤ì •, í°íŠ¸ í¬ê¸°, ìë§‰ ì½ì–´ì£¼ê¸°, ìë§‰ ì§€ì† ì‹œê°„, íŒ¨ë‹ ì˜µì…˜ ì „ë‹¬)
            return self.create_video_with_local_images(content, music_path, output_folder, image_allocation_mode, text_position, text_style, title_area_mode, title_font, body_font, title_font_size, body_font_size, music_mood, scan_result['media_files'], voice_narration, cross_dissolve, subtitle_duration, image_panning_options)

        except Exception as e:
            raise Exception(f"uploads í´ë” ê¸°ë°˜ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def get_local_images(self, test_folder="./test"):
        """test í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì´ë¦„ìˆœìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        # uploads í´ë” ì‚¬ìš© ì‹œ ì„ì‹œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
        if hasattr(self, '_temp_local_images') and self._temp_local_images:
            images = self._temp_local_images
            self._temp_local_images = None  # ì‚¬ìš© í›„ ì •ë¦¬
            print(f"ì—…ë¡œë“œ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {len(images)}ê°œ (ìˆœì„œëŒ€ë¡œ)")
            for i, file in enumerate(images):
                print(f"  {i+1}. {os.path.basename(file)}")
            return images
        
        # ê¸°ì¡´ test í´ë” ë¡œì§
        import glob
        
        # ì´ë¯¸ì§€ í™•ì¥ì íŒ¨í„´ (webp ì¶”ê°€)
        image_patterns = ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.gif", "*.webp"]
        image_files = []
        
        for pattern in image_patterns:
            files = glob.glob(os.path.join(test_folder, pattern))
            files.extend(glob.glob(os.path.join(test_folder, pattern.upper())))
            image_files.extend(files)
        
        # ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬ (1.png, 2.png, 3.png, 4.png)
        import re
        def natural_sort_key(path):
            filename = os.path.basename(path).lower()
            # ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
            numbers = re.findall(r'\d+', filename)
            if numbers:
                return int(numbers[0])  # ì²« ë²ˆì§¸ ìˆ«ìë¡œ ì •ë ¬
            else:
                return float('inf')  # ìˆ«ìê°€ ì—†ìœ¼ë©´ ë§¨ ë’¤ë¡œ
        
        image_files.sort(key=natural_sort_key)
        
        print(f"ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {len(image_files)}ê°œ (ìˆ«ì ìˆœì„œëŒ€ë¡œ)")
        for i, file in enumerate(image_files):
            print(f"  {i+1}. {os.path.basename(file)}")
        
        if len(image_files) == 0:
            print("âŒ test í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            print(f"âœ… ì´ë¯¸ì§€ ì‚¬ìš© ìˆœì„œ: {' â†’ '.join([os.path.basename(f) for f in image_files])}")
        
        return image_files
    def create_fullscreen_background_clip(self, image_path, duration, enable_panning=True):
        """ì „ì²´ í™”ë©´(504x890)ìš© ì´ë¯¸ì§€ ë°°ê²½ í´ë¦½ ìƒì„± (EXIF + ê³ í’ˆì§ˆ)

        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
            duration: í´ë¦½ ì§€ì† ì‹œê°„
            enable_panning: íŒ¨ë‹ í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        logger.info(f"ğŸ–¼ï¸ ì „ì²´ í™”ë©´ ì´ë¯¸ì§€ í´ë¦½ ìƒì„±: {os.path.basename(image_path)} (panning: {enable_panning})")

        try:
            # ì´ë¯¸ì§€ ë¡œë“œ + EXIF ì ìš© + ê³ í’ˆì§ˆ ë¦¬ì‚¬ì´ì¦ˆ
            with Image.open(image_path) as img:
                # âœ… EXIF orientation ì ìš© (ì•„ì´í°/HEIC ì‚¬ì§„ íšŒì „ ë¬¸ì œ í•´ê²°)
                img = ImageOps.exif_transpose(img) or img
                orig_width, orig_height = img.size
                logger.info(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€: {orig_width}x{orig_height}")

                # ì‘ì—… ì˜ì—­: ì „ì²´ í™”ë©´ 504x890
                work_width = self.video_width
                work_height = self.video_height
                work_aspect_ratio = work_width / work_height
                image_aspect_ratio = orig_width / orig_height

                logger.info(f"ğŸ¯ ëª©í‘œ: ì „ì²´ í™”ë©´ {work_width}x{work_height}")
                logger.info(f"ğŸ“Š ì´ë¯¸ì§€ ì¢…íš¡ë¹„: {image_aspect_ratio:.3f}")

                # ============================================
                # 1ë‹¨ê³„: ë¦¬ì‚¬ì´ì§• (íŒ¨ë‹ ì˜µì…˜ì— ë”°ë¼ ë¶„ê¸°)
                # ============================================
                logger.info(f"\n{'='*50}")
                logger.info(f"ğŸ“ 1ë‹¨ê³„: ë¦¬ì‚¬ì´ì§• ì‹œì‘ (íŒ¨ë‹: {enable_panning})")
                logger.info(f"{'='*50}")

                if enable_panning:
                    # íŒ¨ë‹ í™œì„±í™”: ê¸°ì¡´ 3ê°€ì§€ íƒ€ì… ë¶„ë¥˜ ë¡œì§
                    if image_aspect_ratio > 0.590:
                        # ê°€ë¡œí˜•: ë†’ì´ 890px ê³ ì •
                        resized_height = work_height
                        resized_width = int(orig_width * resized_height / orig_height)

                        logger.info(f"ğŸ”³ ê°€ë¡œí˜• ì´ë¯¸ì§€ (aspect > 0.590)")
                        logger.info(f"   ì›ë³¸: {orig_width}x{orig_height} â†’ resizedImage: {resized_width}x{resized_height}")

                        # PIL ë¦¬ì‚¬ì´ì¦ˆ
                        try:
                            resized_img = img.resize((resized_width, resized_height), Image.Resampling.LANCZOS)
                        except AttributeError:
                            resized_img = img.resize((resized_width, resized_height), Image.LANCZOS)

                    elif image_aspect_ratio >= 0.540:
                        # íŠ¹ìˆ˜ë¹„ìœ¨: 2ë‹¨ê³„ ë¦¬ì‚¬ì´ì§• (1100px â†’ 890px í¬ë¡­)
                        logger.info(f"â­ íŠ¹ìˆ˜ë¹„ìœ¨ ì´ë¯¸ì§€ (0.540 â‰¤ aspect â‰¤ 0.590)")

                        # Step A: ë†’ì´ 1100pxë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                        temp_height = 1100
                        temp_width = int(orig_width * temp_height / orig_height)

                        logger.info(f"   Step A: ì›ë³¸ {orig_width}x{orig_height} â†’ ì„ì‹œ {temp_width}x{temp_height}")

                        try:
                            temp_img = img.resize((temp_width, temp_height), Image.Resampling.LANCZOS)
                        except AttributeError:
                            temp_img = img.resize((temp_width, temp_height), Image.LANCZOS)

                        # Step B: ìƒí•˜ í¬ë¡­í•˜ì—¬ 890pxë¡œ ì¡°ì •
                        crop_top = (temp_height - work_height) // 2  # (1100-890)/2 = 105
                        crop_bottom = crop_top + work_height         # 105 + 890 = 995

                        logger.info(f"   Step B: ìƒí•˜ í¬ë¡­ {crop_top}px â†’ resizedImage: {temp_width}x{work_height}")

                        resized_img = temp_img.crop((0, crop_top, temp_width, crop_bottom))

                        resized_width = temp_width
                        resized_height = work_height

                    else:
                        # ì„¸ë¡œí˜•: í­ 504px ê³ ì •
                        resized_width = work_width
                        resized_height = int(orig_height * resized_width / orig_width)

                        logger.info(f"ğŸ”³ ì„¸ë¡œí˜• ì´ë¯¸ì§€ (aspect < 0.540)")
                        logger.info(f"   ì›ë³¸: {orig_width}x{orig_height} â†’ resizedImage: {resized_width}x{resized_height}")

                        # PIL ë¦¬ì‚¬ì´ì¦ˆ
                        try:
                            resized_img = img.resize((resized_width, resized_height), Image.Resampling.LANCZOS)
                        except AttributeError:
                            resized_img = img.resize((resized_width, resized_height), Image.LANCZOS)
                else:
                    # íŒ¨ë‹ ë¹„í™œì„±í™”: ê°€ë¡œë¥¼ 504pxì— ë§ì¶¤ (ëª¨ë“  ì´ë¯¸ì§€ ë™ì¼ ì²˜ë¦¬)
                    resized_width = work_width  # 504px ê³ ì •
                    resized_height = int(orig_height * resized_width / orig_width)

                    logger.info(f"{'='*60}")
                    logger.info(f"ğŸ”„ [ì „ì²´í™”ë©´ - íŒ¨ë‹ OFF] ì´ë¯¸ì§€ ê°€ë¡œ ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ")
                    logger.info(f"   ì›ë³¸ ì´ë¯¸ì§€: {orig_width}x{orig_height}")
                    logger.info(f"   ìº”ë²„ìŠ¤ í­: {work_width}px (504px ê³ ì •)")
                    logger.info(f"   ë¦¬ì‚¬ì´ì¦ˆ ê²°ê³¼: {resized_width}x{resized_height}")
                    logger.info(f"   ì¢…íš¡ë¹„: {orig_width/orig_height:.3f} â†’ {resized_width/resized_height:.3f}")
                    logger.info(f"   ìœ„ì•„ë˜ ê²€ì€ íŒ¨ë”©: {max(0, work_height - resized_height)}px")
                    logger.info(f"{'='*60}")

                    # PIL ë¦¬ì‚¬ì´ì¦ˆ
                    try:
                        resized_img = img.resize((resized_width, resized_height), Image.Resampling.LANCZOS)
                    except AttributeError:
                        resized_img = img.resize((resized_width, resized_height), Image.LANCZOS)

                logger.info(f"âœ… 1ë‹¨ê³„ ë¦¬ì‚¬ì´ì§• ì™„ë£Œ: LANCZOS ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©")

                # RGBA â†’ RGB ë³€í™˜
                if resized_img.mode in ('RGBA', 'LA', 'P'):
                    background = Image.new('RGB', resized_img.size, (0, 0, 0))
                    if resized_img.mode == 'P':
                        resized_img = resized_img.convert('RGBA')
                    background.paste(resized_img, mask=resized_img.split()[-1] if resized_img.mode in ('RGBA', 'LA') else None)
                    resized_img = background
                    logger.info(f"ğŸ”³ RGBA â†’ RGB ë³€í™˜ ì™„ë£Œ")

                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥ (ê³ í’ˆì§ˆ)
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
                resized_img.save(temp_file.name, 'JPEG', quality=95)
                processed_image_path = temp_file.name
                logger.info(f"ğŸ’¾ resizedImage ì €ì¥ ì™„ë£Œ: {processed_image_path}")

            # MoviePy ì´ë¯¸ì§€ í´ë¦½ ìƒì„±
            clip = ImageClip(processed_image_path).set_duration(duration)

            # ============================================
            # 2ë‹¨ê³„: íŒ¨ë‹ (resizedImage í¬ê¸° ê¸°ì¤€) - ğŸ¨ íŒ¨ë‹ ì˜µì…˜ ì²´í¬
            # ============================================
            print(f"\n{'='*50}")
            logger.info(f"ğŸ¬ 2ë‹¨ê³„: íŒ¨ë‹ {'í™œì„±í™”' if enable_panning else 'ë¹„í™œì„±í™”'}")
            logger.info(f"{'='*50}")

            if enable_panning:
                # íŒ¨ë‹ í™œì„±í™”: resizedImage í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ íŒ¨ë‹ íƒ€ì… ë¨¼ì € ê²°ì •
                if resized_width > work_width:
                    # ê°€ë¡œ íŒ¨ë‹ í™•ì •
                    available_margin = (resized_width - work_width) // 2
                    safe_pan_range = min(60, available_margin)

                    # ê°€ë¡œ íŒ¨ë‹ ë°©í–¥ë§Œ ëœë¤ ì„ íƒ
                    pattern = random.choice([1, 2])

                    if pattern == 1:
                        # ì¢Œâ†’ìš° íŒ¨ë‹: ì´ë¯¸ì§€ë¥¼ ì™¼ìª½ìœ¼ë¡œ ì´ë™ (ì™¼ìª½ ë¶€ë¶„ â†’ ì˜¤ë¥¸ìª½ ë¶€ë¶„ ë³´ì—¬ì£¼ê¸°)
                        start_x = 0
                        end_x = -safe_pan_range
                        logger.info(f"ğŸ¬ ê°€ë¡œ íŒ¨ë‹ - íŒ¨í„´ {pattern}: ì¢Œâ†’ìš° ({start_x} â†’ {end_x})")
                    else:  # pattern == 2
                        # ìš°â†’ì¢Œ íŒ¨ë‹: ì´ë¯¸ì§€ë¥¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì´ë™ (ì˜¤ë¥¸ìª½ ë¶€ë¶„ â†’ ì™¼ìª½ ë¶€ë¶„ ë³´ì—¬ì£¼ê¸°)
                        start_x = -(resized_width - work_width)
                        end_x = start_x + safe_pan_range
                        logger.info(f"ğŸ¬ ê°€ë¡œ íŒ¨ë‹ - íŒ¨í„´ {pattern}: ìš°â†’ì¢Œ ({start_x} â†’ {end_x})")

                    start_y = (work_height - resized_height) // 2
                    end_y = start_y

                elif resized_height > work_height:
                    # ì„¸ë¡œ íŒ¨ë‹ í™•ì •
                    available_margin = (resized_height - work_height) // 2
                    safe_pan_range = min(60, available_margin)

                    # ì„¸ë¡œ íŒ¨ë‹ ë°©í–¥ë§Œ ëœë¤ ì„ íƒ
                    pattern = random.choice([1, 2])

                    if pattern == 1:
                        # ìƒâ†’í•˜ íŒ¨ë‹: ì´ë¯¸ì§€ë¥¼ ìœ„ìª½ìœ¼ë¡œ ì´ë™ (ìœ„ìª½ ë¶€ë¶„ â†’ ì•„ë˜ìª½ ë¶€ë¶„ ë³´ì—¬ì£¼ê¸°)
                        start_y = 0
                        end_y = -safe_pan_range
                        logger.info(f"ğŸ¬ ì„¸ë¡œ íŒ¨ë‹ - íŒ¨í„´ {pattern}: ìƒâ†’í•˜ ({start_y} â†’ {end_y})")
                    else:  # pattern == 2
                        # í•˜â†’ìƒ íŒ¨ë‹: ì´ë¯¸ì§€ë¥¼ ì•„ë˜ìª½ìœ¼ë¡œ ì´ë™ (ì•„ë˜ìª½ ë¶€ë¶„ â†’ ìœ„ìª½ ë¶€ë¶„ ë³´ì—¬ì£¼ê¸°)
                        start_y = -(resized_height - work_height)
                        end_y = start_y + safe_pan_range
                        logger.info(f"ğŸ¬ ì„¸ë¡œ íŒ¨ë‹ - íŒ¨í„´ {pattern}: í•˜â†’ìƒ ({start_y} â†’ {end_y})")

                    start_x = (work_width - resized_width) // 2
                    end_x = start_x

                else:
                    # ê³ ì •: ì¤‘ì•™ ë°°ì¹˜ (ì •ì‚¬ê°í˜• ë˜ëŠ” ìº”ë²„ìŠ¤ì™€ ë™ì¼)
                    start_x = (work_width - resized_width) // 2
                    start_y = (work_height - resized_height) // 2
                    end_x = start_x
                    end_y = start_y

                    logger.info(f"ğŸ“ ê³ ì • ëª¨ë“œ (resizedImageì™€ ìº”ë²„ìŠ¤ í¬ê¸° ë™ì¼)")
                    logger.info(f"   ì¤‘ì•™ ë°°ì¹˜: ({start_x}, {start_y})")

                # Linear ì´ì§•ìœ¼ë¡œ íŒ¨ë‹ ì ìš©
                def pos_func(t):
                    progress = t / duration if duration > 0 else 0
                    x = start_x + (end_x - start_x) * progress
                    y = start_y + (end_y - start_y) * progress
                    return (x, y)

                clip = clip.set_position(pos_func)

                logger.info(f"âœ… 2ë‹¨ê³„ íŒ¨ë‹ ì™„ë£Œ: Linear ì´ì§• ì ìš©")
                logger.info(f"   ì‹œì‘ ì¢Œí‘œ: ({start_x}, {start_y}) â†’ ì¢…ë£Œ ì¢Œí‘œ: ({end_x}, {end_y})")
            else:
                # íŒ¨ë‹ ë¹„í™œì„±í™”: ìœ„ë¡œ ë¶™ì´ê¸° (ì•„ë˜ ê²€ì€ íŒ¨ë”©)
                x_pos = 0  # ê°€ë¡œëŠ” ê½‰ ì±„ì›€ (width=504)
                y_pos = 0  # ìœ„ë¡œ ë¶™ì„
                clip = clip.set_position((x_pos, y_pos))
                logger.info(f"ğŸ¨ íŒ¨ë‹ ë¹„í™œì„±í™”: ìœ„ë¡œ ë¶™ì„ ({x_pos}, {y_pos})")
                logger.info(f"   ì´ë¯¸ì§€ í¬ê¸°: {resized_width}x{resized_height}")
                logger.info(f"   ì•„ë˜ ê²€ì€ íŒ¨ë”©: {max(0, work_height - resized_height)}px")

            logger.info(f"{'='*50}\n")
            logger.info(f"âœ… ì „ì²´ í™”ë©´ ì´ë¯¸ì§€ í´ë¦½ ìƒì„± ì™„ë£Œ!")

            return clip

        except Exception as e:
            logger.error(f"âŒ ì „ì²´ í™”ë©´ ì´ë¯¸ì§€ í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê²€ì€ ë°°ê²½
            return ColorClip(size=(self.video_width, self.video_height),
                           color=(0,0,0), duration=duration)

    def create_fullscreen_video_clip(self, video_path, duration, enable_panning=True):
        """ì „ì²´ í™”ë©´(504x890)ìš© ë¹„ë””ì˜¤ ë°°ê²½ í´ë¦½ ìƒì„±

        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            duration: í´ë¦½ ì§€ì† ì‹œê°„
            enable_panning: íŒ¨ë‹ í™œì„±í™” ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        """
        print(f"ğŸ¬ ì „ì²´ í™”ë©´ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„±: {os.path.basename(video_path)} (panning: {enable_panning})")

        try:
            # ë¹„ë””ì˜¤ í´ë¦½ ë¡œë“œ
            video_clip = VideoFileClip(video_path)
            orig_width, orig_height = video_clip.size
            print(f"ğŸ“ ì›ë³¸ ë¹„ë””ì˜¤: {orig_width}x{orig_height}")

            # ì „ì²´ í™”ë©´ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ (ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©´ì„œ í™”ë©´ ê½‰ ì±„ì›€)
            work_width = self.video_width
            work_height = self.video_height
            work_aspect_ratio = work_width / work_height
            video_aspect_ratio = orig_width / orig_height

            print(f"ğŸ¯ ëª©í‘œ: ì „ì²´ í™”ë©´ {work_width}x{work_height}")

            # í™”ë©´ë¹„ì— ë”°ë¥¸ í¬ë¡­ ë° ë¦¬ì‚¬ì´ì¦ˆ
            if video_aspect_ratio > work_aspect_ratio:
                # ê°€ë¡œí˜• ë¹„ë””ì˜¤: ë†’ì´ ë§ì¶¤ í›„ ì–‘ì˜† í¬ë¡­
                new_height = work_height
                new_width = int(orig_width * new_height / orig_height)
                print(f"ğŸ“ ê°€ë¡œí˜• ë¹„ë””ì˜¤: ë†’ì´ ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ {new_width}x{new_height}")

                try:
                    # MoviePy resize with newer API
                    from moviepy.video.fx.all import resize as fx_resize
                    video_clip = video_clip.fx(fx_resize, height=new_height)
                except:
                    # Fallback to direct resize
                    try:
                        video_clip = video_clip.resize(height=new_height)
                    except AttributeError as e:
                        # PIL ANTIALIAS ì´ìŠˆ - í”„ë ˆì„ ì¶”ì¶œ í›„ ìˆ˜ë™ ë¦¬ì‚¬ì´ì¦ˆ
                        print(f"âš ï¸ MoviePy resize ì‹¤íŒ¨ (PIL í˜¸í™˜ì„±): {e}")
                        print(f"ğŸ”„ í”„ë ˆì„ ì¶”ì¶œ ë°©ì‹ìœ¼ë¡œ ì „í™˜")

                        # í”„ë ˆì„ ì¶”ì¶œ (ì›ë³¸ ë¹„ë””ì˜¤ ê¸¸ì´ ì‚¬ìš©, íŒŒë¼ë¯¸í„° duration ë³´ì¡´)
                        fps = 30
                        video_duration = video_clip.duration  # ì§€ì—­ ë³€ìˆ˜ ì‚¬ìš©
                        frames = []

                        for t in [i/fps for i in range(int(video_duration * fps))]:
                            if t <= video_duration:
                                frame = video_clip.get_frame(t)
                                pil_frame = Image.fromarray(frame)

                                # PILë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                                try:
                                    resized_frame = pil_frame.resize((new_width, new_height), Image.Resampling.LANCZOS)
                                except AttributeError:
                                    resized_frame = pil_frame.resize((new_width, new_height), Image.LANCZOS)

                                frames.append(np.array(resized_frame))

                        # ìƒˆ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„±
                        from moviepy.editor import ImageSequenceClip
                        video_clip = ImageSequenceClip(frames, fps=fps)

                # ì¤‘ì•™ í¬ë¡­
                crop_x = (new_width - work_width) // 2
                video_clip = video_clip.crop(x1=crop_x, x2=crop_x + work_width)
            else:
                # ì„¸ë¡œí˜• ë¹„ë””ì˜¤: í­ ë§ì¶¤ í›„ ìƒí•˜ í¬ë¡­
                new_width = work_width
                new_height = int(orig_height * new_width / orig_width)
                print(f"ğŸ“ ì„¸ë¡œí˜• ë¹„ë””ì˜¤: í­ ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ {new_width}x{new_height}")

                try:
                    # MoviePy resize with newer API
                    from moviepy.video.fx.all import resize as fx_resize
                    video_clip = video_clip.fx(fx_resize, width=new_width)
                except:
                    # Fallback to direct resize
                    try:
                        video_clip = video_clip.resize(width=new_width)
                    except AttributeError as e:
                        # PIL ANTIALIAS ì´ìŠˆ - í”„ë ˆì„ ì¶”ì¶œ í›„ ìˆ˜ë™ ë¦¬ì‚¬ì´ì¦ˆ
                        print(f"âš ï¸ MoviePy resize ì‹¤íŒ¨ (PIL í˜¸í™˜ì„±): {e}")
                        print(f"ğŸ”„ í”„ë ˆì„ ì¶”ì¶œ ë°©ì‹ìœ¼ë¡œ ì „í™˜")

                        # í”„ë ˆì„ ì¶”ì¶œ (ì›ë³¸ ë¹„ë””ì˜¤ ê¸¸ì´ ì‚¬ìš©, íŒŒë¼ë¯¸í„° duration ë³´ì¡´)
                        fps = 30
                        video_duration = video_clip.duration  # ì§€ì—­ ë³€ìˆ˜ ì‚¬ìš©
                        frames = []

                        for t in [i/fps for i in range(int(video_duration * fps))]:
                            if t <= video_duration:
                                frame = video_clip.get_frame(t)
                                pil_frame = Image.fromarray(frame)

                                # PILë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                                try:
                                    resized_frame = pil_frame.resize((new_width, new_height), Image.Resampling.LANCZOS)
                                except AttributeError:
                                    resized_frame = pil_frame.resize((new_width, new_height), Image.LANCZOS)

                                frames.append(np.array(resized_frame))

                        # ìƒˆ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„±
                        from moviepy.editor import ImageSequenceClip
                        video_clip = ImageSequenceClip(frames, fps=fps)

                # ì¤‘ì•™ í¬ë¡­
                crop_y = (new_height - work_height) // 2
                video_clip = video_clip.crop(y1=crop_y, y2=crop_y + work_height)

            # ê¸¸ì´ ì¡°ì •
            original_duration = video_clip.duration
            print(f"ğŸ“ ë¹„ë””ì˜¤ ì›ë³¸ ê¸¸ì´: {original_duration:.2f}ì´ˆ, ëª©í‘œ ê¸¸ì´: {duration:.2f}ì´ˆ")

            if original_duration > duration:
                # ë¹„ë””ì˜¤ê°€ ê¸´ ê²½ìš°: ì•ˆì „í•˜ê²Œ ìë¥´ê¸°
                safe_duration = min(duration, original_duration - 0.2)
                video_clip = video_clip.subclip(0, safe_duration)
                print(f"â‚ ë¹„ë””ì˜¤ ê¸¸ì´ ì¡°ì •: {safe_duration:.2f}ì´ˆë¡œ ì˜ë¼ëƒ„")
            elif original_duration < duration:
                # ë¹„ë””ì˜¤ê°€ ì§§ì€ ê²½ìš°: ë°˜ë³µ ì¬ìƒìœ¼ë¡œ ê¸¸ì´ ë§ì¶¤
                try:
                    loop_count = int(duration // original_duration) + 1
                    print(f"ğŸ” ì „ì²´í™”ë©´ ë¹„ë””ì˜¤ ë°˜ë³µ ì²˜ë¦¬: {loop_count}íšŒ ë°˜ë³µí•˜ì—¬ {duration}ì´ˆ ë‹¬ì„±")

                    # ê°œë³„ í´ë¦½ë“¤ì„ ìƒì„±í•´ì„œ ì—°ê²°í•˜ëŠ” ë°©ì‹
                    clips = []
                    current_time = 0

                    while current_time < duration:
                        remaining_time = duration - current_time
                        if remaining_time >= original_duration:
                            # ì „ì²´ í´ë¦½ ì¶”ê°€
                            clips.append(video_clip)
                            current_time += original_duration
                        else:
                            # ë¶€ë¶„ í´ë¦½ ì¶”ê°€ (ì•ˆì „í•˜ê²Œ)
                            safe_remaining = min(remaining_time, original_duration - 0.2)
                            if safe_remaining > 0.2:  # ìµœì†Œ 0.2ì´ˆëŠ” ìˆì–´ì•¼ í•¨
                                print(f"ğŸ“ ë¶€ë¶„ í´ë¦½ ìƒì„±: 0ì´ˆ ~ {safe_remaining:.2f}ì´ˆ")
                                clips.append(video_clip.subclip(0, safe_remaining))
                            current_time = duration  # ë£¨í”„ ì¢…ë£Œ

                    if clips:
                        from moviepy.editor import concatenate_videoclips
                        video_clip = concatenate_videoclips(clips)
                        print(f"âœ… ì „ì²´í™”ë©´ ë¹„ë””ì˜¤ ë°˜ë³µ ì™„ì„±: ìµœì¢… ê¸¸ì´ {video_clip.duration:.2f}ì´ˆ")

                except Exception as e:
                    print(f"âš ï¸ ì „ì²´í™”ë©´ ë¹„ë””ì˜¤ ë°˜ë³µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì—°ì¥ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                    print("ğŸ“¸ ëŒ€ì•ˆ: ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì—°ì¥ ì²˜ë¦¬")
                    safe_frame_time = max(0, min(original_duration - 0.3, original_duration * 0.9))
                    last_frame = video_clip.to_ImageClip(t=safe_frame_time)
                    extension_duration = duration - original_duration
                    extension_clip = last_frame.set_duration(extension_duration)
                    from moviepy.editor import concatenate_videoclips
                    video_clip = concatenate_videoclips([video_clip, extension_clip])
                    print(f"ğŸ–¼ï¸ ë§ˆì§€ë§‰ í”„ë ˆì„ ì—°ì¥: {extension_duration:.2f}ì´ˆ ì¶”ê°€")

            # ìœ„ì¹˜ ì„¤ì • (í™”ë©´ ê°€ë“)
            video_clip = video_clip.set_position((0, 0))

            print(f"âœ… ì „ì²´ í™”ë©´ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± ì™„ë£Œ!")

            return video_clip

        except Exception as e:
            print(f"âŒ ì „ì²´ í™”ë©´ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê²€ì€ ë°°ê²½
            return ColorClip(size=(self.video_width, self.video_height),
                           color=(0,0,0), duration=duration)

    # ==================== ì „í™˜ íš¨ê³¼ ë©”ì†Œë“œë“¤ ====================


    def apply_random_transitions(self, clips, transition_duration=0.4):
        """í´ë¦½ë“¤ ì‚¬ì´ì— ëœë¤ ì „í™˜ íš¨ê³¼ ì ìš©"""
        if len(clips) <= 1:
            return concatenate_videoclips(clips, method="compose") if clips else None

        # ì›ë˜ ì´ ê¸¸ì´ ê³„ì‚° (TTSì™€ ë§ì¶°ì•¼ í•  ê¸°ì¤€)
        original_total_duration = sum(clip.duration for clip in clips)
        print(f"ğŸ¬ ëœë¤ ì „í™˜ íš¨ê³¼ ì ìš©: {len(clips)}ê°œ í´ë¦½, ì›ë³¸ ì´ ê¸¸ì´ {original_total_duration:.2f}ì´ˆ")

        # ë””ì¡¸ë¸Œ ì „í™˜ íš¨ê³¼ë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)
        print("ğŸ¬ ë””ì¡¸ë¸Œ ì „í™˜ íš¨ê³¼ í…ŒìŠ¤íŠ¸: ëª¨ë“  ì „í™˜ì„ ë””ì¡¸ë¸Œë¡œ ê³ ì •")

        # ëª¨ë“  í´ë¦½ë“¤ì„ ì²˜ë¦¬í•  ë¦¬ìŠ¤íŠ¸
        processed_clips = []

        for i in range(len(clips)):
            if i == 0:
                # ì²« ë²ˆì§¸ í´ë¦½ì€ ê·¸ëŒ€ë¡œ ì¶”ê°€
                processed_clips.append(clips[i])
                print(f"  ğŸ“¹ í´ë¦½ {i+1}: ì²« ë²ˆì§¸ í´ë¦½ (ì „í™˜ ì—†ìŒ)")
            else:
                # ë””ì¡¸ë¸Œ ì „í™˜ ì ìš©
                print(f"  ğŸ”„ í´ë¦½ {i+1}: ë””ì¡¸ë¸Œ ì „í™˜ ì ìš©")

                try:
                    # ì´ì „ í´ë¦½ê³¼ í˜„ì¬ í´ë¦½ ì‚¬ì´ì— ë””ì¡¸ë¸Œ ì ìš©
                    prev_clip = processed_clips[-1]
                    curr_clip = clips[i]

                    # ì•ˆì „í•œ ì „í™˜ ì‹œê°„ ê³„ì‚° (0.5ì´ˆ)
                    transition_duration = 0.5
                    safe_duration = min(transition_duration, prev_clip.duration * 0.3, curr_clip.duration * 0.3)
                    safe_duration = max(0.2, safe_duration)  # ìµœì†Œ 0.2ì´ˆ

                    # í˜„ì¬ í´ë¦½ì„ ì´ì „ í´ë¦½ ëì—ì„œ ê²¹ì¹˜ë„ë¡ ì‹œì‘ ì‹œê°„ ì„¤ì •
                    curr_clip_overlapped = curr_clip.set_start(prev_clip.duration - safe_duration)

                    # fadein íš¨ê³¼ ì ìš© (ë””ì¡¸ë¸Œ)
                    from moviepy.video.fx.fadein import fadein
                    curr_clip_faded = curr_clip_overlapped.fx(fadein, safe_duration)
                    processed_clips.append(curr_clip_faded)

                    print(f"    âœ¨ ë””ì¡¸ë¸Œ ì ìš©: {safe_duration:.2f}ì´ˆ ë¸”ë Œë”©")

                except Exception as e:
                    print(f"    âš ï¸ ë””ì¡¸ë¸Œ ì‹¤íŒ¨, cutìœ¼ë¡œ ëŒ€ì²´: {e}")
                    processed_clips.append(clips[i])

        # CompositeVideoClipìœ¼ë¡œ ì²˜ë¦¬ (ê²¹ì¹˜ëŠ” í´ë¦½ë“¤ ë•Œë¬¸ì—)
        try:
            final_video = CompositeVideoClip(processed_clips)
            print(f"âœ… ë””ì¡¸ë¸Œ ì „í™˜ ì ìš© ì™„ë£Œ: ìµœì¢… ê¸¸ì´ {final_video.duration:.2f}ì´ˆ")
        except Exception as e:
            print(f"âš ï¸ Composite ì‹¤íŒ¨, concatenateë¡œ ëŒ€ì²´: {e}")
            final_video = concatenate_videoclips([clip for clip in processed_clips if hasattr(clip, 'duration')], method="compose")
            print(f"âœ… ë””ì¡¸ë¸Œ ì „í™˜ ì ìš© ì™„ë£Œ (Fallback): ìµœì¢… ê¸¸ì´ {final_video.duration:.2f}ì´ˆ")

        return final_video

        # ê¸°ì¡´ ì „í™˜ íš¨ê³¼ ì½”ë“œ (ì¼ì‹œì ìœ¼ë¡œ ë¹„í™œì„±í™”)
        """
        transitions = ['cut', 'dissolve', 'wipe']

        # ëª¨ë“  í´ë¦½ë“¤ì„ ì²˜ë¦¬í•  ë¦¬ìŠ¤íŠ¸
        processed_clips = []

        for i in range(len(clips)):
            if i == 0:
                # ì²« ë²ˆì§¸ í´ë¦½ì€ ê·¸ëŒ€ë¡œ ì¶”ê°€
                processed_clips.append(clips[i])
            else:
                # ì´ì „ í´ë¦½ê³¼ í˜„ì¬ í´ë¦½ ì‚¬ì´ì— ì „í™˜ íš¨ê³¼ ì ìš©
                transition_type = random.choice(transitions)
                print(f"  ğŸ”„ í´ë¦½ {i}: {transition_type} ì „í™˜")

                if transition_type == 'cut':
                    # ë‹¨ìˆœ ì—°ê²° (ê¸°ì¡´ ë°©ì‹)
                    processed_clips.append(clips[i])

                elif transition_type == 'dissolve':
                    # í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ - ë” ê°„ë‹¨í•œ ë°©ì‹
                    try:
                        # ì´ì „ í´ë¦½ì˜ ë ë¶€ë¶„ê³¼ í˜„ì¬ í´ë¦½ì˜ ì‹œì‘ ë¶€ë¶„ì„ ì˜¤ë²„ë©
                        prev_clip = processed_clips[-1]
                        curr_clip = clips[i]

                        # ì•ˆì „í•œ ì „í™˜ ì‹œê°„ ê³„ì‚°
                        safe_duration = min(transition_duration, prev_clip.duration * 0.2, curr_clip.duration * 0.2)
                        safe_duration = max(0.1, safe_duration)

                        # í˜„ì¬ í´ë¦½ì„ ì´ì „ í´ë¦½ ëì—ì„œ ê²¹ì¹˜ë„ë¡ ì‹œì‘ ì‹œê°„ ì„¤ì •
                        curr_clip_overlapped = curr_clip.set_start(prev_clip.duration - safe_duration)

                        # fadein íš¨ê³¼ ì ìš©
                        curr_clip_faded = curr_clip_overlapped.fx(fadein, safe_duration)
                        processed_clips.append(curr_clip_faded)

                        print(f"    âœ¨ Cross dissolve: {safe_duration:.2f}ì´ˆ ë¸”ë Œë”©")

                    except Exception as e:
                        print(f"    âš ï¸ Dissolve ì‹¤íŒ¨, cutìœ¼ë¡œ ëŒ€ì²´: {e}")
                        processed_clips.append(clips[i])

                elif transition_type == 'wipe':
                    # ì™€ì´í”„ ì „í™˜
                    try:
                        processed_clip = self._apply_wipe_transition(
                            processed_clips[-1], clips[i], transition_duration * 0.7
                        )
                        # ì „ì²´ compositeë¥¼ ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ìš”ì†Œë¡œ êµì²´
                        processed_clips[-1] = processed_clip
                    except Exception as e:
                        print(f"    âš ï¸ Wipe ì‹¤íŒ¨, cutìœ¼ë¡œ ëŒ€ì²´: {e}")
                        processed_clips.append(clips[i])

        # dissolveë‚˜ wipeì— ì˜í•´ ê²¹ì¹œ í´ë¦½ë“¤ì€ CompositeVideoClipìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ 
        # ë‚˜ë¨¸ì§€ëŠ” concatenateë¡œ ì²˜ë¦¬
        try:
            final_video = CompositeVideoClip(processed_clips)
            print(f"âœ… ëœë¤ ì „í™˜ ì ìš© ì™„ë£Œ (Composite): ìµœì¢… ê¸¸ì´ {final_video.duration:.2f}ì´ˆ")
        except:
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ concatenate ì‚¬ìš©
            final_video = concatenate_videoclips([clip for clip in processed_clips if hasattr(clip, 'duration')], method="compose")
            print(f"âœ… ëœë¤ ì „í™˜ ì ìš© ì™„ë£Œ (Fallback): ìµœì¢… ê¸¸ì´ {final_video.duration:.2f}ì´ˆ")

        return final_video
        """

    def _apply_cross_dissolve(self, clip1, clip2, duration=0.4):
        """í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ íš¨ê³¼ ì ìš© (ì§„ì§œ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ - ê²€ì€ í™”ë©´ ì—†ìŒ)"""
        try:
            # ì•ˆì „í•œ duration ê³„ì‚°
            safe_duration = min(duration, clip1.duration * 0.3, clip2.duration * 0.3)
            safe_duration = max(0.1, safe_duration)  # ìµœì†Œ 0.1ì´ˆ

            # clip1ì„ ê·¸ëŒ€ë¡œ ìœ ì§€
            clip1_part = clip1

            # clip2ë¥¼ clip1 ëì—ì„œ safe_durationë§Œí¼ ì•ë‹¹ê²¨ ì‹œì‘
            # clip2ì˜ ì‹œì‘ ë¶€ë¶„ì— transparency ì• ë‹ˆë©”ì´ì…˜ ì ìš©
            def make_mask(t):
                # 0ì´ˆì—ì„œ safe_durationê¹Œì§€ opacityê°€ 0ì—ì„œ 1ë¡œ ë³€í™”
                if t < safe_duration:
                    opacity = t / safe_duration  # 0 â†’ 1
                    return opacity
                else:
                    return 1.0

            # clip2ë¥¼ íˆ¬ëª…ë„ ì• ë‹ˆë©”ì´ì…˜ê³¼ í•¨ê»˜ ì˜¤ë²„ë©
            clip2_with_alpha = clip2.set_start(clip1.duration - safe_duration)

            # ê°„ë‹¨í•œ linear fade-in ì ìš© (ê²€ì€ìƒ‰ í˜ì´ë“œê°€ ì•„ë‹Œ íˆ¬ëª…ë„ ë³€í™”)
            try:
                # MoviePyì˜ crossfadein ì‚¬ìš© ì‹œë„
                clip2_crossfade = clip2_with_alpha.fx(fadein, safe_duration)
                print(f"    âœ¨ Cross dissolve: {safe_duration:.2f}ì´ˆ ë¸”ë Œë”©")
                return clip1_part, clip2_crossfade
            except:
                # ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ composite ì ìš©
                print(f"    âœ¨ Cross dissolve (simple): {safe_duration:.2f}ì´ˆ ë¸”ë Œë”©")
                return clip1_part, clip2_with_alpha

        except Exception as e:
            print(f"    âš ï¸ Cross dissolve ì‹¤íŒ¨, cutìœ¼ë¡œ ëŒ€ì²´: {e}")
            return clip1, clip2

    def _apply_wipe_transition(self, clip1, clip2, duration=0.3):
        """ì™€ì´í”„ ì „í™˜ íš¨ê³¼ ì ìš© (4ë°©í–¥ ëœë¤)"""
        try:
            wipe_directions = ['left_to_right', 'right_to_left', 'top_to_bottom', 'bottom_to_top']
            direction = random.choice(wipe_directions)

            # ì•ˆì „í•œ duration ê³„ì‚°
            safe_duration = min(duration, clip1.duration * 0.2)
            safe_duration = max(0.1, safe_duration)

            print(f"    ğŸŒŠ Wipe {direction}: {safe_duration:.2f}ì´ˆ")

            # ì™€ì´í”„ ë§ˆìŠ¤í¬ ìƒì„±
            mask_clip = self._create_wipe_mask(direction, safe_duration)

            # clip1ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ê³¼ clip2ì˜ ì‹œì‘ ë¶€ë¶„ì„ ì˜¤ë²„ë©
            clip1_end = clip1.duration

            # clip2ë¥¼ clip1 ëì—ì„œ ì‹œì‘í•˜ë˜, ì™€ì´í”„ durationë§Œí¼ ì•ë‹¹ê¹€
            clip2_with_wipe = clip2.set_start(clip1_end - safe_duration)
            clip2_with_mask = clip2_with_wipe.set_mask(mask_clip.set_start(clip1_end - safe_duration))

            # ë‘ í´ë¦½ì„ í•©ì„±
            composite = CompositeVideoClip([clip1, clip2_with_mask])

            return composite

        except Exception as e:
            print(f"    âš ï¸ Wipe ì „í™˜ ì‹¤íŒ¨, cutìœ¼ë¡œ ëŒ€ì²´: {e}")
            # ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ì—°ê²°
            return concatenate_videoclips([clip1, clip2], method="compose")

    def _create_wipe_mask(self, direction, duration):
        """ì™€ì´í”„ ì „í™˜ìš© ë§ˆìŠ¤í¬ í´ë¦½ ìƒì„±"""
        def make_frame(t):
            # ì§„í–‰ ë¹„ìœ¨ (0 â†’ 1)
            progress = t / duration

            # ë§ˆìŠ¤í¬ ë°°ì—´ ìƒì„± (0=íˆ¬ëª…, 255=ë¶ˆíˆ¬ëª…)
            mask = np.zeros((self.video_height, self.video_width))

            if direction == 'left_to_right':
                # ì¢Œì—ì„œ ìš°ë¡œ
                cutoff = int(self.video_width * progress)
                mask[:, :cutoff] = 255

            elif direction == 'right_to_left':
                # ìš°ì—ì„œ ì¢Œë¡œ
                cutoff = int(self.video_width * (1 - progress))
                mask[:, cutoff:] = 255

            elif direction == 'top_to_bottom':
                # ìƒì—ì„œ í•˜ë¡œ
                cutoff = int(self.video_height * progress)
                mask[:cutoff, :] = 255

            elif direction == 'bottom_to_top':
                # í•˜ì—ì„œ ìƒìœ¼ë¡œ
                cutoff = int(self.video_height * (1 - progress))
                mask[cutoff:, :] = 255

            return mask

        # numpy importê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ
        try:
            import numpy as np
        except ImportError:
            print("    âš ï¸ numpy ì—†ìŒ, ê°„ë‹¨í•œ ë§ˆìŠ¤í¬ ì‚¬ìš©")
            # numpy ì—†ì„ ê²½ìš° ê°„ë‹¨í•œ í˜ì´ë“œ ë§ˆìŠ¤í¬
            return ColorClip(size=(self.video_width, self.video_height),
                           color=(255, 255, 255)).set_duration(duration).fx(fadein, duration)

        mask_clip = VideoClip(make_frame, duration=duration)
        return mask_clip

    def detect_image_transitions(self, clips, media_files, image_allocation_mode):
        """í´ë¦½ê³¼ ë¯¸ë””ì–´ íŒŒì¼ì„ ë§¤í•‘í•˜ì—¬ ëª¨ë“  ì „í™˜ êµ¬ê°„ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜ (ì˜ìƒ-ì˜ìƒ, ì´ë¯¸ì§€-ì´ë¯¸ì§€, ì˜ìƒ-ì´ë¯¸ì§€, ì´ë¯¸ì§€-ì˜ìƒ)"""
        msg = f"ğŸ” ë¯¸ë””ì–´ ì „í™˜ êµ¬ê°„ ê°ì§€ ì‹œì‘..."
        print(msg)
        logging.info(msg)

        msg = f"   clips ê°œìˆ˜: {len(clips) if clips else 0}"
        print(msg)
        logging.info(msg)

        msg = f"   media_files ê°œìˆ˜: {len(media_files) if media_files else 0}"
        print(msg)
        logging.info(msg)

        msg = f"   image_allocation_mode: {image_allocation_mode}"
        print(msg)
        logging.info(msg)

        if not media_files or not clips:
            msg = "   âš ï¸ media_files ë˜ëŠ” clipsê°€ ì—†ìŠµë‹ˆë‹¤"
            print(msg)
            logging.warning(msg)
            return []

        # í´ë¦½ê³¼ ë¯¸ë””ì–´ íŒŒì¼ ë§¤í•‘ ìƒì„±
        clip_to_media_mapping = self._create_clip_media_mapping(clips, media_files, image_allocation_mode)

        msg = f"   í´ë¦½-ë¯¸ë””ì–´ ë§¤í•‘: {clip_to_media_mapping}"
        print(msg)
        logging.info(msg)

        transition_indices = []
        for i in range(len(clips) - 1):
            try:
                curr_media_idx = clip_to_media_mapping.get(i)
                next_media_idx = clip_to_media_mapping.get(i+1)

                if curr_media_idx is None or next_media_idx is None:
                    msg = f"   [{i}] ë§¤í•‘ ì—†ìŒ: {curr_media_idx} â†’ {next_media_idx}"
                    print(msg)
                    logging.info(msg)
                    continue

                curr_media = media_files[curr_media_idx]
                next_media = media_files[next_media_idx]

                curr_type = curr_media[1] if len(curr_media) > 1 else "unknown"
                next_type = next_media[1] if len(next_media) > 1 else "unknown"

                msg = f"   í´ë¦½ [{i}] â†’ [{i+1}]: ë¯¸ë””ì–´ [{curr_media_idx}] ({curr_type}) â†’ [{next_media_idx}] ({next_type})"
                print(msg)
                logging.info(msg)

                # ëª¨ë“  íƒ€ì…ì˜ ì „í™˜ì— dissolve ì ìš© (ì˜ìƒ-ì˜ìƒ, ì´ë¯¸ì§€-ì´ë¯¸ì§€, ì˜ìƒ-ì´ë¯¸ì§€, ì´ë¯¸ì§€-ì˜ìƒ)
                transition_indices.append(i)
                msg = f"  âœ… ì „í™˜ êµ¬ê°„ ë°œê²¬: í´ë¦½ {i} â†’ {i+1} ({curr_type}â†’{next_type})"
                print(msg)
                logging.info(msg)

            except Exception as e:
                msg = f"   âš ï¸ í´ë¦½ [{i}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"
                print(msg)
                logging.error(msg)
                continue

        msg = f"ğŸ­ ì´ {len(transition_indices)}ê°œ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ êµ¬ê°„ ê°ì§€ (ëª¨ë“  ë¯¸ë””ì–´ ì „í™˜): {transition_indices}"
        print(msg)
        logging.info(msg)
        return transition_indices

    def _create_clip_media_mapping(self, clips, media_files, image_allocation_mode):
        """í´ë¦½ê³¼ ë¯¸ë””ì–´ íŒŒì¼ ê°„ì˜ ë§¤í•‘ ìƒì„±"""
        mapping = {}

        if image_allocation_mode == "1_per_image":
            # ê° í´ë¦½ë§ˆë‹¤ ë¯¸ë””ì–´ 1ê°œ
            for i, clip in enumerate(clips):
                media_idx = i % len(media_files)  # ë¯¸ë””ì–´ íŒŒì¼ ìˆœí™˜ ì‚¬ìš©
                mapping[i] = media_idx
        elif image_allocation_mode == "2_per_image":
            # í´ë¦½ 2ê°œë‹¹ ë¯¸ë””ì–´ 1ê°œ
            for i, clip in enumerate(clips):
                media_idx = (i // 2) % len(media_files)  # 2ê°œì”© ë¬¶ì–´ì„œ ë¯¸ë””ì–´ ì‚¬ìš©
                mapping[i] = media_idx
        else:
            # ê¸°ë³¸: 1:1 ë§¤í•‘
            for i, clip in enumerate(clips):
                if i < len(media_files):
                    mapping[i] = i

        return mapping


    def apply_crossfade_to_clips(self, clips, transition_indices, fade_duration=0.4):
        """ì§€ì •ëœ ì „í™˜ êµ¬ê°„ì˜ í´ë¦½ë“¤ì— fade íš¨ê³¼ ì ìš©"""
        msg = "ğŸ¨ apply_crossfade_to_clips í˜¸ì¶œë¨!"
        print(msg)
        logging.info(msg)

        msg = f"   ì „í™˜ êµ¬ê°„: {transition_indices}"
        print(msg)
        logging.info(msg)

        msg = f"   í˜ì´ë“œ ì‹œê°„: {fade_duration}ì´ˆ"
        print(msg)
        logging.info(msg)

        try:
            # MoviePy fade ëª¨ë“ˆ import ì‹œë„ (ìµœì‹  ë²„ì „ í˜¸í™˜)
            from moviepy.video.fx.fadein import fadein
            from moviepy.video.fx.fadeout import fadeout
            msg = "âœ… MoviePy fade ëª¨ë“ˆ import ì„±ê³µ"
            print(msg)
            logging.info(msg)
        except ImportError as e:
            msg = f"âŒ MoviePy fade ëª¨ë“ˆ import ì‹¤íŒ¨: {e}"
            print(msg)
            logging.error(msg)
            return clips

        processed_clips = []

        for i, clip in enumerate(clips):
            try:
                clip_copy = clip.copy()

                # í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ë¡œì§:
                # transition_indicesì— ìˆëŠ” ì¸ë±ìŠ¤ëŠ” "ì „í™˜ì´ ì‹œì‘ë˜ëŠ” í´ë¦½"ì„ ì˜ë¯¸
                # ì¦‰, í´ë¦½ iì—ì„œ í´ë¦½ i+1ë¡œ ì „í™˜

                # í˜„ì¬ í´ë¦½ì—ì„œ ë‹¤ìŒ í´ë¦½ìœ¼ë¡œì˜ ì „í™˜ (fadeout)
                if i in transition_indices:
                    if clip_copy.duration >= fade_duration:
                        clip_copy = clip_copy.fx(fadeout, fade_duration)
                        msg = f"âœ¨ í´ë¦½ {i}â†’{i+1}: 2ì´ˆ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì ìš© ì™„ë£Œ (fadeout)"
                        print(msg)
                        logging.info(msg)
                    else:
                        msg = f"âš ï¸ í´ë¦½ {i}: ê¸¸ì´({clip_copy.duration:.1f}ì´ˆ)ê°€ í˜ì´ë“œ ì‹œê°„ë³´ë‹¤ ì§§ì•„ fadeout ìƒëµ"
                        print(msg)
                        logging.warning(msg)

                # ì´ì „ í´ë¦½ì—ì„œ í˜„ì¬ í´ë¦½ìœ¼ë¡œì˜ ì „í™˜ (fadein)
                # i-1ì´ transition_indicesì— ìˆìœ¼ë©´ í˜„ì¬ í´ë¦½ì— fadein ì ìš©
                if i > 0 and (i-1) in transition_indices:
                    clip_copy = clip_copy.fx(fadein, fade_duration)
                    msg = f"âœ¨ í´ë¦½ {i-1}â†’{i}: 2ì´ˆ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì ìš© ì™„ë£Œ (fadein)"
                    print(msg)
                    logging.info(msg)

                processed_clips.append(clip_copy)
                msg = f"âœ… í´ë¦½ {i} ì²˜ë¦¬ ì™„ë£Œ"
                print(msg)
                logging.info(msg)

            except Exception as e:
                msg = f"âš ï¸ í´ë¦½ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
                print(msg)
                logging.error(msg)
                # ì‹¤íŒ¨ ì‹œ ì›ë³¸ í´ë¦½ ì‚¬ìš©
                processed_clips.append(clip)

        msg = f"ğŸ¨ í¬ë¡œìŠ¤í˜ì´ë“œ íš¨ê³¼ ì ìš© ì™„ë£Œ: {len(processed_clips)}ê°œ í´ë¦½"
        print(msg)
        logging.info(msg)

        return processed_clips

    def apply_smart_crossfade_transitions(self, clips, media_files=None, image_allocation_mode="1_per_image", fade_duration=0.4):
        """ê¸°ì¡´ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ìŠ¤ë§ˆíŠ¸ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì ìš©"""
        msg = f"ğŸ¬ apply_smart_crossfade_transitions í˜¸ì¶œë¨!"
        print(msg)
        logging.info(msg)

        msg = f"   clips ê°œìˆ˜: {len(clips) if clips else 0}"
        print(msg)
        logging.info(msg)

        msg = f"   media_files íƒ€ì…: {type(media_files)}"
        print(msg)
        logging.info(msg)

        msg = f"   media_files ê°œìˆ˜: {len(media_files) if media_files else 0}"
        print(msg)
        logging.info(msg)

        msg = f"   image_allocation_mode: {image_allocation_mode}"
        print(msg)
        logging.info(msg)

        msg = f"   fade_duration: {fade_duration}"
        print(msg)
        logging.info(msg)

        if not clips or len(clips) <= 1:
            msg = "   âš ï¸ í´ë¦½ì´ ì—†ê±°ë‚˜ 1ê°œ ì´í•˜ì…ë‹ˆë‹¤. ê¸°ë³¸ ì—°ê²° ì‚¬ìš©"
            print(msg)
            logging.warning(msg)
            return concatenate_videoclips(clips, method="compose") if clips else None

        msg = f"ğŸ¬ ìŠ¤ë§ˆíŠ¸ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì „í™˜ ì‹œì‘: {len(clips)}ê°œ í´ë¦½ (ê°•í™”ëœ 2ì´ˆ íš¨ê³¼)"
        print(msg)
        logging.info(msg)

        # ëª¨ë“  ë¯¸ë””ì–´ ì „í™˜ êµ¬ê°„ ê°ì§€ (ì˜ìƒ-ì˜ìƒ, ì´ë¯¸ì§€-ì´ë¯¸ì§€, ì˜ìƒ-ì´ë¯¸ì§€, ì´ë¯¸ì§€-ì˜ìƒ)
        msg = "ğŸ” ë¯¸ë””ì–´ ì „í™˜ êµ¬ê°„ ê°ì§€ í˜¸ì¶œ..."
        print(msg)
        logging.info(msg)

        transition_indices = self.detect_image_transitions(clips, media_files, image_allocation_mode)

        msg = f"ğŸ” ê°ì§€ ê²°ê³¼: {transition_indices}"
        print(msg)
        logging.info(msg)

        if not transition_indices:
            msg = "â„¹ï¸ ì „í™˜ êµ¬ê°„ì´ ì—†ì–´ ì¼ë°˜ ì—°ê²° ì‚¬ìš©"
            print(msg)
            logging.info(msg)

            msg = "   -> concatenate_videoclipsë¡œ ê¸°ë³¸ ì—°ê²°í•©ë‹ˆë‹¤"
            print(msg)
            logging.info(msg)
            return concatenate_videoclips(clips, method="compose")

        # ê°œë³„ í´ë¦½ì— fade íš¨ê³¼ ì ìš©
        print("ğŸ”„ ê°œë³„ í´ë¦½ì— fade íš¨ê³¼ ì ìš© í˜¸ì¶œ...")
        processed_clips = self.apply_crossfade_to_clips(clips, transition_indices, fade_duration)
        print(f"ğŸ”„ fade íš¨ê³¼ ì ìš© ì™„ë£Œ. ì²˜ë¦¬ëœ í´ë¦½ ê°œìˆ˜: {len(processed_clips)}")

        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ìˆœì°¨ ì—°ê²° (CompositeVideoClip ì‚¬ìš© ì•ˆí•¨)
        try:
            print("ğŸ”— ìµœì¢… ì˜ìƒ ì—°ê²° ì‹œì‘...")
            print(f"   ì—°ê²°í•  í´ë¦½ ê°œìˆ˜: {len(processed_clips)}")

            # ê° í´ë¦½ì˜ ìƒíƒœ í™•ì¸
            for i, clip in enumerate(processed_clips):
                try:
                    print(f"   í´ë¦½ [{i}]: ê¸¸ì´ {clip.duration:.2f}ì´ˆ, í¬ê¸° {clip.size}")
                except Exception as e:
                    print(f"   í´ë¦½ [{i}]: ì •ë³´ í™•ì¸ ì‹¤íŒ¨ - {e}")

            final_video = concatenate_videoclips(processed_clips, method="compose")
            print(f"âœ… í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì „í™˜ ì™„ë£Œ: ìµœì¢… ê¸¸ì´ {final_video.duration:.2f}ì´ˆ")
            return final_video
        except Exception as e:
            print(f"âš ï¸ ì „í™˜ íš¨ê³¼ ì ìš© ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            print("   -> ì›ë³¸ í´ë¦½ë“¤ë¡œ ê¸°ë³¸ ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ í´ë¦½ë“¤ë¡œ ê¸°ë³¸ ì—°ê²°
            try:
                fallback_video = concatenate_videoclips(clips, method="compose")
                print(f"âœ… ê¸°ë³¸ ì—°ê²° ì„±ê³µ: ê¸¸ì´ {fallback_video.duration:.2f}ì´ˆ")
                return fallback_video
            except Exception as e2:
                print(f"âš ï¸ ê¸°ë³¸ ì—°ê²°ë„ ì‹¤íŒ¨: {e2}")
                return None


