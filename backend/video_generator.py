import os
import requests
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import *
import uuid
import tempfile
from gtts import gTTS
import re
import base64
import json
import random
import math

class VideoGenerator:
    def __init__(self):
        self.video_width = 414
        self.video_height = 896  # ìŠ¤ë§ˆíŠ¸í° í•´ìƒë„ (414x896)
        self.fps = 30
        self.font_path = os.path.join(os.path.dirname(__file__), "font", "BMYEONSUNG_otf.otf")
        
        # Naver Clova Voice ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        self.naver_client_id = os.getenv('NAVER_CLIENT_ID')
        self.naver_client_secret = os.getenv('NAVER_CLIENT_SECRET')
        
        # Microsoft Azure Speech ì„¤ì •
        self.azure_speech_key = os.getenv('AZURE_SPEECH_KEY')
        self.azure_speech_region = os.getenv('AZURE_SPEECH_REGION', 'koreacentral')
        
    def get_emoji_font(self):
        """ì´ëª¨ì§€ ì§€ì› í°íŠ¸ ê²½ë¡œ ë°˜í™˜"""
        emoji_fonts = [
            "/usr/share/fonts/truetype/noto/NotoColorEmoji.ttf",
            "/System/Library/Fonts/Apple Color Emoji.ttc",
            "/Windows/Fonts/seguiemj.ttf",
            "/usr/share/fonts/truetype/noto/NotoEmoji-Regular.ttf"
        ]
        
        for font_path in emoji_fonts:
            if os.path.exists(font_path):
                return font_path
        return None
    
    def has_emoji(self, text):
        """í…ìŠ¤íŠ¸ì— ì´ëª¨ì§€ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        emoji_pattern = re.compile(
            "[\U0001F600-\U0001F64F"  # ê°ì • í‘œí˜„
            "\U0001F300-\U0001F5FF"  # ê¸°í˜¸ ë° ê·¸ë¦¼ë¬¸ì
            "\U0001F680-\U0001F6FF"  # êµí†µ ë° ì§€ë„ ê¸°í˜¸
            "\U0001F1E0-\U0001F1FF"  # êµ­ê¸°
            "\U00002600-\U000026FF"  # ê¸°íƒ€ ê¸°í˜¸
            "\U00002700-\U000027BF"  # ì¥ì‹ ê¸°í˜¸
            "\U0001F900-\U0001F9FF"  # ì¶”ê°€ ê·¸ë¦¼ë¬¸ì
            "\U0001FA70-\U0001FAFF"  # í™•ì¥ëœ ê·¸ë¦¼ë¬¸ì-A
            "]+", re.UNICODE)
        return emoji_pattern.search(text) is not None
    
    def split_text_and_emoji(self, text):
        """í…ìŠ¤íŠ¸ì™€ ì´ëª¨ì§€ë¥¼ ë¶„ë¦¬"""
        emoji_pattern = re.compile(
            "[\U0001F600-\U0001F64F"
            "\U0001F300-\U0001F5FF"
            "\U0001F680-\U0001F6FF"
            "\U0001F1E0-\U0001F1FF"
            "\U00002600-\U000026FF"
            "\U00002700-\U000027BF"
            "\U0001F900-\U0001F9FF"
            "\U0001FA70-\U0001FAFF"
            "]", re.UNICODE)
        
        parts = []
        last_end = 0
        
        for match in emoji_pattern.finditer(text):
            if match.start() > last_end:
                parts.append(('text', text[last_end:match.start()]))
            parts.append(('emoji', match.group()))
            last_end = match.end()
        
        if last_end < len(text):
            parts.append(('text', text[last_end:]))
        
        return parts
    
    def draw_text_with_emoji(self, draw, text, x, y, text_font, emoji_font, color):
        """í…ìŠ¤íŠ¸ì™€ ì´ëª¨ì§€ë¥¼ í•¨ê»˜ ë Œë”ë§"""
        parts = self.split_text_and_emoji(text)
        current_x = x
        
        for part_type, content in parts:
            if part_type == 'text' and content.strip():
                draw.text((current_x, y), content, font=text_font, fill=color)
                bbox = draw.textbbox((0, 0), content, font=text_font)
                current_x += bbox[2] - bbox[0]
            elif part_type == 'emoji':
                # ì´ëª¨ì§€ í°íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ë¡œ ì‹œë„
                if emoji_font:
                    try:
                        draw.text((current_x, y + 2), content, font=emoji_font, fill=color)
                        bbox = draw.textbbox((0, 0), content, font=emoji_font)
                    except:
                        # ì´ëª¨ì§€ í°íŠ¸ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ í°íŠ¸ë¡œ ì‹œë„
                        draw.text((current_x, y), content, font=text_font, fill=color)
                        bbox = draw.textbbox((0, 0), content, font=text_font)
                else:
                    # ì´ëª¨ì§€ í°íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ë¡œ ì‹œë„
                    draw.text((current_x, y), content, font=text_font, fill=color)
                    bbox = draw.textbbox((0, 0), content, font=text_font)
                
                current_x += bbox[2] - bbox[0]
        
    def create_fallback_image(self, width=1920, height=1080, color_index=0):
        """ì¸í„°ë„· ì—°ê²° ì—†ì´ ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ë‹¤ì–‘í•œ ìƒ‰ìƒ íŒ”ë ˆíŠ¸
            colors = [
                (255, 87, 51),   # ì£¼í™©ìƒ‰
                (51, 255, 87),   # ì´ˆë¡ìƒ‰  
                (51, 87, 255),   # íŒŒë€ìƒ‰
                (255, 51, 245),  # ìì£¼ìƒ‰
                (255, 195, 0),   # ë…¸ë€ìƒ‰
                (0, 195, 255),   # í•˜ëŠ˜ìƒ‰
            ]
            
            color = colors[color_index % len(colors)]
            
            # ì´ë¯¸ì§€ ìƒì„±
            img = Image.new('RGB', (width, height), color=color)
            draw = ImageDraw.Draw(img)
            
            # í…ìŠ¤íŠ¸ ì¶”ê°€
            try:
                font = ImageFont.truetype(self.font_path, 60)
            except:
                font = ImageFont.load_default()
            
            text = f"ë°°ê²½ ì´ë¯¸ì§€ {color_index + 1}"
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            
            x = (width - text_width) // 2
            y = (height - text_height) // 2
            
            # í…ìŠ¤íŠ¸ ê·¸ë¦¼ì
            draw.text((x + 2, y + 2), text, font=font, fill=(0, 0, 0))
            # í°ìƒ‰ í…ìŠ¤íŠ¸
            draw.text((x, y), text, font=font, fill=(255, 255, 255))
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
            img.save(temp_file.name, "JPEG", quality=85)
            temp_file.close()
            
            print(f"ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {temp_file.name}")
            return temp_file.name
            
        except Exception as e:
            print(f"ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def download_image(self, image_url):
        """ì´ë¯¸ì§€ URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (fallback í¬í•¨)"""
        try:
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„: {image_url}")
            
            # íƒ€ì„ì•„ì›ƒê³¼ í—¤ë” ì¶”ê°€
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(image_url, headers=headers, timeout=10)  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
            
            print(f"ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            response.raise_for_status()
            
            # ì´ë¯¸ì§€ ì½˜í…ì¸  ìœ íš¨ì„± ê²€ì‚¬
            if len(response.content) < 1000:
                raise Exception(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {len(response.content)} bytes")
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
            temp_file.write(response.content)
            temp_file.close()
            
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {temp_file.name} ({len(response.content)} bytes)")
            return temp_file.name
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({str(e)}), ê¸°ë³¸ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´")
            # URLì—ì„œ ìƒ‰ìƒ ì¸ë±ìŠ¤ ì¶”ì¶œ ì‹œë„
            color_index = 0
            try:
                if "Image+1" in image_url or "random=1" in image_url:
                    color_index = 0
                elif "Image+2" in image_url or "random=2" in image_url:
                    color_index = 1
                elif "Image+3" in image_url or "random=3" in image_url:
                    color_index = 2
                elif "Image+4" in image_url or "random=4" in image_url:
                    color_index = 3
            except:
                pass
                
            fallback_image = self.create_fallback_image(1920, 1080, color_index)
            if fallback_image:
                return fallback_image
            else:
                raise Exception(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ëª¨ë‘ ì‹¤íŒ¨: {str(e)}")
    
    def create_title_image(self, title, width, height):
        """ì œëª© ì´ë¯¸ì§€ ìƒì„±"""
        # ê²€ì€ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
        img = Image.new('RGB', (width, height), color='black')
        draw = ImageDraw.Draw(img)
        
        # í•œê¸€ í°íŠ¸ ì„¤ì • (2ë°° í¬ê¸°ë¡œ)
        try:
            font = ImageFont.truetype(self.font_path, 48)  # 24 â†’ 48ë¡œ 2ë°° í¬ê¸°
        except Exception as e:
            print(f"í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            try:
                font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 48)
            except:
                font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸° (ê¸´ ì œëª© ì²˜ë¦¬)
        words = title.split(' ')
        lines = []
        current_line = ""
        
        for word in words:
            test_line = current_line + " " + word if current_line else word
            bbox = draw.textbbox((0, 0), test_line, font=font)
            if bbox[2] - bbox[0] < width - 40:  # ì¢Œìš° ì—¬ë°± 20ì”©
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word
        
        if current_line:
            lines.append(current_line)
        
        # ì´ëª¨ì§€ í°íŠ¸ ì¤€ë¹„ (ì œëª© í°íŠ¸ í¬ê¸°ì— ë§ì¶¤)
        emoji_font_path = self.get_emoji_font()
        emoji_font = None
        if emoji_font_path:
            try:
                emoji_font = ImageFont.truetype(emoji_font_path, 44)  # 22 â†’ 44ë¡œ 2ë°° ì¦ê°€
            except:
                emoji_font = None
        
        # í…ìŠ¤íŠ¸ ì¤‘ì•™ ì •ë ¬ (í°íŠ¸ í¬ê¸°ì— ë§ì¶˜ ì¤„ê°„ê²©)
        line_height = 45  # 48px í°íŠ¸ì— ë§ì¶˜ ì ì • ì¤„ê°„ê²©
        total_height = len(lines) * line_height
        start_y = (height - total_height) // 2
        
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (width - text_width) // 2
            y = start_y + i * line_height
            
            # ì¼ë‹¨ ê¸°ë³¸ í°íŠ¸ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§ (ì´ëª¨ì§€ í¬í•¨)
            try:
                draw.text((x, y), line, font=font, fill='white')
            except Exception as e:
                print(f"í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
                # í´ë°±ìœ¼ë¡œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                default_font = ImageFont.load_default()
                draw.text((x, y), line, font=default_font, fill='white')
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
        img.save(temp_file.name, "PNG")
        temp_file.close()
        
        return temp_file.name
    
    def create_simple_group_clip(self, image_path, group_segments, total_duration, title_image_path=None, text_position="bottom"):
        """ê°„ë‹¨í•œ ê·¸ë£¹ í´ë¦½ ìƒì„± (uploads í´ë”ìš©)"""
        print(f"    ğŸ”§ ê°„ë‹¨í•œ ê·¸ë£¹ í´ë¦½ ìƒì„±: {total_duration:.1f}ì´ˆ")
        
        # 1. ì—°ì† ë°°ê²½ ì´ë¯¸ì§€ (ì „ì²´ ê·¸ë£¹ ì‹œê°„ë™ì•ˆ)
        bg_clip = self.create_continuous_background_clip(image_path, total_duration)
        
        # 2. ìƒë‹¨ ê²€ì€ ì˜ì—­ (ì „ì²´ ì‹œê°„)
        black_top = ColorClip(size=(self.video_width, 180), color=(0,0,0))
        black_top = black_top.set_duration(total_duration).set_position((0, 0))
        
        # 3. ì œëª© í´ë¦½ ì„¤ì •
        if title_image_path and os.path.exists(title_image_path):
            title_clip = ImageClip(title_image_path).set_duration(total_duration).set_position((0, 0))
        else:
            title_clip = None
        
        # 4. ê° í…ìŠ¤íŠ¸ë¥¼ ì‹œê°„ë³„ë¡œ ë°°ì¹˜
        text_clips = []
        current_time = 0.0
        
        for body_key, body_text, tts_path, clip_duration in group_segments:
            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height - 180, text_position)
            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(clip_duration).set_position((0, 180))
            text_clips.append(text_clip)
            current_time += clip_duration
        
        # 5. í•©ì„±
        composition_clips = [bg_clip, black_top]
        if title_clip:
            composition_clips.append(title_clip)
        composition_clips.extend(text_clips)
        
        group_final = CompositeVideoClip(composition_clips, size=(self.video_width, self.video_height))
        
        return group_final

    def create_truly_continuous_group_clip(self, image_path, group_segments, total_duration, title_image_path, text_position="bottom"):
        """ê·¸ë£¹ ë‚´ì—ì„œ ì •ë§ ëŠê¸°ì§€ ì•ŠëŠ” ì—°ì† í´ë¦½ ìƒì„±"""
        print(f"    ğŸ”§ ì—°ì† ê·¸ë£¹ í´ë¦½ ìƒì„±: {total_duration:.1f}ì´ˆ")
        
        # 1. ì—°ì† ë°°ê²½ ì´ë¯¸ì§€ (ì „ì²´ ê·¸ë£¹ ì‹œê°„ë™ì•ˆ - ëŠê¸°ì§€ ì•ŠìŒ!)
        bg_clip = self.create_continuous_background_clip(image_path, total_duration)
        
        # 2. ìƒë‹¨ ê²€ì€ ì˜ì—­ (ì „ì²´ ì‹œê°„)
        black_top = ColorClip(size=(self.video_width, 180), color=(0,0,0))
        black_top = black_top.set_duration(total_duration).set_position((0, 0))
        
        # 3. ì œëª© (ì „ì²´ ì‹œê°„)
        title_clip = ImageClip(title_image_path).set_duration(total_duration).set_position((0, 0))
        
        # 4. ê°„ë‹¨í•œ ë°©ë²•: ê° í…ìŠ¤íŠ¸ë¥¼ ì‹œê°„ë³„ë¡œ ë°°ì¹˜
        text_clips = []
        current_time = 0.0
        
        for body_key, body_text, tts_path, clip_duration in group_segments:
            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height - 180, text_position)
            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(clip_duration).set_position((0, 180))
            text_clips.append(text_clip)
            current_time += clip_duration
        
        # 5. í•©ì„± (ë°°ê²½ì€ ì—°ì†, í…ìŠ¤íŠ¸ë§Œ ì‹œê°„ë³„ë¡œ)
        group_final = CompositeVideoClip([
            bg_clip,     # ì—°ì† ë°°ê²½
            black_top,   # ìƒë‹¨
            title_clip,  # ì œëª©
        ] + text_clips, size=(self.video_width, self.video_height))
        
        return group_final
    
    def create_text_image(self, text, width, height, text_position="bottom"):
        """í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (ë°°ê²½ ë°•ìŠ¤ í¬í•¨)"""
        # íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
        img = Image.new('RGBA', (width, height), color=(0, 0, 0, 0))
        draw = ImageDraw.Draw(img)
        
        # í•œê¸€ í°íŠ¸ ì„¤ì • (ë°”ë”” í…ìŠ¤íŠ¸ìš©, 36ptë¡œ ì¡°ì •)
        try:
            font = ImageFont.truetype(self.font_path, 36)  # 36ptë¡œ ì„¤ì •
        except Exception as e:
            print(f"í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            try:
                font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", 36)
            except:
                font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
        words = text.split(' ')
        lines = []
        current_line = ""
        
        for word in words:
            test_line = current_line + " " + word if current_line else word
            bbox = draw.textbbox((0, 0), test_line, font=font)
            if bbox[2] - bbox[0] < width - 60:  # ì—¬ë°± ê³ ë ¤ (ì¢Œìš° 30ì”©)
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word
        
        if current_line:
            lines.append(current_line)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ë°•ìŠ¤ í¬ê¸° ê³„ì‚° (í°íŠ¸ í¬ê¸°ì— ë§ì¶˜ ì¤„ê°„ê²©)
        line_height = 40  # 36pt í°íŠ¸ì— ë§ì¶˜ ì ì • ì¤„ê°„ê²©
        total_height = len(lines) * line_height
        padding = 20  # íŒ¨ë”© ì¡°ì •
        
        # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚° (ë°•ìŠ¤ ì—†ì´)
        if text_position == "top":
            # ìƒ: íƒ€ì´í‹€ ì•„ë˜ (10í”½ì…€ ê°„ê²©)
            title_height = 120  # íƒ€ì´í‹€ ì˜ì—­ ë†’ì´
            start_y = title_height + 10 + padding
        elif text_position == "middle":
            # ì¤‘: í™”ë©´ ì¤‘ì•™
            start_y = (height - total_height) // 2
        else:  # bottom (ê¸°ë³¸ê°’)
            # í•˜: í™”ë©´ í•˜ë‹¨ (ê¸°ì¡´ ìœ„ì¹˜ë³´ë‹¤ ë” ì•„ë˜)
            start_y = height - total_height - 70  # í•˜ë‹¨ì—ì„œ 70í”½ì…€ ìœ„
        
        # ì´ëª¨ì§€ í°íŠ¸ ì¤€ë¹„ (ë³¸ë¬¸ í°íŠ¸ í¬ê¸°ì— ë§ì¶¤)
        emoji_font_path = self.get_emoji_font()
        emoji_font = None
        if emoji_font_path:
            try:
                emoji_font = ImageFont.truetype(emoji_font_path, 32)  # 36pt ë³¸ë¬¸ì— ë§ì¶˜ ì´ëª¨ì§€ í¬ê¸°
            except:
                emoji_font = None
        
        # í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸° (ì™¸ê³½ì„  íš¨ê³¼ë¡œ ê°€ë…ì„± í™•ë³´)
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (width - text_width) // 2
            y = start_y + i * line_height
            
            # í…ìŠ¤íŠ¸ ë Œë”ë§ (ë¶€ë“œëŸ¬ìš´ ì™¸ê³½ì„  íš¨ê³¼)
            try:
                # ë” ë¶€ë“œëŸ¬ìš´ ì™¸ê³½ì„  (2px ë‘ê»˜)
                outline_positions = [
                    (-2, -2), (-2, -1), (-2, 0), (-2, 1), (-2, 2),
                    (-1, -2), (-1, -1), (-1, 0), (-1, 1), (-1, 2),
                    (0, -2), (0, -1),           (0, 1), (0, 2),
                    (1, -2), (1, -1), (1, 0), (1, 1), (1, 2),
                    (2, -2), (2, -1), (2, 0), (2, 1), (2, 2)
                ]
                
                # ê²€ì€ìƒ‰ ì™¸ê³½ì„  ê·¸ë¦¬ê¸°
                for dx, dy in outline_positions:
                    draw.text((x + dx, y + dy), line, font=font, fill='black')
                
                # í°ìƒ‰ í…ìŠ¤íŠ¸ (ì¤‘ì•™)
                draw.text((x, y), line, font=font, fill='white')
                
            except Exception as e:
                print(f"ë³¸ë¬¸ í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
                # í´ë°±: ê¸°ë³¸ ì™¸ê³½ì„ 
                for dx in [-1, 0, 1]:
                    for dy in [-1, 0, 1]:
                        if dx != 0 or dy != 0:
                            draw.text((x + dx, y + dy), line, font=font, fill='black')
                draw.text((x, y), line, font=font, fill='white')
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
        img.save(temp_file.name, "PNG")
        temp_file.close()
        
        return temp_file.name
    
    def crop_to_square(self, image_path):
        """ì´ë¯¸ì§€ë¥¼ ì¤‘ì•™ ê¸°ì¤€ ì •ì‚¬ê°í˜•ìœ¼ë¡œ í¬ë¡­í•˜ì—¬ 716x716ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ"""
        try:
            with Image.open(image_path) as img:
                width, height = img.size
                print(f"ğŸ”³ ì´ë¯¸ì§€ ë¡œë“œ: {image_path} ({width}x{height})")
                
                # ì´ë¯¸ 716x716ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
                if width == 716 and height == 716:
                    print(f"ğŸ”³ ì´ë¯¸ 716x716: ë³€í™˜ ë¶ˆí•„ìš”")
                    return image_path
                
                # ì§§ì€ ë³€ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ì‚¬ê°í˜• í¬ê¸° ê²°ì •
                crop_size = min(width, height)
                
                # ì¤‘ì•™ ê¸°ì¤€ í¬ë¡­ ì¢Œí‘œ ê³„ì‚°
                left = (width - crop_size) // 2
                top = (height - crop_size) // 2
                right = left + crop_size
                bottom = top + crop_size
                
                # í¬ë¡­ ì‹¤í–‰ (ì •ì‚¬ê°í˜•ì´ ì•„ë‹Œ ê²½ìš°ë§Œ)
                if width != height:
                    cropped_img = img.crop((left, top, right, bottom))
                    print(f"ğŸ”³ í¬ë¡­ ì‹¤í–‰: {width}x{height} â†’ {crop_size}x{crop_size}")
                else:
                    cropped_img = img.copy()
                    print(f"ğŸ”³ ì •ì‚¬ê°í˜• ì´ë¯¸ì§€: í¬ë¡­ ìƒëµ")
                
                # í•­ìƒ 716x716ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (PIL ë²„ì „ í˜¸í™˜ì„± ê³ ë ¤)
                try:
                    # Pillow 10.0.0+ ë²„ì „
                    resized_img = cropped_img.resize((716, 716), Image.Resampling.LANCZOS)
                except AttributeError:
                    # ì´ì „ ë²„ì „ í˜¸í™˜ì„±
                    resized_img = cropped_img.resize((716, 716), Image.LANCZOS)
                
                # RGBA ëª¨ë“œì¸ ê²½ìš° RGBë¡œ ë³€í™˜ (JPEG ì €ì¥ ìœ„í•´)
                if resized_img.mode in ('RGBA', 'LA', 'P'):
                    # í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ ë³€í™˜
                    background = Image.new('RGB', resized_img.size, (255, 255, 255))
                    if resized_img.mode == 'P':
                        resized_img = resized_img.convert('RGBA')
                    background.paste(resized_img, mask=resized_img.split()[-1] if resized_img.mode in ('RGBA', 'LA') else None)
                    resized_img = background
                    print(f"ğŸ”³ RGBA â†’ RGB ë³€í™˜ ì™„ë£Œ")
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
                resized_img.save(temp_file.name, 'JPEG', quality=95)
                
                print(f"ğŸ”³ ìµœì¢… ë¦¬ì‚¬ì´ì¦ˆ: â†’ 716x716")
                print(f"ğŸ”³ ì„ì‹œ íŒŒì¼ ìƒì„±: {temp_file.name}")
                
                return temp_file.name
                
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì—ëŸ¬: {image_path}")
            print(f"âŒ ì—ëŸ¬ ë‚´ìš©: {str(e)}")
            # ì—ëŸ¬ ë°œìƒì‹œ ì›ë³¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return image_path

    def easing_function(self, p):
        """ë”ìš± ë¶€ë“œëŸ¬ìš´ ì´ì§• í•¨ìˆ˜ (cubic ease-in-out)"""
        if p < 0.5:
            return 4 * p * p * p
        else:
            return 1 - pow(-2 * p + 2, 3) / 2

    def create_background_clip(self, image_path, duration):
        """3ê°€ì§€ Ken Burns íš¨ê³¼ ì¤‘ ëœë¤ ì„ íƒ - ì •ì‚¬ê°í˜• í¬ë¡­ + íŒ¨í„´ ì ìš©"""
        print(f"ğŸ¬ ë°°ê²½ í´ë¦½ ìƒì„± ì‹œì‘: {image_path} (duration: {duration:.1f}s)")
        
        # ì´ë¯¸ì§€ë¥¼ ì •ì‚¬ê°í˜•ìœ¼ë¡œ í¬ë¡­ í›„ 716x716ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        square_image_path = self.crop_to_square(image_path)
        
        try:
            # ë°°ê²½ í´ë¦½ ìƒì„±
            bg_clip = ImageClip(square_image_path).set_duration(duration)
            
            # íƒ€ì´í‹€ ì•„ë˜ ì˜ì—­ ê³„ì‚° (íƒ€ì´í‹€ ë†’ì´ 180px)
            title_height = 180
            
            # 2ê°€ì§€ íŒ¨ë‹ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ (í™•ëŒ€ íŒ¨í„´ ì œê±°)
            pattern = random.randint(1, 2)
            
            if duration > 3:
                if pattern == 1:
                    # íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹
                    def left_to_right(t):
                        progress = self.easing_function(t / duration)  # ë¶€ë“œëŸ¬ìš´ ì´ì§• ì ìš©
                        # 302px ì—¬ìœ ê³µê°„ì—ì„œ 30px ì´ë™ (3ì´ˆì— ì¤‘ì•™ í†µê³¼)
                        mid_point = 3.0 / duration  # 3ì´ˆ ì§€ì 
                        if t / duration <= mid_point:
                            # 0 â†’ 0.5
                            q = 0.5 * progress / mid_point
                        else:
                            # 0.5 â†’ 1
                            q = 0.5 + 0.5 * (progress - mid_point) / (1 - mid_point)
                        x_offset = -(151 - 30 * q)  # ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ
                        return (x_offset, title_height)
                    
                    bg_clip = bg_clip.set_position(left_to_right)
                    print(f"ğŸ¬ íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹ (duration: {duration:.1f}s)")
                    
                else:
                    # íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹
                    def right_to_left(t):
                        progress = self.easing_function(t / duration)  # ë¶€ë“œëŸ¬ìš´ ì´ì§• ì ìš©
                        # 302px ì—¬ìœ ê³µê°„ì—ì„œ 30px ì´ë™ (3ì´ˆì— ì¤‘ì•™ í†µê³¼)
                        mid_point = 3.0 / duration  # 3ì´ˆ ì§€ì 
                        if t / duration <= mid_point:
                            # 1 â†’ 0.5
                            q = 1 - 0.5 * progress / mid_point
                        else:
                            # 0.5 â†’ 0
                            q = 0.5 - 0.5 * (progress - mid_point) / (1 - mid_point)
                        x_offset = -(151 - 30 * q)  # ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ
                        return (x_offset, title_height)
                    
                    bg_clip = bg_clip.set_position(right_to_left)
                    print(f"ğŸ¬ íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹ (duration: {duration:.1f}s)")
                
            else:
                # ì§§ì€ í´ë¦½ì€ ì¤‘ì•™ ê³ ì • (íŒ¨í„´ì— ê´€ê³„ì—†ì´)
                x_center = (716 - 414) // 2  # ì¤‘ì•™ ìœ„ì¹˜ = 151px
                bg_clip = bg_clip.set_position((x_center, title_height))
                print(f"ğŸ¬ ì§§ì€ í´ë¦½: ì¤‘ì•™ ê³ ì • ({x_center}px)")
            
            return bg_clip
                
        except Exception as e:
            print(f"âŒ ë°°ê²½ í´ë¦½ ìƒì„± ì—ëŸ¬: {str(e)}")
            # ì—ëŸ¬ ë°œìƒì‹œ ê¸°ë³¸ í´ë¦½ ë°˜í™˜
            fallback_clip = ImageClip(image_path).set_duration(duration)
            fallback_clip = fallback_clip.resize(height=716).set_position((0, 180))
            return fallback_clip
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if square_image_path != image_path and os.path.exists(square_image_path):
                try:
                    os.unlink(square_image_path)
                    print(f"ğŸ—‘ï¸ ì„ì‹œ íŒŒì¼ ì •ë¦¬: {square_image_path}")
                except:
                    pass


    
    def create_continuous_background_clip(self, image_path, total_duration, start_offset=0.0):
        """2ê°œ body ë™ì•ˆ ì—°ì†ì ìœ¼ë¡œ ì›€ì§ì´ëŠ” ë°°ê²½ í´ë¦½ ìƒì„± - 3ê°€ì§€ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ"""
        print(f"ğŸ¬ ì—°ì† ë°°ê²½ í´ë¦½ ìƒì„±: {image_path} (duration: {total_duration:.1f}s, offset: {start_offset:.1f}s)")
        
        # ì´ë¯¸ì§€ë¥¼ ì •ì‚¬ê°í˜•ìœ¼ë¡œ í¬ë¡­ í›„ 716x716ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        square_image_path = self.crop_to_square(image_path)
        
        try:
            # ë°°ê²½ í´ë¦½ ìƒì„±
            bg_clip = ImageClip(square_image_path).set_duration(total_duration)
            
            # íƒ€ì´í‹€ ì•„ë˜ ì˜ì—­ ê³„ì‚°
            title_height = 180
            
            # 2ê°€ì§€ íŒ¨ë‹ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ (í™•ëŒ€ íŒ¨í„´ ì œê±°)
            pattern = random.randint(1, 2)
            
            # ì—°ì†ì„±ì„ ê³ ë ¤í•œ íš¨ê³¼ ì ìš©
            if total_duration > 3:
                if pattern == 1:
                    # íŒ¨í„´ 1: ì—°ì† ì¢Œ â†’ ìš° íŒ¨ë‹
                    def continuous_left_to_right(t):
                        # ì‹œì‘ ì˜¤í”„ì…‹ì„ ê³ ë ¤í•œ ì „ì²´ ì§„í–‰ë„
                        total_progress = (t + start_offset) / (total_duration + start_offset + 3)
                        progress = self.easing_function(total_progress)
                        # 30px ì´ë™ ë²”ìœ„ì—ì„œ ì—°ì†ì„± ìœ ì§€
                        x_offset = -(151 - 30 * progress)
                        return (x_offset, title_height)
                    
                    bg_clip = bg_clip.set_position(continuous_left_to_right)
                    print(f"ğŸ¬ ì—°ì† íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹")
                    
                else:
                    # íŒ¨í„´ 2: ì—°ì† ìš° â†’ ì¢Œ íŒ¨ë‹
                    def continuous_right_to_left(t):
                        # ì‹œì‘ ì˜¤í”„ì…‹ì„ ê³ ë ¤í•œ ì „ì²´ ì§„í–‰ë„
                        total_progress = (t + start_offset) / (total_duration + start_offset + 3)
                        progress = self.easing_function(total_progress)
                        # 30px ì´ë™ ë²”ìœ„ì—ì„œ ì—°ì†ì„± ìœ ì§€ (ë°˜ëŒ€ ë°©í–¥)
                        x_offset = -(151 - 30 * (1 - progress))
                        return (x_offset, title_height)
                    
                    bg_clip = bg_clip.set_position(continuous_right_to_left)
                    print(f"ğŸ¬ ì—°ì† íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹")
                    
            else:
                # ì§§ì€ í´ë¦½ì€ ì¤‘ì•™ ê³ ì •
                x_center = (716 - 414) // 2
                bg_clip = bg_clip.set_position((x_center, title_height))
                print(f"ğŸ¬ ì—°ì† ì§§ì€ í´ë¦½: ì¤‘ì•™ ê³ ì • ({x_center}px)")
            
            return bg_clip
                
        except Exception as e:
            print(f"âŒ ì—°ì† ë°°ê²½ í´ë¦½ ì—ëŸ¬: {str(e)}")
            # ì—ëŸ¬ ë°œìƒì‹œ ê¸°ë³¸ í´ë¦½ ë°˜í™˜
            fallback_clip = ImageClip(image_path).set_duration(total_duration)
            fallback_clip = fallback_clip.resize(height=716).set_position((0, 180))
            return fallback_clip
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if square_image_path != image_path and os.path.exists(square_image_path):
                try:
                    os.unlink(square_image_path)
                    print(f"ğŸ—‘ï¸ ì—°ì† ì„ì‹œ íŒŒì¼ ì •ë¦¬: {square_image_path}")
                except:
                    pass

    
    def create_video_background_clip(self, video_path, duration):
        """ë¹„ë””ì˜¤ ë°°ê²½ í´ë¦½ ìƒì„± - 414px í­ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ í›„ íƒ€ì´í‹€ ì•„ë˜ ì¤‘ì•™ì •ë ¬"""
        from moviepy.editor import VideoFileClip, ColorClip, CompositeVideoClip
        
        try:
            print(f"ğŸ¬ ë¹„ë””ì˜¤ ë°°ê²½ í´ë¦½ ìƒì„± ì‹œì‘: {video_path}")
            
            # ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œ
            video_clip = VideoFileClip(video_path)
            
            # íƒ€ì´í‹€ ì•„ë˜ ì˜ì—­ ê³„ì‚° (íƒ€ì´í‹€ ë†’ì´ 180px)
            title_height = 180
            available_height = self.video_height - title_height  # 896 - 180 = 716px
            
            # ë¹„ë””ì˜¤ ì›ë³¸ í¬ê¸°
            orig_width = video_clip.w
            orig_height = video_clip.h
            
            print(f"ğŸ“ ë¹„ë””ì˜¤ ì›ë³¸: {orig_width}x{orig_height}")
            print(f"ğŸ¯ ëª©í‘œ: í­ 414pxë¡œ ë¦¬ì‚¬ì´ì¦ˆ í›„ íƒ€ì´í‹€ ì•„ë˜ ì¤‘ì•™ì •ë ¬")
            
            # 1ë‹¨ê³„: ì „ì²´ ë°°ê²½ì„ ê²€ì€ìƒ‰ìœ¼ë¡œ ì±„ìš°ê¸°
            black_background = ColorClip(size=(self.video_width, available_height), 
                                       color=(0,0,0), duration=duration)
            black_background = black_background.set_position((0, title_height))
            
            # 2ë‹¨ê³„: ë¹„ë””ì˜¤ë¥¼ 414px í­ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ì¢…íš¡ë¹„ ìœ ì§€)
            if orig_width < self.video_width:
                print(f"ğŸ“ˆ ë¹„ë””ì˜¤ í­ í™•ì¥ í•„ìš”: {orig_width}px â†’ {self.video_width}px")
                # ì‘ì€ ë¹„ë””ì˜¤ëŠ” 414pxë¡œ í™•ì¥ (ì¢…íš¡ë¹„ ìœ ì§€)
                video_clip = video_clip.resize(width=self.video_width)
            elif orig_width > self.video_width:
                print(f"ğŸ“‰ ë¹„ë””ì˜¤ í­ ì¶•ì†Œ í•„ìš”: {orig_width}px â†’ {self.video_width}px")
                # í° ë¹„ë””ì˜¤ëŠ” 414pxë¡œ ì¶•ì†Œ (ì¢…íš¡ë¹„ ìœ ì§€)
                video_clip = video_clip.resize(width=self.video_width)
            else:
                print(f"âœ… ë¹„ë””ì˜¤ í­ ì´ë¯¸ ì ì •: {orig_width}px = {self.video_width}px")
            
            resized_height = video_clip.h
            print(f"ğŸ”§ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ: {self.video_width}x{resized_height}")
            
            # 3ë‹¨ê³„: ë¹„ë””ì˜¤ ê¸¸ì´ ì¡°ì •
            if video_clip.duration > duration:
                video_clip = video_clip.subclip(0, duration)
                print(f"â‚ ë¹„ë””ì˜¤ ê¸¸ì´ ì¡°ì •: {duration}ì´ˆë¡œ ì˜ë¼ëƒ„")
            elif video_clip.duration < duration:
                last_frame_time = max(video_clip.duration - 0.1, 0)
                last_frame = video_clip.to_ImageClip(t=last_frame_time)
                extension_duration = duration - video_clip.duration
                extension_clip = last_frame.set_duration(extension_duration)
                video_clip = CompositeVideoClip([video_clip, extension_clip.set_start(video_clip.duration)])
                print(f"â© ë¹„ë””ì˜¤ ê¸¸ì´ ì—°ì¥: {duration}ì´ˆê¹Œì§€ ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì±„ì›€")
            
            # 4ë‹¨ê³„: íƒ€ì´í‹€ ë°”ë¡œ ì•„ë˜ì— ì¤‘ì•™ì •ë ¬ë¡œ ìœ„ì¹˜ ì„¤ì •
            x_center = 0  # ê°€ë¡œëŠ” ì´ë¯¸ 414pxë¡œ ë§ì¶¤
            y_position = title_height  # íƒ€ì´í‹€ ë°”ë¡œ ì•„ë˜
            
            video_clip = video_clip.set_position((x_center, y_position))
            
            # 5ë‹¨ê³„: ê²€ì€ ë°°ê²½ ìœ„ì— ë¹„ë””ì˜¤ í•©ì„±
            final_clip = CompositeVideoClip([black_background, video_clip])
            
            print(f"âœ… ì™„ì„±: ê²€ì€ë°°ê²½({self.video_width}x{available_height}) + ë¹„ë””ì˜¤({self.video_width}x{resized_height})")
            print(f"ğŸ‰ ë¹„ë””ì˜¤ ë°°ê²½ í´ë¦½ ìƒì„± ì™„ë£Œ!")
            
            return final_clip
            
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ë°°ê²½ í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            
            # ì‹¤íŒ¨ ì‹œ ê²€ì€ í™”ë©´ìœ¼ë¡œ ëŒ€ì²´
            title_height = 180
            available_height = self.video_height - title_height
            fallback_clip = ColorClip(size=(self.video_width, available_height), 
                                    color=(0,0,0), duration=duration)
            fallback_clip = fallback_clip.set_position((0, title_height))
            print(f"ğŸ”„ ê²€ì€ í™”ë©´ìœ¼ë¡œ ëŒ€ì²´: {self.video_width}x{available_height}")
            return fallback_clip
    
    def create_tts_with_naver(self, text):
        """ë„¤ì´ë²„ Clova Voice TTS ìƒì„±"""
        if not self.naver_client_id or not self.naver_client_secret:
            return None
            
        try:
            print(f"ë„¤ì´ë²„ TTS ìƒì„± ì¤‘: {text[:50]}...")
            
            # Naver Clova Voice API í˜¸ì¶œ
            url = "https://naveropenapi.apigw.ntruss.com/tts-premium/v1/tts"
            headers = {
                "X-NCP-APIGW-API-KEY-ID": self.naver_client_id,
                "X-NCP-APIGW-API-KEY": self.naver_client_secret,
                "Content-Type": "application/x-www-form-urlencoded"
            }
            
            data = {
                "speaker": "nara",  # ì—¬ì„± ìŒì„± (clara, matt, shinji, nara ë“± ì„ íƒ ê°€ëŠ¥)
                "volume": "0",      # ë³¼ë¥¨ (-5~5)
                "speed": "0",       # ì†ë„ (-5~5)
                "pitch": "0",       # ìŒë†’ì´ (-5~5)
                "format": "mp3",    # ì¶œë ¥ í¬ë§·
                "text": text
            }
            
            response = requests.post(url, headers=headers, data=data)
            
            if response.status_code == 200:
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
                temp_file.write(response.content)
                temp_file.close()
                print(f"ë„¤ì´ë²„ TTS ìƒì„± ì™„ë£Œ: {temp_file.name}")
                return temp_file.name
            else:
                print(f"ë„¤ì´ë²„ TTS API ì˜¤ë¥˜: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"ë„¤ì´ë²„ TTS ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def create_tts_with_azure(self, text):
        """Microsoft Azure Cognitive Services TTS ìƒì„±"""
        if not self.azure_speech_key:
            return None
            
        try:
            print(f"Azure TTS ìƒì„± ì¤‘: {text[:50]}...")
            
            # Azure Cognitive Services Speech API í˜¸ì¶œ
            url = f"https://{self.azure_speech_region}.tts.speech.microsoft.com/cognitiveservices/v1"
            headers = {
                "Ocp-Apim-Subscription-Key": self.azure_speech_key,
                "Content-Type": "application/ssml+xml",
                "X-Microsoft-OutputFormat": "audio-24khz-48kbitrate-mono-mp3"
            }
            
            # SSML í˜•ì‹ìœ¼ë¡œ ìš”ì²­ ìƒì„± (í•œêµ­ì–´ ì—¬ì„± ìŒì„±)
            ssml = f"""<speak version='1.0' xml:lang='ko-KR'>
                <voice xml:lang='ko-KR' xml:gender='Female' name='ko-KR-SunHiNeural'>
                    <prosody rate='medium' pitch='medium'>
                        {text}
                    </prosody>
                </voice>
            </speak>"""
            
            response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
            
            if response.status_code == 200:
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
                temp_file.write(response.content)
                temp_file.close()
                print(f"Azure TTS ìƒì„± ì™„ë£Œ: {temp_file.name}")
                return temp_file.name
            else:
                print(f"Azure TTS API ì˜¤ë¥˜: {response.status_code}, {response.text}")
                return None
                
        except Exception as e:
            print(f"Azure TTS ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def create_tts_audio(self, text, lang='ko'):
        """Google TTSë¡œ ìµœì í™”ëœ í•œêµ­ì–´ ìŒì„± ìƒì„±"""
        try:
            print(f"Google TTS ìƒì„± ì¤‘: {text[:50]}...")
            
            # í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ë” ìì—°ìŠ¤ëŸ½ê²Œ)
            processed_text = self.preprocess_korean_text(text)
            
            # ìµœì í™”ëœ í•œêµ­ì–´ Google TTS ì„¤ì •
            tts = gTTS(
                text=processed_text, 
                lang='ko',  # ëª…ì‹œì ìœ¼ë¡œ í•œêµ­ì–´ ì„¤ì •
                slow=False,
                tld='com'   # êµ¬ê¸€ ë„ë©”ì¸ ìµœì í™”
            )
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
            tts.save(temp_file.name)
            temp_file.close()
            print(f"Google TTS ìƒì„± ì™„ë£Œ (ìµœì í™”): {temp_file.name}")
            return temp_file.name
            
        except Exception as e:
            print(f"TTS ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def preprocess_korean_text(self, text):
        """í•œêµ­ì–´ TTS í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ê°„ë‹¨ ë²„ì „)"""
        try:
            import re
            processed = text.strip()
            
            # 1. ì´ëª¨ì§€ë§Œ ì œê±° (í•œê¸€ í…ìŠ¤íŠ¸ëŠ” ë³´ì¡´)
            emoji_pattern = re.compile("["
                u"\U0001F600-\U0001F64F"  # emoticons
                u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                u"\U0001F680-\U0001F6FF"  # transport & map symbols
                u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                "]+", flags=re.UNICODE)
            processed = emoji_pattern.sub(' ', processed)
            
            # 2. ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ, ë¬¼ê²°í‘œì‹œë¥¼ ë§ˆì¹¨í‘œë¡œ ë³€í™˜
            processed = re.sub(r'[?!~]+', '.', processed)
            
            # 3. ê³µë°± ì •ë¦¬
            processed = re.sub(r'\s+', ' ', processed).strip()
            if processed and not processed.endswith('.'):
                processed += '.'
            
            print(f"TTS ì „ì²˜ë¦¬ ì „: {text}")
            print(f"TTS ì „ì²˜ë¦¬ í›„: {processed}")
            
            return processed
            
        except Exception as e:
            print(f"í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return text  # ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
    
    def get_audio_duration(self, audio_path):
        """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì‹¤ì œ ì¬ìƒ ì‹œê°„ ë°˜í™˜"""
        try:
            audio = AudioFileClip(audio_path)
            duration = audio.duration
            audio.close()
            return duration
        except Exception as e:
            print(f"ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨: {e}")
            return 3.0  # ê¸°ë³¸ê°’
    
    def get_local_images(self, test_folder="./test"):
        """test í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì´ë¦„ìˆœìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        import glob
        
        # ì´ë¯¸ì§€ í™•ì¥ì íŒ¨í„´ (webp ì¶”ê°€)
        image_patterns = ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.gif", "*.webp"]
        image_files = []
        
        for pattern in image_patterns:
            files = glob.glob(os.path.join(test_folder, pattern))
            files.extend(glob.glob(os.path.join(test_folder, pattern.upper())))
            image_files.extend(files)
        
        # ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬ (1.png, 2.png, 3.png, 4.png)
        import re
        def natural_sort_key(path):
            filename = os.path.basename(path).lower()
            # ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
            numbers = re.findall(r'\d+', filename)
            if numbers:
                return int(numbers[0])  # ì²« ë²ˆì§¸ ìˆ«ìë¡œ ì •ë ¬
            else:
                return float('inf')  # ìˆ«ìê°€ ì—†ìœ¼ë©´ ë§¨ ë’¤ë¡œ
        
        image_files.sort(key=natural_sort_key)
        
        print(f"ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {len(image_files)}ê°œ (ìˆ«ì ìˆœì„œëŒ€ë¡œ)")
        for i, file in enumerate(image_files):
            print(f"  {i+1}. {os.path.basename(file)}")
        
        if len(image_files) == 0:
            print("âŒ test í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            print(f"âœ… ì´ë¯¸ì§€ ì‚¬ìš© ìˆœì„œ: {' â†’ '.join([os.path.basename(f) for f in image_files])}")
        
        return image_files
    
    def create_video_with_local_images(self, content, music_path, output_folder, image_allocation_mode="2_per_image", text_position="bottom"):
        """ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì‚¬ìš©í•œ ë¦´ìŠ¤ ì˜ìƒ ìƒì„±"""
        try:
            # ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
            local_images = self.get_local_images()
            
            if not local_images:
                raise Exception("test í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            
            print(f"ë¡œì»¬ ì´ë¯¸ì§€ {len(local_images)}ê°œë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ìƒì„±")
            
            # ì œëª© ì´ë¯¸ì§€ ìƒì„± (414x180, ë” ë„“ì€ ì˜ì—­)
            title_image_path = self.create_title_image(
                content['title'], 
                self.video_width, 
                180
            )
            
            # ê° bodyë³„ë¡œ ê°œë³„ TTS ìƒì„± (ë¹ˆ ê°’ ì œì™¸)
            body_keys = [key for key in content.keys() if key.startswith('body') and content[key].strip()]
            tts_files = []
            
            for body_key in body_keys:
                print(f"{body_key} TTS ìƒì„± ì¤‘...")
                body_tts = self.create_tts_audio(content[body_key])
                if body_tts:
                    body_duration = self.get_audio_duration(body_tts)
                    tts_files.append((body_key, body_tts, body_duration))
                    print(f"{body_key} TTS ì™„ë£Œ: {body_duration:.1f}ì´ˆ")
            
            # ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
            print(f"ğŸ¬ ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ: {image_allocation_mode}")
            
            group_clips = []
            audio_segments = []
            
            if image_allocation_mode == "1_per_image":
                # Mode 2: body 1ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (1:1 ë§¤ì¹­)
                print("ğŸ–¼ï¸ 1:1 ë§¤ì¹­ ëª¨ë“œ: bodyë³„ë¡œ ê°ê° ë‹¤ë¥¸ ì´ë¯¸ì§€ ì‚¬ìš©")
                
                for i, body_key in enumerate(body_keys):
                    # bodyë³„ë¡œ ê°œë³„ ì´ë¯¸ì§€ í• ë‹¹ (ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ì‚¬ìš©)
                    image_index = min(i, len(local_images) - 1)
                    current_image_path = local_images[image_index]
                    
                    # í•´ë‹¹ bodyì˜ TTS ì •ë³´ ì°¾ê¸°
                    body_tts_info = None
                    body_duration = 3.0
                    for tts_key, tts_path, tts_duration in tts_files:
                        if tts_key == body_key:
                            body_tts_info = (body_key, content[body_key], tts_path, tts_duration)
                            body_duration = tts_duration
                            break
                    else:
                        body_tts_info = (body_key, content[body_key], None, 3.0)
                    
                    # íŒŒì¼ íƒ€ì… í™•ì¸ (ë¹„ë””ì˜¤ vs ì´ë¯¸ì§€)
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm']
                    is_video = any(current_image_path.lower().endswith(ext) for ext in video_extensions)
                    file_type = "ë¹„ë””ì˜¤" if is_video else "ì´ë¯¸ì§€"
                    
                    print(f"ğŸ“¸ {body_key}: {file_type} {image_index + 1}/{len(local_images)} â†’ '{os.path.basename(current_image_path)}' ({body_duration:.1f}ì´ˆ)")
                    
                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ë°°ê²½ í´ë¦½ ìƒì„±
                    if is_video:
                        bg_clip = self.create_video_background_clip(current_image_path, body_duration)
                    else:
                        bg_clip = self.create_background_clip(current_image_path, body_duration)
                    black_top = ColorClip(size=(self.video_width, 180), color=(0,0,0)).set_duration(body_duration).set_position((0, 0))
                    title_clip = ImageClip(title_image_path).set_duration(body_duration).set_position((0, 0))
                    
                    # í…ìŠ¤íŠ¸ í´ë¦½
                    text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height - 180, text_position)
                    text_clip = ImageClip(text_image_path).set_duration(body_duration).set_position((0, 180))
                    
                    # ê°œë³„ í´ë¦½ í•©ì„±
                    individual_clip = CompositeVideoClip([bg_clip, black_top, title_clip, text_clip], size=(self.video_width, self.video_height))
                    group_clips.append(individual_clip)
                    print(f"    âœ… {body_key} ì™„ë£Œ: ê°œë³„ ì´ë¯¸ì§€ ì ìš©")
                    
                    # ì˜¤ë””ì˜¤ ì¶”ê°€
                    if body_tts_info[2]:  # tts_pathê°€ ìˆìœ¼ë©´
                        audio_segments.append(AudioFileClip(body_tts_info[2]))
                        
            else:  # image_allocation_mode == "2_per_image"
                # Mode 1: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (ê·¸ë£¹ ë°©ì‹)
                print("ğŸ–¼ï¸ 2:1 ë§¤ì¹­ ëª¨ë“œ: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ ì‚¬ìš©")
                
                for group_idx in range(0, len(body_keys), 2):
                    group_bodies = body_keys[group_idx:group_idx + 2]
                    # ê·¸ë£¹ ìˆœì„œëŒ€ë¡œ ì´ë¯¸ì§€ ì‚¬ìš© (body1,2 â†’ image0, body3,4 â†’ image1)
                    image_index = min(group_idx // 2, len(local_images) - 1)
                    current_image_path = local_images[image_index]
                    print(f"ê·¸ë£¹ {group_idx//2 + 1}: ì´ë¯¸ì§€ ì¸ë±ìŠ¤ {image_index}, íŒŒì¼: {os.path.basename(current_image_path)}")
                    
                    # ê·¸ë£¹ TTS ì •ë³´ ìˆ˜ì§‘
                    group_tts_info = []
                    group_total_duration = 0.0
                    
                    for body_key in group_bodies:
                        for tts_key, tts_path, tts_duration in tts_files:
                            if tts_key == body_key:
                                group_tts_info.append((body_key, content[body_key], tts_path, tts_duration))
                                group_total_duration += tts_duration
                                break
                        else:
                            group_tts_info.append((body_key, content[body_key], None, 3.0))
                            group_total_duration += 3.0
                    
                    # íŒŒì¼ íƒ€ì… í™•ì¸ (ë¹„ë””ì˜¤ vs ì´ë¯¸ì§€)
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm']
                    is_video = any(current_image_path.lower().endswith(ext) for ext in video_extensions)
                    file_type = "ë¹„ë””ì˜¤" if is_video else "ì´ë¯¸ì§€"
                    
                    print(f"ğŸ“¸ ê·¸ë£¹ {group_idx//2 + 1}: {[info[0] for info in group_tts_info]} â†’ '{os.path.basename(current_image_path)}' ({file_type}, {group_total_duration:.1f}ì´ˆ)")
                    
                    # íŒŒì¼ íƒ€ì…ì— ë”°ë¥¸ ë°°ê²½ í´ë¦½ ìƒì„±
                    if is_video:
                        bg_clip = self.create_video_background_clip(current_image_path, group_total_duration)
                    else:
                        bg_clip = self.create_continuous_background_clip(current_image_path, group_total_duration, 0.0)
                    black_top = ColorClip(size=(self.video_width, 180), color=(0,0,0)).set_duration(group_total_duration)
                    title_clip = ImageClip(title_image_path).set_duration(group_total_duration).set_position((0, 0))
                    
                    # í…ìŠ¤íŠ¸ í´ë¦½ë“¤
                    text_clips = []
                    current_time = 0.0
                    for body_key, body_text, tts_path, duration in group_tts_info:
                        text_image_path = self.create_text_image(body_text, self.video_width, self.video_height - 180, text_position)
                        text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(duration).set_position((0, 180))
                        text_clips.append(text_clip)
                        print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                        current_time += duration
                    
                    # ê·¸ë£¹ ì „ì²´ í•©ì„± (CompositeVideoClip í•˜ë‚˜ë¡œ)
                    group_clip = CompositeVideoClip([bg_clip, black_top, title_clip] + text_clips, size=(self.video_width, self.video_height))
                    group_clips.append(group_clip)
                    print(f"    âœ… ê·¸ë£¹ {group_idx//2 + 1} ì™„ë£Œ: ë°°ê²½ ì—°ì† ë³´ì¥")
                    
                    # ì˜¤ë””ì˜¤ ì¶”ê°€
                    for _, _, tts_path, _ in group_tts_info:
                        if tts_path:
                            audio_segments.append(AudioFileClip(tts_path))
            
            # ê·¸ë£¹ë“¤ ì—°ê²°
            final_video = concatenate_videoclips(group_clips, method="compose")
            
            # 8. TTS ì˜¤ë””ì˜¤ë“¤ ì—°ê²°
            if audio_segments:
                final_audio = concatenate_audioclips(audio_segments)
                
                # 9. ë°°ê²½ìŒì•… ì¶”ê°€
                if music_path and os.path.exists(music_path):
                    background_music = AudioFileClip(music_path)
                    background_music = background_music.volumex(0.25)  # ë³¼ë¥¨ 25%
                    
                    # ë°°ê²½ìŒì•…ì´ ì˜ìƒë³´ë‹¤ ì§§ìœ¼ë©´ ë°˜ë³µ, ê¸¸ë©´ ìë¥´ê¸°
                    if background_music.duration < final_audio.duration:
                        background_music = background_music.loop(duration=final_audio.duration)
                    else:
                        background_music = background_music.subclip(0, final_audio.duration)
                    
                    # TTSì™€ ë°°ê²½ìŒì•… í•©ì„±
                    final_audio = CompositeAudioClip([final_audio, background_music])
                
                final_video = final_video.set_audio(final_audio)
                print("TTS ì˜¤ë””ì˜¤ì™€ ë°°ê²½ìŒì•… í•©ì„± ì™„ë£Œ")
            
            # 10. ìµœì¢… ì˜ìƒ ì €ì¥
            video_id = str(uuid.uuid4())[:8]
            output_filename = f"reels_{video_id}.mp4"
            output_path = os.path.join(output_folder, output_filename)
            
            print(f"ìµœì¢… ì˜ìƒ ë Œë”ë§ ì‹œì‘: {output_path}")
            final_video.write_videofile(
                output_path,
                fps=self.fps,
                codec='libx264',
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True
            )
            
            print(f"ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_path}")
            return output_path
            
        except Exception as e:
            raise Exception(f"ë¡œì»¬ ì´ë¯¸ì§€ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def create_video(self, content, image_urls, music_path, output_folder, image_allocation_mode="2_per_image"):
        """ë¦´ìŠ¤ ì˜ìƒ ìƒì„± (414x896 í•´ìƒë„, ì—¬ëŸ¬ ì´ë¯¸ì§€ ì§€ì›)"""
        try:
            # ì—¬ëŸ¬ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            image_paths = []
            for i, image_url in enumerate(image_urls):
                print(f"ì´ë¯¸ì§€ {i+1}/{len(image_urls)} ë‹¤ìš´ë¡œë“œ ì¤‘: {image_url}")
                image_path = self.download_image(image_url)
                image_paths.append(image_path)
            
            # ì œëª© ì´ë¯¸ì§€ ìƒì„± (414x180, ë” ë„“ì€ ì˜ì—­)
            title_image_path = self.create_title_image(
                content['title'], 
                self.video_width, 
                180
            )
            
            # ê° bodyë³„ë¡œ ê°œë³„ TTS ìƒì„± (ë¹ˆ ê°’ ì œì™¸)
            body_keys = [key for key in content.keys() if key.startswith('body') and content[key].strip()]
            tts_files = []
            
            # ì œëª© TTS ìƒì„±
            print("ì œëª© TTS ìƒì„± ì¤‘...")
            title_tts = self.create_tts_audio(content['title'])
            if title_tts:
                title_duration = self.get_audio_duration(title_tts)
                tts_files.append(('title', title_tts, title_duration))
                print(f"ì œëª© TTS ì™„ë£Œ: {title_duration:.1f}ì´ˆ")
            
            # ê° body TTS ìƒì„±
            for body_key in body_keys:
                print(f"{body_key} TTS ìƒì„± ì¤‘...")
                body_tts = self.create_tts_audio(content[body_key])
                if body_tts:
                    body_duration = self.get_audio_duration(body_tts)
                    tts_files.append((body_key, body_tts, body_duration))
                    print(f"{body_key} TTS ì™„ë£Œ: {body_duration:.1f}ì´ˆ")
            
            # ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
            print(f"ğŸ¬ ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ: {image_allocation_mode}")
            body_clips = []
            audio_segments = []  # TTS ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë“¤
            
            if image_allocation_mode == "1_per_image":
                # Mode 2: body 1ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (1:1 ë§¤ì¹­)
                print("ğŸ–¼ï¸ 1:1 ë§¤ì¹­ ëª¨ë“œ: bodyë³„ë¡œ ê°ê° ë‹¤ë¥¸ ì´ë¯¸ì§€ ì‚¬ìš©")
                
                for i, body_key in enumerate(body_keys):
                    # í•´ë‹¹ bodyì˜ TTS ì •ë³´ ì°¾ê¸°
                    body_tts_info = None
                    for tts_key, tts_path, tts_duration in tts_files:
                        if tts_key == body_key:
                            body_tts_info = (tts_path, tts_duration)
                            break
                    
                    if not body_tts_info:
                        print(f"{body_key}ì˜ TTSë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œê°„ ì‚¬ìš©.")
                        clip_duration = 3.0
                        tts_path = None
                    else:
                        tts_path, clip_duration = body_tts_info
                    
                    # bodyë³„ë¡œ ê°œë³„ ì´ë¯¸ì§€ í• ë‹¹ (ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ì‚¬ìš©)
                    image_index = min(i, len(image_paths) - 1)  # body1 â†’ image0, body2 â†’ image1, body3 â†’ image2
                    current_image_path = image_paths[image_index]
                    
                    print(f"{body_key} í´ë¦½ ìƒì„±: {clip_duration:.1f}ì´ˆ, ì´ë¯¸ì§€: {image_index + 1}/{len(image_paths)} (1:1 ë§¤ì¹­)")
                    
                    # ê°œë³„ body í´ë¦½ ìƒì„±
                    bg_clip = self.create_background_clip(current_image_path, clip_duration)
                    black_top = ColorClip(size=(self.video_width, 180), color=(0,0,0)).set_duration(clip_duration).set_position((0, 0))
                    title_clip = ImageClip(title_image_path).set_duration(clip_duration).set_position((0, 0))
                    
                    text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height - 180, text_position)
                    text_clip = ImageClip(text_image_path).set_duration(clip_duration).set_position((0, 180))
                    
                    # ê°œë³„ í´ë¦½ í•©ì„±
                    combined_clip = CompositeVideoClip([bg_clip, black_top, title_clip, text_clip], size=(self.video_width, self.video_height))
                    body_clips.append(combined_clip)
                    
                    # ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
                    if tts_path and os.path.exists(tts_path):
                        body_audio = AudioFileClip(tts_path)
                        audio_segments.append(body_audio)
                        print(f"{body_key} ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€")
                        
            else:  # image_allocation_mode == "2_per_image"
                # Mode 1: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (ê·¸ë£¹ ë°©ì‹)
                print("ğŸ–¼ï¸ 2:1 ë§¤ì¹­ ëª¨ë“œ: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ ì‚¬ìš©")
                
                for i, body_key in enumerate(body_keys):
                    # í•´ë‹¹ bodyì˜ TTS ì •ë³´ ì°¾ê¸°
                    body_tts_info = None
                    for tts_key, tts_path, tts_duration in tts_files:
                        if tts_key == body_key:
                            body_tts_info = (tts_path, tts_duration)
                            break
                    
                    if not body_tts_info:
                        print(f"{body_key}ì˜ TTSë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œê°„ ì‚¬ìš©.")
                        clip_duration = 3.0
                        tts_path = None
                    else:
                        tts_path, clip_duration = body_tts_info
                    
                    # body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ í• ë‹¹ (body1,2 â†’ image0, body3,4 â†’ image1)
                    image_index = min(i // 2, len(image_paths) - 1)
                    current_image_path = image_paths[image_index]
                    
                    print(f"{body_key} í´ë¦½ ìƒì„±: {clip_duration:.1f}ì´ˆ, ì´ë¯¸ì§€: {image_index + 1}/{len(image_paths)} (2:1 ë§¤ì¹­)")
                    
                    # ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ í´ë¦½ ìƒì„±
                    bg_clip = self.create_background_clip(current_image_path, clip_duration)
                    black_top = ColorClip(size=(self.video_width, 180), color=(0,0,0)).set_duration(clip_duration).set_position((0, 0))
                    title_clip = ImageClip(title_image_path).set_duration(clip_duration).set_position((0, 0))
                    
                    text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height - 180, text_position)
                    text_clip = ImageClip(text_image_path).set_duration(clip_duration).set_position((0, 180))
                    
                    # í´ë¦½ í•©ì„±
                    combined_clip = CompositeVideoClip([bg_clip, black_top, title_clip, text_clip], size=(self.video_width, self.video_height))
                    body_clips.append(combined_clip)
                    
                    # ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
                    if tts_path and os.path.exists(tts_path):
                        body_audio = AudioFileClip(tts_path)
                        audio_segments.append(body_audio)
                        print(f"{body_key} ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€")
            
            # ì „ì²´ ì˜ìƒ í•©ì¹˜ê¸°
            final_video = concatenate_videoclips(body_clips)
            print(f"ìµœì¢… ë¹„ë””ì˜¤ ê¸¸ì´: {final_video.duration:.1f}ì´ˆ")
            
            # TTS ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì—°ê²°
            if audio_segments:
                print(f"TTS ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ê°œìˆ˜: {len(audio_segments)}")
                combined_tts = concatenate_audioclips(audio_segments)
                print(f"ê²°í•©ëœ TTS ê¸¸ì´: {combined_tts.duration:.1f}ì´ˆ")
                
                # ë°°ê²½ìŒì•… ì¶”ê°€
                audio_tracks = [combined_tts]
                
                if os.path.exists(music_path):
                    print("ë°°ê²½ìŒì•… ì¶”ê°€ ì¤‘...")
                    # ë°°ê²½ìŒì•… (ë³¼ë¥¨ì„ 20%ë¡œ ë‚®ì¶¤ - TTSê°€ ë” ì˜ ë“¤ë¦¬ë„ë¡)
                    bg_music = AudioFileClip(music_path).volumex(0.2)
                    if bg_music.duration < combined_tts.duration:
                        bg_music = bg_music.loop(duration=combined_tts.duration)
                    else:
                        bg_music = bg_music.subclip(0, combined_tts.duration)
                    audio_tracks.append(bg_music)
                
                # ì˜¤ë””ì˜¤ í•©ì„±
                if len(audio_tracks) > 1:
                    print("TTS + ë°°ê²½ìŒì•… í•©ì„± ì¤‘...")
                    final_audio = CompositeAudioClip(audio_tracks)
                else:
                    print("TTSë§Œ ì‚¬ìš©")
                    final_audio = audio_tracks[0]
                
                final_video = final_video.set_audio(final_audio)
                print("ìµœì¢… ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ ì¶”ê°€ ì™„ë£Œ")
                
            else:
                print("TTS ì˜¤ë””ì˜¤ê°€ ì—†ì–´ì„œ ë°°ê²½ìŒì•…ë§Œ ì‚¬ìš©")
                if os.path.exists(music_path):
                    bg_music = AudioFileClip(music_path)
                    if bg_music.duration > final_video.duration:
                        bg_music = bg_music.subclip(0, final_video.duration)
                    final_video = final_video.set_audio(bg_music)
            
            # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ìƒì„±
            output_filename = f"reels_{uuid.uuid4().hex[:8]}.mp4"
            output_path = os.path.join(output_folder, output_filename)
            
            # ì˜ìƒ ë Œë”ë§ (ì´ë¯¸ 414x896ìœ¼ë¡œ êµ¬ì„±ë¨)
            final_video.write_videofile(
                output_path,
                fps=self.fps,
                codec='libx264',
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True
            )
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(image_path):
                os.unlink(image_path)
            if os.path.exists(title_image_path):
                os.unlink(title_image_path)
            
            # ëª¨ë“  TTS íŒŒì¼ ì •ë¦¬
            for tts_key, tts_path, tts_duration in tts_files:
                if os.path.exists(tts_path):
                    os.unlink(tts_path)
                    print(f"{tts_key} TTS íŒŒì¼ ì •ë¦¬: {tts_path}")
            
            return output_path
            
        except Exception as e:
            raise Exception(f"Video generation failed: {str(e)}")
    
    def scan_uploads_folder(self, uploads_folder="uploads"):
        """uploads í´ë”ë¥¼ ìŠ¤ìº”í•˜ì—¬ íŒŒì¼ë“¤ì„ ì°¾ê³  ë¶„ë¥˜"""
        scan_result = {
            'json_file': None,
            'image_files': [],  # í˜¸í™˜ì„± ìœ ì§€
            'media_files': []   # ìƒˆë¡œìš´ ë¯¸ë””ì–´ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
        }
        
        if not os.path.exists(uploads_folder):
            print(f"âŒ {uploads_folder} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return scan_result
        
        # JSON íŒŒì¼ ì°¾ê¸° (text.json)
        json_path = os.path.join(uploads_folder, "text.json")
        if os.path.exists(json_path):
            scan_result['json_file'] = json_path
            print(f"âœ… JSON íŒŒì¼ ë°œê²¬: {json_path}")
        
        # ìŒì•… íŒŒì¼ì€ ë” ì´ìƒ uploadsì—ì„œ ì°¾ì§€ ì•ŠìŒ (bgm í´ë” ì§ì ‘ ì‚¬ìš©)
        
        # ë¯¸ë””ì–´ íŒŒì¼ë“¤ ì°¾ê¸° (ì´ë¯¸ì§€ + ë¹„ë””ì˜¤)
        image_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.webp', '.bmp']
        video_extensions = ['.mp4', '.mov', '.avi', '.webm']
        all_extensions = image_extensions + video_extensions
        
        # ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ë¯¸ë””ì–´ íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ì •ë ¬
        media_files = []
        image_files = []  # í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
        
        for filename in os.listdir(uploads_folder):
            if any(filename.lower().endswith(ext) for ext in all_extensions):
                # íŒŒì¼ëª…ì´ ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
                name_without_ext = os.path.splitext(filename)[0]
                if name_without_ext.isdigit():
                    file_number = int(name_without_ext)
                    full_path = os.path.join(uploads_folder, filename)
                    
                    # íŒŒì¼ íƒ€ì… ê²°ì •
                    is_video = any(filename.lower().endswith(ext) for ext in video_extensions)
                    file_type = "video" if is_video else "image"
                    
                    media_files.append((file_number, full_path, file_type))
                    
                    # í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ image_filesì—ë„ ì¶”ê°€
                    image_files.append((file_number, full_path))
        
        # ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬
        media_files.sort(key=lambda x: x[0])
        image_files.sort(key=lambda x: x[0])
        
        # ê²°ê³¼ ì €ì¥
        scan_result['media_files'] = [(path, file_type) for _, path, file_type in media_files]
        scan_result['image_files'] = [path for _, path in image_files]  # í˜¸í™˜ì„± ìœ ì§€
        
        print(f"ğŸ“Š ë¯¸ë””ì–´ íŒŒì¼ {len(scan_result['media_files'])}ê°œ ë°œê²¬:")
        for i, (media_path, file_type) in enumerate(scan_result['media_files'], 1):
            print(f"   {i}. {os.path.basename(media_path)} ({file_type})")
        
        return scan_result
    
    def create_video_from_uploads(self, output_folder, bgm_file_path=None, image_allocation_mode="2_per_image", text_position="bottom", uploads_folder="uploads"):
        """uploads í´ë”ì˜ íŒŒì¼ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ìƒì„± (ê¸°ì¡´ ë©”ì„œë“œ ì¬ì‚¬ìš©)"""
        try:
            print("ğŸš€ uploads í´ë” ê¸°ë°˜ ì˜ìƒ ìƒì„± ì‹œì‘")
            
            # uploads í´ë” ìŠ¤ìº”
            scan_result = self.scan_uploads_folder(uploads_folder)
            
            # í•„ìˆ˜ íŒŒì¼ ê²€ì¦
            if not scan_result['json_file']:
                raise Exception("text.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            
            if not scan_result['image_files']:
                raise Exception("ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            
            # JSON ë‚´ìš© ë¡œë“œ
            with open(scan_result['json_file'], 'r', encoding='utf-8') as f:
                content = json.load(f)
            print(f"âœ… JSON ë‚´ìš© ë¡œë“œ: {scan_result['json_file']}")
            
            # ìŒì•… íŒŒì¼ ì„¤ì • (bgm_file_path ì§ì ‘ ì‚¬ìš©)
            music_path = bgm_file_path or ""
            if music_path and os.path.exists(music_path):
                print(f"âœ… ìŒì•… íŒŒì¼ ì‚¬ìš©: {music_path}")
            else:
                print("âš ï¸  ìŒì•… íŒŒì¼ ì—†ìŒ - ìŒì„±ë§Œ ì‚¬ìš©")
                music_path = ""
            
            # ê¸°ì¡´ create_video_with_local_images ë°©ì‹ ì¬ì‚¬ìš©
            # ìŠ¤ìº”ëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ë¡œ ë¡œì»¬ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ëŒ€ì²´
            self._temp_local_images = scan_result['image_files']
            
            # ê¸°ì¡´ ë©”ì„œë“œ í˜¸ì¶œ (ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ, í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì „ë‹¬)
            return self.create_video_with_local_images(content, music_path, output_folder, image_allocation_mode, text_position)
            
        except Exception as e:
            raise Exception(f"uploads í´ë” ê¸°ë°˜ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def get_local_images(self, test_folder="./test"):
        """test í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì´ë¦„ìˆœìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        # uploads í´ë” ì‚¬ìš© ì‹œ ì„ì‹œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
        if hasattr(self, '_temp_local_images') and self._temp_local_images:
            images = self._temp_local_images
            self._temp_local_images = None  # ì‚¬ìš© í›„ ì •ë¦¬
            print(f"ì—…ë¡œë“œ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {len(images)}ê°œ (ìˆœì„œëŒ€ë¡œ)")
            for i, file in enumerate(images):
                print(f"  {i+1}. {os.path.basename(file)}")
            return images
        
        # ê¸°ì¡´ test í´ë” ë¡œì§
        import glob
        
        # ì´ë¯¸ì§€ í™•ì¥ì íŒ¨í„´ (webp ì¶”ê°€)
        image_patterns = ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.gif", "*.webp"]
        image_files = []
        
        for pattern in image_patterns:
            files = glob.glob(os.path.join(test_folder, pattern))
            files.extend(glob.glob(os.path.join(test_folder, pattern.upper())))
            image_files.extend(files)
        
        # ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬ (1.png, 2.png, 3.png, 4.png)
        import re
        def natural_sort_key(path):
            filename = os.path.basename(path).lower()
            # ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
            numbers = re.findall(r'\d+', filename)
            if numbers:
                return int(numbers[0])  # ì²« ë²ˆì§¸ ìˆ«ìë¡œ ì •ë ¬
            else:
                return float('inf')  # ìˆ«ìê°€ ì—†ìœ¼ë©´ ë§¨ ë’¤ë¡œ
        
        image_files.sort(key=natural_sort_key)
        
        print(f"ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {len(image_files)}ê°œ (ìˆ«ì ìˆœì„œëŒ€ë¡œ)")
        for i, file in enumerate(image_files):
            print(f"  {i+1}. {os.path.basename(file)}")
        
        if len(image_files) == 0:
            print("âŒ test í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            print(f"âœ… ì´ë¯¸ì§€ ì‚¬ìš© ìˆœì„œ: {' â†’ '.join([os.path.basename(f) for f in image_files])}")
        
        return image_files