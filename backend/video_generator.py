import os
import requests
from PIL import Image, ImageDraw, ImageFont
from moviepy.editor import *
import numpy as np
import uuid
import tempfile
from gtts import gTTS
import re
import base64
import json
import random
import math
import logging
from datetime import datetime

# ë¡œê¹… ì„¤ì • - íŒŒì¼ì—ë§Œ ì €ì¥
def setup_crossfade_logging():
    """í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì „ìš© ë¡œê¹… ì„¤ì •"""
    log_filename = f"crossfade_debug_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler(log_filename, encoding='utf-8'),
            logging.StreamHandler()  # ì½˜ì†”ì—ë„ ì¶œë ¥
        ]
    )

    print(f"ğŸ” í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ë””ë²„ê¹… ë¡œê·¸ íŒŒì¼: {log_filename}")
    return log_filename

# ì „ì—­ ë¡œê·¸ íŒŒì¼ëª… ì €ì¥
CROSSFADE_LOG_FILE = None

class VideoGenerator:
    def __init__(self):
        # ë¡œê¹… ì´ˆê¸°í™”
        global CROSSFADE_LOG_FILE
        if CROSSFADE_LOG_FILE is None:
            CROSSFADE_LOG_FILE = setup_crossfade_logging()

        self.video_width = 504
        self.video_height = 890  # ì‡¼ì¸ /ë¦´ìŠ¤ í•´ìƒë„ (504x890)
        self.fps = 30
        self.font_path = os.path.join(os.path.dirname(__file__), "font", "BMYEONSUNG_otf.otf")
        
        # Naver Clova Voice ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        self.naver_client_id = os.getenv('NAVER_CLIENT_ID')
        self.naver_client_secret = os.getenv('NAVER_CLIENT_SECRET')
        
        # Microsoft Azure Speech ì„¤ì •
        self.azure_speech_key = os.getenv('AZURE_SPEECH_KEY')
        self.azure_speech_region = os.getenv('AZURE_SPEECH_REGION', 'koreacentral')
        
    def get_emoji_font(self):
        """ì´ëª¨ì§€ ì§€ì› í°íŠ¸ ê²½ë¡œ ë°˜í™˜"""
        emoji_fonts = [
            "/usr/share/fonts/truetype/noto/NotoColorEmoji.ttf",
            "/System/Library/Fonts/Apple Color Emoji.ttc",
            "/Windows/Fonts/seguiemj.ttf",
            "/usr/share/fonts/truetype/noto/NotoEmoji-Regular.ttf"
        ]
        
        for font_path in emoji_fonts:
            if os.path.exists(font_path):
                return font_path
        return None
    
    def has_emoji(self, text):
        """í…ìŠ¤íŠ¸ì— ì´ëª¨ì§€ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
        emoji_pattern = re.compile(
            "[\U0001F600-\U0001F64F"  # ê°ì • í‘œí˜„
            "\U0001F300-\U0001F5FF"  # ê¸°í˜¸ ë° ê·¸ë¦¼ë¬¸ì
            "\U0001F680-\U0001F6FF"  # êµí†µ ë° ì§€ë„ ê¸°í˜¸
            "\U0001F1E0-\U0001F1FF"  # êµ­ê¸°
            "\U00002600-\U000026FF"  # ê¸°íƒ€ ê¸°í˜¸
            "\U00002700-\U000027BF"  # ì¥ì‹ ê¸°í˜¸
            "\U0001F900-\U0001F9FF"  # ì¶”ê°€ ê·¸ë¦¼ë¬¸ì
            "\U0001FA70-\U0001FAFF"  # í™•ì¥ëœ ê·¸ë¦¼ë¬¸ì-A
            "]+", re.UNICODE)
        return emoji_pattern.search(text) is not None
    
    def split_text_and_emoji(self, text):
        """í…ìŠ¤íŠ¸ì™€ ì´ëª¨ì§€ë¥¼ ë¶„ë¦¬"""
        emoji_pattern = re.compile(
            "[\U0001F600-\U0001F64F"
            "\U0001F300-\U0001F5FF"
            "\U0001F680-\U0001F6FF"
            "\U0001F1E0-\U0001F1FF"
            "\U00002600-\U000026FF"
            "\U00002700-\U000027BF"
            "\U0001F900-\U0001F9FF"
            "\U0001FA70-\U0001FAFF"
            "]", re.UNICODE)
        
        parts = []
        last_end = 0
        
        for match in emoji_pattern.finditer(text):
            if match.start() > last_end:
                parts.append(('text', text[last_end:match.start()]))
            parts.append(('emoji', match.group()))
            last_end = match.end()
        
        if last_end < len(text):
            parts.append(('text', text[last_end:]))
        
        return parts
    
    def draw_text_with_emoji(self, draw, text, x, y, text_font, emoji_font, color):
        """í…ìŠ¤íŠ¸ì™€ ì´ëª¨ì§€ë¥¼ í•¨ê»˜ ë Œë”ë§"""
        parts = self.split_text_and_emoji(text)
        current_x = x
        
        for part_type, content in parts:
            if part_type == 'text' and content.strip():
                draw.text((current_x, y), content, font=text_font, fill=color)
                bbox = draw.textbbox((0, 0), content, font=text_font)
                current_x += bbox[2] - bbox[0]
            elif part_type == 'emoji':
                # ì´ëª¨ì§€ í°íŠ¸ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ë¡œ ì‹œë„
                if emoji_font:
                    try:
                        draw.text((current_x, y + 2), content, font=emoji_font, fill=color)
                        bbox = draw.textbbox((0, 0), content, font=emoji_font)
                    except:
                        # ì´ëª¨ì§€ í°íŠ¸ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ í°íŠ¸ë¡œ ì‹œë„
                        draw.text((current_x, y), content, font=text_font, fill=color)
                        bbox = draw.textbbox((0, 0), content, font=text_font)
                else:
                    # ì´ëª¨ì§€ í°íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ í°íŠ¸ë¡œ ì‹œë„
                    draw.text((current_x, y), content, font=text_font, fill=color)
                    bbox = draw.textbbox((0, 0), content, font=text_font)
                
                current_x += bbox[2] - bbox[0]
        
    def create_fallback_image(self, width=1920, height=1080, color_index=0):
        """ì¸í„°ë„· ì—°ê²° ì—†ì´ ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„±"""
        try:
            # ë‹¤ì–‘í•œ ìƒ‰ìƒ íŒ”ë ˆíŠ¸
            colors = [
                (255, 87, 51),   # ì£¼í™©ìƒ‰
                (51, 255, 87),   # ì´ˆë¡ìƒ‰  
                (51, 87, 255),   # íŒŒë€ìƒ‰
                (255, 51, 245),  # ìì£¼ìƒ‰
                (255, 195, 0),   # ë…¸ë€ìƒ‰
                (0, 195, 255),   # í•˜ëŠ˜ìƒ‰
            ]
            
            color = colors[color_index % len(colors)]
            
            # ì´ë¯¸ì§€ ìƒì„±
            img = Image.new('RGB', (width, height), color=color)
            draw = ImageDraw.Draw(img)
            
            # í…ìŠ¤íŠ¸ ì¶”ê°€
            try:
                font = ImageFont.truetype(self.font_path, 60)
            except:
                font = ImageFont.load_default()
            
            text = f"ë°°ê²½ ì´ë¯¸ì§€ {color_index + 1}"
            bbox = draw.textbbox((0, 0), text, font=font)
            text_width = bbox[2] - bbox[0]
            text_height = bbox[3] - bbox[1]
            
            x = (width - text_width) // 2
            y = (height - text_height) // 2
            
            # í…ìŠ¤íŠ¸ ê·¸ë¦¼ì
            draw.text((x + 2, y + 2), text, font=font, fill=(0, 0, 0))
            # í°ìƒ‰ í…ìŠ¤íŠ¸
            draw.text((x, y), text, font=font, fill=(255, 255, 255))
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
            img.save(temp_file.name, "JPEG", quality=85)
            temp_file.close()
            
            print(f"ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {temp_file.name}")
            return temp_file.name
            
        except Exception as e:
            print(f"ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def download_image(self, image_url):
        """ì´ë¯¸ì§€ URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ (fallback í¬í•¨)"""
        try:
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹œë„: {image_url}")
            
            # íƒ€ì„ì•„ì›ƒê³¼ í—¤ë” ì¶”ê°€
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            response = requests.get(image_url, headers=headers, timeout=10)  # íƒ€ì„ì•„ì›ƒ ë‹¨ì¶•
            
            print(f"ì‘ë‹µ ìƒíƒœ: {response.status_code}")
            response.raise_for_status()
            
            # ì´ë¯¸ì§€ ì½˜í…ì¸  ìœ íš¨ì„± ê²€ì‚¬
            if len(response.content) < 1000:
                raise Exception(f"ì´ë¯¸ì§€ íŒŒì¼ì´ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤: {len(response.content)} bytes")
            
            # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
            temp_file.write(response.content)
            temp_file.close()
            
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {temp_file.name} ({len(response.content)} bytes)")
            return temp_file.name
            
        except Exception as e:
            print(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({str(e)}), ê¸°ë³¸ ì´ë¯¸ì§€ë¡œ ëŒ€ì²´")
            # URLì—ì„œ ìƒ‰ìƒ ì¸ë±ìŠ¤ ì¶”ì¶œ ì‹œë„
            color_index = 0
            try:
                if "Image+1" in image_url or "random=1" in image_url:
                    color_index = 0
                elif "Image+2" in image_url or "random=2" in image_url:
                    color_index = 1
                elif "Image+3" in image_url or "random=3" in image_url:
                    color_index = 2
                elif "Image+4" in image_url or "random=4" in image_url:
                    color_index = 3
            except:
                pass
                
            fallback_image = self.create_fallback_image(1920, 1080, color_index)
            if fallback_image:
                return fallback_image
            else:
                raise Exception(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ê¸°ë³¸ ì´ë¯¸ì§€ ìƒì„± ëª¨ë‘ ì‹¤íŒ¨: {str(e)}")
    
    def create_title_image(self, title, width, height, title_font="BMYEONSUNG_otf.otf"):
        """ì œëª© ì´ë¯¸ì§€ ìƒì„± - ì§€ì • ì˜ì—­(50,65)~(444,200)ì— ì•„ë˜ ì •ë ¬"""
        # ê²€ì€ ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± (ì „ì²´ íƒ€ì´í‹€ ì˜ì—­)
        img = Image.new('RGB', (width, height), color='black')
        draw = ImageDraw.Draw(img)

        # íƒ€ì´í‹€ í…ìŠ¤íŠ¸ ì˜ì—­ ì •ì˜: (50, 65) ~ (444, 200)
        title_left = 50
        title_top = 65
        title_right = 444  # ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­: (50,65) ~ (444,200)
        title_bottom = 200  # í…ìŠ¤íŠ¸ ì˜ì—­ í•˜ë‹¨ì„ 200ìœ¼ë¡œ ì œí•œ (í•˜ë‹¨ 20px ì—¬ë°± í™•ë³´)
        title_width = title_right - title_left  # 394px (444-50)
        title_height = title_bottom - title_top  # 135px (200-65)

        # íƒ€ì´í‹€ í°íŠ¸ ì„¤ì •
        title_font_path = os.path.join(os.path.dirname(__file__), "font", title_font)
        try:
            font = ImageFont.truetype(title_font_path, 48)  # íƒ€ì´í‹€ìš© 48pt
            print(f"âœ… íƒ€ì´í‹€ í°íŠ¸ ë¡œë“œ ì„±ê³µ: {title_font} (48pt)")
        except Exception as e:
            print(f"âŒ íƒ€ì´í‹€ í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ({title_font}): {e}")
            # ê¸°ë³¸ í°íŠ¸ë¡œ fallback
            try:
                font = ImageFont.truetype(self.font_path, 48)
                print(f"âœ… ê¸°ë³¸ íƒ€ì´í‹€ í°íŠ¸ë¡œ fallback: {self.font_path}")
            except Exception as e2:
                print(f"âŒ ê¸°ë³¸ íƒ€ì´í‹€ í°íŠ¸ë„ ì‹¤íŒ¨: {e2}")
                try:
                    font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 48)
                except:
                    font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸° (íƒ€ì´í‹€ ì˜ì—­ í­ì— ë§ì¶°)
        words = title.split(' ')
        lines = []
        current_line = ""
        
        for word in words:
            test_line = current_line + " " + word if current_line else word
            bbox = draw.textbbox((0, 0), test_line, font=font)
            if bbox[2] - bbox[0] < title_width - 20:  # íƒ€ì´í‹€ ì˜ì—­ ë‚´ ì—¬ë°± 10pxì”©
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word
        
        if current_line:
            lines.append(current_line)
        
        # ì´ëª¨ì§€ í°íŠ¸ ì¤€ë¹„ (ì œëª© í°íŠ¸ í¬ê¸°ì— ë§ì¶¤)
        emoji_font_path = self.get_emoji_font()
        emoji_font = None
        if emoji_font_path:
            try:
                emoji_font = ImageFont.truetype(emoji_font_path, 44)  # 22 â†’ 44ë¡œ 2ë°° ì¦ê°€
            except:
                emoji_font = None
        
        # í…ìŠ¤íŠ¸ ì•„ë˜ ì •ë ¬ (íƒ€ì´í‹€ ì˜ì—­ í•˜ë‹¨ì—ì„œ ìœ„ë¡œ ë°°ì¹˜)
        line_height = 50  # 48px í°íŠ¸ì— ë§ì¶˜ ì ì • ì¤„ê°„ê²©
        total_text_height = len(lines) * line_height
        
        # ì•„ë˜ ì •ë ¬: íƒ€ì´í‹€ ì˜ì—­ í•˜ë‹¨ì—ì„œ í…ìŠ¤íŠ¸ ë†’ì´ë§Œí¼ ìœ„ë¡œ
        start_y = title_bottom - total_text_height - 5  # ì•ˆì „ ì—¬ë°± 5px
        
        print(f"ğŸ“ íƒ€ì´í‹€ ë°°ì¹˜: ì˜ì—­({title_left},{title_top})~({title_right},{title_bottom})")
        print(f"ğŸ“ í…ìŠ¤íŠ¸ ì‹œì‘: Y={start_y}, ì¤„ìˆ˜={len(lines)}, ì „ì²´ë†’ì´={total_text_height}px")
        
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            
            # X ì¢Œí‘œ: íƒ€ì´í‹€ ì˜ì—­ ë‚´ ì¤‘ì•™ ì •ë ¬
            x = title_left + (title_width - text_width) // 2
            y = start_y + i * line_height
            
            # íƒ€ì´í‹€ ì˜ì—­ ë²”ìœ„ ì²´í¬
            if y < title_top:
                y = title_top + 10  # ìµœì†Œ ìƒë‹¨ ì—¬ë°± í™•ë³´
            
            # í…ìŠ¤íŠ¸ì˜ ì‹¤ì œ ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚° (ë Œë”ë§ ì „ í™•ì¸)
            actual_bbox = draw.textbbox((x, y), line, font=font)
            text_bottom = actual_bbox[3]  # ì‹¤ì œ í…ìŠ¤íŠ¸ í•˜ë‹¨ ìœ„ì¹˜
            
            print(f"ğŸ“ ì¤„ {i+1}: '{line}' at ({x}, {y})")
            print(f"ğŸ“ ì‹¤ì œ í…ìŠ¤íŠ¸ ë°”ìš´ë”©ë°•ìŠ¤: {actual_bbox}")
            print(f"ğŸ“ í…ìŠ¤íŠ¸ í•˜ë‹¨ ìœ„ì¹˜: {text_bottom}, ì˜ì—­ í•˜ë‹¨: {title_bottom}")
            
            if text_bottom > title_bottom:
                print(f"âš ï¸  ê²½ê³ : í…ìŠ¤íŠ¸ê°€ ì˜ì—­ì„ {text_bottom - title_bottom}px ì´ˆê³¼!")
            
            # ì¼ë‹¨ ê¸°ë³¸ í°íŠ¸ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§ (ì´ëª¨ì§€ í¬í•¨)
            try:
                draw.text((x, y), line, font=font, fill='white')
            except Exception as e:
                print(f"í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
                # í´ë°±ìœ¼ë¡œ ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©
                default_font = ImageFont.load_default()
                draw.text((x, y), line, font=default_font, fill='white')
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
        img.save(temp_file.name, "PNG")
        temp_file.close()
        
        return temp_file.name
    
    def create_simple_group_clip(self, image_path, group_segments, total_duration, title_image_path=None, text_position="bottom", text_style="outline", title_font="BMYEONSUNG_otf.otf", body_font="BMYEONSUNG_otf.otf"):
        """ê°„ë‹¨í•œ ê·¸ë£¹ í´ë¦½ ìƒì„± (uploads í´ë”ìš©)"""
        print(f"    ğŸ”§ ê°„ë‹¨í•œ ê·¸ë£¹ í´ë¦½ ìƒì„±: {total_duration:.1f}ì´ˆ")
        
        # 1. ì—°ì† ë°°ê²½ ì´ë¯¸ì§€ (ì „ì²´ ê·¸ë£¹ ì‹œê°„ë™ì•ˆ)
        bg_clip = self.create_continuous_background_clip(image_path, total_duration)
        
        # 2. ìƒë‹¨ ê²€ì€ ì˜ì—­ (ì „ì²´ ì‹œê°„)
        black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0))
        black_top = black_top.set_duration(total_duration).set_position((0, 0))
        
        # 3. ì œëª© í´ë¦½ ì„¤ì •
        if title_image_path and os.path.exists(title_image_path):
            title_clip = ImageClip(title_image_path).set_duration(total_duration).set_position((0, 0))
        else:
            title_clip = None
        
        # 4. ê° í…ìŠ¤íŠ¸ë¥¼ ì‹œê°„ë³„ë¡œ ë°°ì¹˜
        text_clips = []
        current_time = 0.0

        for body_key, body_text, tts_path, clip_duration in group_segments:
            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font)
            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(clip_duration).set_position((0, 0))
            text_clips.append(text_clip)
            current_time += clip_duration
        
        # 5. í•©ì„±
        composition_clips = [bg_clip, black_top]
        if title_clip:
            composition_clips.append(title_clip)
        composition_clips.extend(text_clips)
        
        group_final = CompositeVideoClip(composition_clips, size=(self.video_width, self.video_height))
        
        return group_final

    def create_truly_continuous_group_clip(self, image_path, group_segments, total_duration, title_image_path, text_position="bottom", text_style="outline", title_font="BMYEONSUNG_otf.otf", body_font="BMYEONSUNG_otf.otf"):
        """ê·¸ë£¹ ë‚´ì—ì„œ ì •ë§ ëŠê¸°ì§€ ì•ŠëŠ” ì—°ì† í´ë¦½ ìƒì„±"""
        print(f"    ğŸ”§ ì—°ì† ê·¸ë£¹ í´ë¦½ ìƒì„±: {total_duration:.1f}ì´ˆ")
        
        # 1. ì—°ì† ë°°ê²½ ì´ë¯¸ì§€ (ì „ì²´ ê·¸ë£¹ ì‹œê°„ë™ì•ˆ - ëŠê¸°ì§€ ì•ŠìŒ!)
        bg_clip = self.create_continuous_background_clip(image_path, total_duration)
        
        # 2. ìƒë‹¨ ê²€ì€ ì˜ì—­ (ì „ì²´ ì‹œê°„)
        black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0))
        black_top = black_top.set_duration(total_duration).set_position((0, 0))
        
        # 3. ì œëª© (ì „ì²´ ì‹œê°„)
        title_clip = ImageClip(title_image_path).set_duration(total_duration).set_position((0, 0))
        
        # 4. ê°„ë‹¨í•œ ë°©ë²•: ê° í…ìŠ¤íŠ¸ë¥¼ ì‹œê°„ë³„ë¡œ ë°°ì¹˜
        text_clips = []
        current_time = 0.0

        for body_key, body_text, tts_path, clip_duration in group_segments:
            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font)
            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(clip_duration).set_position((0, 0))
            text_clips.append(text_clip)
            current_time += clip_duration
        
        # 5. í•©ì„± (ë°°ê²½ì€ ì—°ì†, í…ìŠ¤íŠ¸ë§Œ ì‹œê°„ë³„ë¡œ)
        group_final = CompositeVideoClip([
            bg_clip,     # ì—°ì† ë°°ê²½
            black_top,   # ìƒë‹¨
            title_clip,  # ì œëª©
        ] + text_clips, size=(self.video_width, self.video_height))
        
        return group_final
    
    def create_text_image(self, text, width, height, text_position="bottom", text_style="outline", is_title=False, title_font="BMYEONSUNG_otf.otf", body_font="BMYEONSUNG_otf.otf"):
        """í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± (ë°°ê²½ ë°•ìŠ¤ í¬í•¨)"""
        # íˆ¬ëª… ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
        img = Image.new('RGBA', (width, height), color=(0, 0, 0, 0))
        draw = ImageDraw.Draw(img)

        # í°íŠ¸ ì„ íƒ (íƒ€ì´í‹€/ë°”ë”” êµ¬ë¶„)
        selected_font = title_font if is_title else body_font
        font_path = os.path.join(os.path.dirname(__file__), "font", selected_font)

        # í°íŠ¸ í¬ê¸° ì„¤ì • (íƒ€ì´í‹€ì€ ë” í¬ê²Œ, white_backgroundëŠ” 2pt ì‘ê²Œ)
        if text_style == "white_background":
            font_size = 40 if is_title else 34  # 2í¬ì¸íŠ¸ ì‘ê²Œ
        else:
            font_size = 42 if is_title else 36  # ê¸°ë³¸ í¬ê¸°

        # í•œê¸€ í°íŠ¸ ì„¤ì •
        try:
            font = ImageFont.truetype(font_path, font_size)
            print(f"âœ… í°íŠ¸ ë¡œë“œ ì„±ê³µ: {selected_font} ({font_size}pt)")
        except Exception as e:
            print(f"âŒ ì‚¬ìš©ì í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ({selected_font}): {e}")
            # ê¸°ë³¸ í°íŠ¸ë¡œ fallback
            try:
                font = ImageFont.truetype(self.font_path, font_size)
                print(f"âœ… ê¸°ë³¸ í°íŠ¸ë¡œ fallback: {self.font_path}")
            except Exception as e2:
                print(f"âŒ ê¸°ë³¸ í°íŠ¸ë„ ì‹¤íŒ¨: {e2}")
                try:
                    font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", font_size)
                except:
                    font = ImageFont.load_default()
        
        # í…ìŠ¤íŠ¸ë¥¼ ì—¬ëŸ¬ ì¤„ë¡œ ë‚˜ëˆ„ê¸°
        words = text.split(' ')
        lines = []
        current_line = ""
        
        for word in words:
            test_line = current_line + " " + word if current_line else word
            bbox = draw.textbbox((0, 0), test_line, font=font)
            if bbox[2] - bbox[0] < width - 60:  # ì—¬ë°± ê³ ë ¤ (ì¢Œìš° 30ì”©)
                current_line = test_line
            else:
                if current_line:
                    lines.append(current_line)
                current_line = word
        
        if current_line:
            lines.append(current_line)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ ë°•ìŠ¤ í¬ê¸° ê³„ì‚° (í°íŠ¸ í¬ê¸°ì— ë§ì¶˜ ì¤„ê°„ê²©)
        line_height = 40  # 36pt í°íŠ¸ì— ë§ì¶˜ ì ì • ì¤„ê°„ê²©
        total_height = len(lines) * line_height
        padding = 20  # íŒ¨ë”© ì¡°ì •
        
        # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚° (ìƒˆë¡œìš´ ì˜ì—­ êµ¬ì„±)
        # ì „ì²´ í•´ìƒë„: 504x890, íƒ€ì´í‹€ ì˜ì—­: 220px
        # ìƒë‹¨ í…ìŠ¤íŠ¸ ì˜ì—­: 340-520 (ì¤‘ì•™: 430px)
        # í•˜ë‹¨ í…ìŠ¤íŠ¸ ì˜ì—­: 520-700 (ì¤‘ì•™: 610px)
        
        title_height = 220  # íƒ€ì´í‹€ ì˜ì—­ ë†’ì´ (ê³ ì •)
        
        if text_position == "top":
            # ìƒë‹¨ í…ìŠ¤íŠ¸ ì˜ì—­ ì¤‘ì•™: 340-520 (ì¤‘ì•™ 430px)
            zone_center_y = 430
            start_y = zone_center_y - (total_height // 2)
        else:  # bottom (middleë„ bottomê³¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬)
            # í•˜ë‹¨ í…ìŠ¤íŠ¸ ì˜ì—­ ì¤‘ì•™: 520-700 (ì¤‘ì•™ 610px)
            zone_center_y = 610
            start_y = zone_center_y - (total_height // 2)
        
        # ìµœì†Œê°’ ë³´ì¥ (íƒ€ì´í‹€ ì˜ì—­ ì¹¨ë²” ë°©ì§€)
        start_y = max(start_y, title_height + padding)
        
        # ì´ëª¨ì§€ í°íŠ¸ ì¤€ë¹„ (ë³¸ë¬¸ í°íŠ¸ í¬ê¸°ì— ë§ì¶¤)
        emoji_font_path = self.get_emoji_font()
        emoji_font = None
        if emoji_font_path:
            try:
                emoji_font = ImageFont.truetype(emoji_font_path, 32)  # 36pt ë³¸ë¬¸ì— ë§ì¶˜ ì´ëª¨ì§€ í¬ê¸°
            except:
                emoji_font = None
        
        # text_styleì— ë”°ë¥¸ í…ìŠ¤íŠ¸ ë Œë”ë§
        if text_style == "background":
            # ë°˜íˆ¬ëª… ë°°ê²½ ìŠ¤íƒ€ì¼ (ê¸°ì¡´)
            self._render_text_with_background(draw, lines, font, emoji_font, width, start_y, line_height)
        elif text_style == "white_background":
            # í°ìƒ‰ ë°˜íˆ¬ëª… ë°°ê²½ + ê²€ì€ìƒ‰ ê¸€ì + ë‘¥ê·¼ ëª¨ì„œë¦¬ (ì‹ ê·œ)
            self._render_text_with_white_background(draw, lines, font, emoji_font, width, start_y, line_height)
        elif text_style == "black_text_white_outline":
            # ê²€ì€ìƒ‰ ê¸€ì”¨ + í°ìƒ‰ ì™¸ê³½ì„  (ì‹ ê·œ)
            self._render_text_with_black_text_white_outline(draw, lines, font, emoji_font, width, start_y, line_height)
        else:
            # ì™¸ê³½ì„  ìŠ¤íƒ€ì¼ (ê¸°ë³¸ê°’)
            self._render_text_with_outline(draw, lines, font, emoji_font, width, start_y, line_height)
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.png')
        img.save(temp_file.name, "PNG")
        temp_file.close()
        
        return temp_file.name
    
    def _render_text_with_outline(self, draw, lines, font, emoji_font, width, start_y, line_height):
        """ì™¸ê³½ì„  ìŠ¤íƒ€ì¼ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§ (ê¸°ì¡´ ë°©ì‹)"""
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (width - text_width) // 2
            y = start_y + i * line_height
            
            # í…ìŠ¤íŠ¸ ë Œë”ë§ (ë¶€ë“œëŸ¬ìš´ ì™¸ê³½ì„  íš¨ê³¼)
            try:
                # ë” ë¶€ë“œëŸ¬ìš´ ì™¸ê³½ì„  (3px ë‘ê»˜, 1.5ë°° ê°•í™”)
                outline_positions = [
                    (-3, -3), (-3, -2), (-3, -1), (-3, 0), (-3, 1), (-3, 2), (-3, 3),
                    (-2, -3), (-2, -2), (-2, -1), (-2, 0), (-2, 1), (-2, 2), (-2, 3),
                    (-1, -3), (-1, -2), (-1, -1), (-1, 0), (-1, 1), (-1, 2), (-1, 3),
                    (0, -3), (0, -2), (0, -1),            (0, 1), (0, 2), (0, 3),
                    (1, -3), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3),
                    (2, -3), (2, -2), (2, -1), (2, 0), (2, 1), (2, 2), (2, 3),
                    (3, -3), (3, -2), (3, -1), (3, 0), (3, 1), (3, 2), (3, 3)
                ]
                
                # ê²€ì€ìƒ‰ ì™¸ê³½ì„  ê·¸ë¦¬ê¸°
                for dx, dy in outline_positions:
                    draw.text((x + dx, y + dy), line, font=font, fill='black')
                
                # í°ìƒ‰ í…ìŠ¤íŠ¸ (ì¤‘ì•™)
                draw.text((x, y), line, font=font, fill='white')
                
            except Exception as e:
                print(f"ë³¸ë¬¸ í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
                # í´ë°±: ê¸°ë³¸ ì™¸ê³½ì„ 
                for dx in [-1, 0, 1]:
                    for dy in [-1, 0, 1]:
                        if dx != 0 or dy != 0:
                            draw.text((x + dx, y + dy), line, font=font, fill='black')
                draw.text((x, y), line, font=font, fill='white')
    
    def _render_text_with_background(self, draw, lines, font, emoji_font, width, start_y, line_height):
        """ë°˜íˆ¬ëª… ë°°ê²½ ìŠ¤íƒ€ì¼ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§"""
        # ì „ì²´ í…ìŠ¤íŠ¸ ì˜ì—­ í¬ê¸° ê³„ì‚°
        max_text_width = 0
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            if text_width > max_text_width:
                max_text_width = text_width
        
        # ë°°ê²½ ë°•ìŠ¤ í¬ê¸°ì™€ ìœ„ì¹˜ ê³„ì‚°
        padding_x = 20  # ì¢Œìš° íŒ¨ë”©
        padding_y = 10  # ìƒí•˜ íŒ¨ë”©
        background_width = max_text_width + padding_x * 2
        background_height = len(lines) * line_height + padding_y * 2
        
        background_x = (width - background_width) // 2
        background_y = start_y - padding_y
        
        # ë°˜íˆ¬ëª… ê²€ì€ ë°°ê²½ ì§ì ‘ ê·¸ë¦¬ê¸°
        draw.rectangle(
            [background_x, background_y, background_x + background_width, background_y + background_height],
            fill=(0, 0, 0, 178)  # ê²€ì€ìƒ‰ 70% íˆ¬ëª…ë„
        )
        
        # í…ìŠ¤íŠ¸ ë Œë”ë§ (ë°°ê²½ ìœ„ì— í°ìƒ‰ í…ìŠ¤íŠ¸)
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            # ë°°ê²½ ë°•ìŠ¤ ë‚´ë¶€ ì¤‘ì•™ ì •ë ¬
            x = background_x + (background_width - text_width) // 2
            y = start_y + i * line_height

            # í°ìƒ‰ í…ìŠ¤íŠ¸ (ë°°ê²½ì´ ìˆìœ¼ë¯€ë¡œ ì™¸ê³½ì„  ë¶ˆí•„ìš”)
            draw.text((x, y), line, font=font, fill='white')

    def _render_text_with_white_background(self, draw, lines, font, emoji_font, width, start_y, line_height):
        """í°ìƒ‰ ë°˜íˆ¬ëª… ë°°ê²½ + ê²€ì€ìƒ‰ ê¸€ì + ë‘¥ê·¼ ëª¨ì„œë¦¬ ìŠ¤íƒ€ì¼ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§"""
        # ì „ì²´ í…ìŠ¤íŠ¸ ì˜ì—­ í¬ê¸° ê³„ì‚°
        max_text_width = 0
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            if text_width > max_text_width:
                max_text_width = text_width

        # ë°°ê²½ ë°•ìŠ¤ í¬ê¸°ì™€ ìœ„ì¹˜ ê³„ì‚°
        padding_x = 20  # ì¢Œìš° íŒ¨ë”©
        padding_y = 10  # ìƒí•˜ íŒ¨ë”©
        background_width = max_text_width + padding_x * 2
        background_height = len(lines) * line_height + padding_y * 2

        background_x = (width - background_width) // 2
        background_y = start_y - padding_y

        # ë‘¥ê·¼ ëª¨ì„œë¦¬ í°ìƒ‰ ë°˜íˆ¬ëª… ë°°ê²½ ê·¸ë¦¬ê¸°
        from PIL import ImageDraw

        # ë‘¥ê·¼ ëª¨ì„œë¦¬ ë°˜ì§€ë¦„
        corner_radius = 12

        # ë°˜íˆ¬ëª… í°ìƒ‰ ë°°ê²½ (íˆ¬ëª…ë„ 80%)
        # PILì—ì„œ ë‘¥ê·¼ ì‚¬ê°í˜•ì„ ê·¸ë¦¬ëŠ” í•¨ìˆ˜
        def draw_rounded_rectangle(draw, xy, radius, fill):
            x1, y1, x2, y2 = xy
            # ë„¤ ëª¨ì„œë¦¬ì˜ ì› ê·¸ë¦¬ê¸°
            draw.ellipse([x1, y1, x1 + radius*2, y1 + radius*2], fill=fill)  # ì™¼ìª½ ìœ„
            draw.ellipse([x2 - radius*2, y1, x2, y1 + radius*2], fill=fill)  # ì˜¤ë¥¸ìª½ ìœ„
            draw.ellipse([x1, y2 - radius*2, x1 + radius*2, y2], fill=fill)  # ì™¼ìª½ ì•„ë˜
            draw.ellipse([x2 - radius*2, y2 - radius*2, x2, y2], fill=fill)  # ì˜¤ë¥¸ìª½ ì•„ë˜

            # ì¤‘ì•™ ì‚¬ê°í˜•ë“¤ ê·¸ë¦¬ê¸°
            draw.rectangle([x1 + radius, y1, x2 - radius, y2], fill=fill)  # ê°€ë¡œ ì¤‘ì•™
            draw.rectangle([x1, y1 + radius, x2, y2 - radius], fill=fill)  # ì„¸ë¡œ ì¤‘ì•™

        # ë‘¥ê·¼ ëª¨ì„œë¦¬ í°ìƒ‰ ë°˜íˆ¬ëª… ë°°ê²½ ê·¸ë¦¬ê¸°
        draw_rounded_rectangle(
            draw,
            [background_x, background_y, background_x + background_width, background_y + background_height],
            corner_radius,
            (255, 255, 255, 204)  # í°ìƒ‰ 80% íˆ¬ëª…ë„
        )

        # í…ìŠ¤íŠ¸ ë Œë”ë§ (ë°°ê²½ ë°•ìŠ¤ ë‚´ë¶€ì— ê²€ì€ìƒ‰ í…ìŠ¤íŠ¸)
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            # ë°°ê²½ ë°•ìŠ¤ ë‚´ë¶€ ì¤‘ì•™ ì •ë ¬
            x = background_x + (background_width - text_width) // 2
            y = start_y + i * line_height

            # ê²€ì€ìƒ‰ í…ìŠ¤íŠ¸ (ë°°ê²½ì´ ìˆìœ¼ë¯€ë¡œ ì™¸ê³½ì„  ë¶ˆí•„ìš”)
            draw.text((x, y), line, font=font, fill='black')

    def _render_text_with_black_text_white_outline(self, draw, lines, font, emoji_font, width, start_y, line_height):
        """ê²€ì€ìƒ‰ ê¸€ì”¨ + í°ìƒ‰ ì™¸ê³½ì„  ìŠ¤íƒ€ì¼ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§"""
        # ê° ì¤„ë³„ë¡œ í…ìŠ¤íŠ¸ ë Œë”ë§
        for i, line in enumerate(lines):
            bbox = draw.textbbox((0, 0), line, font=font)
            text_width = bbox[2] - bbox[0]
            x = (width - text_width) // 2
            y = start_y + i * line_height

            try:
                # ë” ë¶€ë“œëŸ¬ìš´ í°ìƒ‰ ì™¸ê³½ì„  (3px ë‘ê»˜)
                outline_positions = [
                    (-3, -3), (-3, -2), (-3, -1), (-3, 0), (-3, 1), (-3, 2), (-3, 3),
                    (-2, -3), (-2, -2), (-2, -1), (-2, 0), (-2, 1), (-2, 2), (-2, 3),
                    (-1, -3), (-1, -2), (-1, -1), (-1, 0), (-1, 1), (-1, 2), (-1, 3),
                    (0, -3), (0, -2), (0, -1),            (0, 1), (0, 2), (0, 3),
                    (1, -3), (1, -2), (1, -1), (1, 0), (1, 1), (1, 2), (1, 3),
                    (2, -3), (2, -2), (2, -1), (2, 0), (2, 1), (2, 2), (2, 3),
                    (3, -3), (3, -2), (3, -1), (3, 0), (3, 1), (3, 2), (3, 3)
                ]

                # í°ìƒ‰ ì™¸ê³½ì„  ê·¸ë¦¬ê¸°
                for dx, dy in outline_positions:
                    draw.text((x + dx, y + dy), line, font=font, fill='white')

                # ê²€ì€ìƒ‰ í…ìŠ¤íŠ¸ (ì¤‘ì•™)
                draw.text((x, y), line, font=font, fill='black')

            except Exception as e:
                print(f"ë³¸ë¬¸ í…ìŠ¤íŠ¸ ë Œë”ë§ ì˜¤ë¥˜: {e}")
                # í´ë°±: ê¸°ë³¸ ì™¸ê³½ì„ 
                for dx in [-1, 0, 1]:
                    for dy in [-1, 0, 1]:
                        if dx != 0 or dy != 0:
                            draw.text((x + dx, y + dy), line, font=font, fill='white')
                draw.text((x, y), line, font=font, fill='black')

    def crop_to_square(self, image_path):
        """ì´ë¯¸ì§€ë¥¼ ì¤‘ì•™ ê¸°ì¤€ ì •ì‚¬ê°í˜•ìœ¼ë¡œ í¬ë¡­í•˜ì—¬ 716x716ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ"""
        try:
            with Image.open(image_path) as img:
                width, height = img.size
                print(f"ğŸ”³ ì´ë¯¸ì§€ ë¡œë“œ: {image_path} ({width}x{height})")
                
                # ì´ë¯¸ 716x716ì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
                if width == 716 and height == 716:
                    print(f"ğŸ”³ ì´ë¯¸ 716x716: ë³€í™˜ ë¶ˆí•„ìš”")
                    return image_path
                
                # ì§§ì€ ë³€ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ì‚¬ê°í˜• í¬ê¸° ê²°ì •
                crop_size = min(width, height)
                
                # ì¤‘ì•™ ê¸°ì¤€ í¬ë¡­ ì¢Œí‘œ ê³„ì‚°
                left = (width - crop_size) // 2
                top = (height - crop_size) // 2
                right = left + crop_size
                bottom = top + crop_size
                
                # í¬ë¡­ ì‹¤í–‰ (ì •ì‚¬ê°í˜•ì´ ì•„ë‹Œ ê²½ìš°ë§Œ)
                if width != height:
                    cropped_img = img.crop((left, top, right, bottom))
                    print(f"ğŸ”³ í¬ë¡­ ì‹¤í–‰: {width}x{height} â†’ {crop_size}x{crop_size}")
                else:
                    cropped_img = img.copy()
                    print(f"ğŸ”³ ì •ì‚¬ê°í˜• ì´ë¯¸ì§€: í¬ë¡­ ìƒëµ")
                
                # í•­ìƒ 716x716ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (PIL ë²„ì „ í˜¸í™˜ì„± ê³ ë ¤)
                try:
                    # Pillow 10.0.0+ ë²„ì „
                    resized_img = cropped_img.resize((716, 716), Image.Resampling.LANCZOS)
                except AttributeError:
                    # ì´ì „ ë²„ì „ í˜¸í™˜ì„±
                    resized_img = cropped_img.resize((716, 716), Image.LANCZOS)
                
                # RGBA ëª¨ë“œì¸ ê²½ìš° RGBë¡œ ë³€í™˜ (JPEG ì €ì¥ ìœ„í•´)
                if resized_img.mode in ('RGBA', 'LA', 'P'):
                    # í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ ë³€í™˜
                    background = Image.new('RGB', resized_img.size, (255, 255, 255))
                    if resized_img.mode == 'P':
                        resized_img = resized_img.convert('RGBA')
                    background.paste(resized_img, mask=resized_img.split()[-1] if resized_img.mode in ('RGBA', 'LA') else None)
                    resized_img = background
                    print(f"ğŸ”³ RGBA â†’ RGB ë³€í™˜ ì™„ë£Œ")
                
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.jpg')
                resized_img.save(temp_file.name, 'JPEG', quality=95)
                
                print(f"ğŸ”³ ìµœì¢… ë¦¬ì‚¬ì´ì¦ˆ: â†’ 716x716")
                print(f"ğŸ”³ ì„ì‹œ íŒŒì¼ ìƒì„±: {temp_file.name}")
                
                return temp_file.name
                
        except Exception as e:
            print(f"âŒ ì´ë¯¸ì§€ ë³€í™˜ ì—ëŸ¬: {image_path}")
            print(f"âŒ ì—ëŸ¬ ë‚´ìš©: {str(e)}")
            # ì—ëŸ¬ ë°œìƒì‹œ ì›ë³¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ë°˜í™˜
            return image_path

    def easing_function(self, p):
        """ë”ìš± ë¶€ë“œëŸ¬ìš´ ì´ì§• í•¨ìˆ˜ (cubic ease-in-out)"""
        if p < 0.5:
            return 4 * p * p * p
        else:
            return 1 - pow(-2 * p + 2, 3) / 2
    
    def linear_easing_function(self, p):
        """ì¼ì •í•œ ì†ë„ì˜ ì„ í˜• ì´ì§• í•¨ìˆ˜ (íŒ¨ë‹ ì „ìš©)"""
        return p

    def create_background_clip(self, image_path, duration):
        """ìƒˆë¡œìš´ ì˜ìƒ/ì´ë¯¸ì§€ ë°°ì¹˜ ë° íŒ¨ë‹ ê·œì¹™ ì ìš©"""
        print(f"ğŸ¬ ë°°ê²½ í´ë¦½ ìƒì„± ì‹œì‘: {image_path} (duration: {duration:.1f}s)")
        
        try:
            # ì´ë¯¸ì§€ ì •ë³´ ë¡œë“œ
            with Image.open(image_path) as img:
                orig_width, orig_height = img.size
                print(f"ğŸ“ ì´ë¯¸ì§€ ì›ë³¸: {orig_width}x{orig_height}")
            
            # ì‘ì—… ì˜ì—­ ì •ì˜: (0, 220) ~ (504, 890)
            work_width = 504
            work_height = 670  # 890 - 220
            work_aspect_ratio = work_width / work_height  # 252:335 = 0.751
            image_aspect_ratio = orig_width / orig_height
            
            print(f"ğŸ“Š ì¢…íš¡ë¹„ ë¹„êµ: ì´ë¯¸ì§€ {image_aspect_ratio:.3f} vs ì‘ì—…ì˜ì—­ {work_aspect_ratio:.3f}")
            
            # ë°°ê²½ í´ë¦½ ìƒì„±
            bg_clip = ImageClip(image_path).set_duration(duration)
            
            if image_aspect_ratio > work_aspect_ratio:
                # ê°€ë¡œí˜• ì´ë¯¸ì§€: ì„¸ë¡œ ë†’ì´ë¥¼ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë°°ì¹˜í•˜ê³  ì¢Œìš° íŒ¨ë‹
                print(f"ğŸ”„ ê°€ë¡œí˜• ì´ë¯¸ì§€ ì²˜ë¦¬: ì„¸ë¡œ ë†’ì´ë¥¼ {work_height}ì— ë§ì¶¤")
                
                # ì„¸ë¡œë¥¼ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ
                bg_clip = bg_clip.resize(height=work_height)
                resized_width = int(orig_width * work_height / orig_height)
                print(f"ğŸ”§ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ: {resized_width}x{work_height}")
                
                # ì¢Œìš° íŒ¨ë‹ ë²”ìœ„ ê³„ì‚°
                pan_range = min(60, (resized_width - work_width) // 2)  # ìµœëŒ€ 60px ë˜ëŠ” ì—¬ìœ  ê³µê°„ì˜ ì ˆë°˜
                
                # 2ê°€ì§€ ì¢Œìš° íŒ¨ë‹ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ
                pattern = random.randint(1, 2)
                
                if pattern == 1:
                    # íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹
                    def left_to_right(t):
                        progress = self.linear_easing_function(t / duration)
                        x_offset = -((resized_width - work_width) // 2 - pan_range * progress)
                        return (x_offset, 220)  # YëŠ” íƒ€ì´í‹€ ë°”ë¡œ ì•„ë˜
                    
                    bg_clip = bg_clip.set_position(left_to_right)
                    print(f"ğŸ¬ íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹ ({pan_range}px ì´ë™)")
                    
                else:
                    # íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹
                    def right_to_left(t):
                        progress = self.linear_easing_function(t / duration)
                        x_offset = -((resized_width - work_width) // 2 - pan_range * (1 - progress))
                        return (x_offset, 220)  # YëŠ” íƒ€ì´í‹€ ë°”ë¡œ ì•„ë˜
                    
                    bg_clip = bg_clip.set_position(right_to_left)
                    print(f"ğŸ¬ íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹ ({pan_range}px ì´ë™)")
                    
            else:
                # ì„¸ë¡œí˜• ì´ë¯¸ì§€: ê°€ë¡œ í­ì„ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë°°ì¹˜í•˜ê³  ìƒí•˜ íŒ¨ë‹
                print(f"ğŸ”„ ì„¸ë¡œí˜• ì´ë¯¸ì§€ ì²˜ë¦¬: ê°€ë¡œ í­ì„ {work_width}ì— ë§ì¶¤")
                
                # ê°€ë¡œë¥¼ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ
                bg_clip = bg_clip.resize(width=work_width)
                resized_height = int(orig_height * work_width / orig_width)
                print(f"ğŸ”§ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ: {work_width}x{resized_height}")
                
                # ìƒí•˜ íŒ¨ë‹ ë²”ìœ„ ê³„ì‚°
                pan_range = min(60, (resized_height - work_height) // 2)  # ìµœëŒ€ 60px ë˜ëŠ” ì—¬ìœ  ê³µê°„ì˜ ì ˆë°˜
                
                # 2ê°€ì§€ ìƒí•˜ íŒ¨ë‹ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ
                pattern = random.randint(3, 4)  # íŒ¨í„´ 3, 4ë¡œ êµ¬ë¶„
                
                if pattern == 3:
                    # íŒ¨í„´ 3: ìœ„ â†’ ì•„ë˜ íŒ¨ë‹
                    def top_to_bottom(t):
                        progress = self.linear_easing_function(t / duration)
                        y_offset = 220 - ((resized_height - work_height) // 2 - pan_range * progress)
                        return (0, y_offset)  # XëŠ” ì¤‘ì•™
                    
                    bg_clip = bg_clip.set_position(top_to_bottom)
                    print(f"ğŸ¬ íŒ¨í„´ 3: ìœ„ â†’ ì•„ë˜ íŒ¨ë‹ ({pan_range}px ì´ë™)")
                    
                else:
                    # íŒ¨í„´ 4: ì•„ë˜ â†’ ìœ„ íŒ¨ë‹
                    def bottom_to_top(t):
                        progress = self.linear_easing_function(t / duration)
                        y_offset = 220 - ((resized_height - work_height) // 2 - pan_range * (1 - progress))
                        return (0, y_offset)  # XëŠ” ì¤‘ì•™
                    
                    bg_clip = bg_clip.set_position(bottom_to_top)
                    print(f"ğŸ¬ íŒ¨í„´ 4: ì•„ë˜ â†’ ìœ„ íŒ¨ë‹ ({pan_range}px ì´ë™)")
            
            return bg_clip
                
        except Exception as e:
            print(f"âŒ ë°°ê²½ í´ë¦½ ìƒì„± ì—ëŸ¬: {str(e)}")
            # ì—ëŸ¬ ë°œìƒì‹œ ê¸°ë³¸ í´ë¦½ ë°˜í™˜
            fallback_clip = ImageClip(image_path).set_duration(duration)
            fallback_clip = fallback_clip.resize(height=670).set_position((0, 220))
            return fallback_clip


    
    def create_continuous_background_clip(self, image_path, total_duration, start_offset=0.0):
        """2ê°œ body ë™ì•ˆ ì—°ì†ì ìœ¼ë¡œ ì›€ì§ì´ëŠ” ë°°ê²½ í´ë¦½ ìƒì„± - 3ê°€ì§€ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ"""
        print(f"ğŸ¬ ì—°ì† ë°°ê²½ í´ë¦½ ìƒì„±: {image_path} (duration: {total_duration:.1f}s, offset: {start_offset:.1f}s)")
        
        # ì´ë¯¸ì§€ë¥¼ ì •ì‚¬ê°í˜•ìœ¼ë¡œ í¬ë¡­ í›„ 716x716ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        square_image_path = self.crop_to_square(image_path)
        
        try:
            # ë°°ê²½ í´ë¦½ ìƒì„±
            bg_clip = ImageClip(square_image_path).set_duration(total_duration)
            
            # íƒ€ì´í‹€ ì•„ë˜ ì˜ì—­ ê³„ì‚°
            title_height = 220
            
            # 2ê°€ì§€ íŒ¨ë‹ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ (í™•ëŒ€ íŒ¨í„´ ì œê±°)
            pattern = random.randint(1, 2)
            
            # ëª¨ë“  ì—°ì† í´ë¦½ì— íŒ¨ë‹ ì ìš© (3ì´ˆ ë¯¸ë§Œ í¬í•¨)
            if pattern == 1:
                # íŒ¨í„´ 1: ì—°ì† ì¢Œ â†’ ìš° íŒ¨ë‹ (Linear ì´ì§• + 60px ì´ë™)
                def continuous_left_to_right(t):
                    # ì „ì²´ ì§€ì† ì‹œê°„ì— ëŒ€í•œ ì§„í–‰ë„
                    progress = self.linear_easing_function(t / total_duration)  # ì¼ì •í•œ ì†ë„
                    # 60px ì´ë™ ë²”ìœ„ë¡œ í™•ëŒ€
                    x_offset = -(151 - 60 * progress)
                    return (x_offset, title_height)
                
                bg_clip = bg_clip.set_position(continuous_left_to_right)
                print(f"ğŸ¬ ì—°ì† íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹ (duration: {total_duration:.1f}s)")
                
            else:
                # íŒ¨í„´ 2: ì—°ì† ìš° â†’ ì¢Œ íŒ¨ë‹ (Linear ì´ì§• + 60px ì´ë™)
                def continuous_right_to_left(t):
                    # ì „ì²´ ì§€ì† ì‹œê°„ì— ëŒ€í•œ ì§„í–‰ë„
                    progress = self.linear_easing_function(t / total_duration)  # ì¼ì •í•œ ì†ë„
                    # 60px ì´ë™ ë²”ìœ„ë¡œ í™•ëŒ€ (ë°˜ëŒ€ ë°©í–¥)
                    x_offset = -(151 - 60 * (1 - progress))
                    return (x_offset, title_height)
                
                bg_clip = bg_clip.set_position(continuous_right_to_left)
                print(f"ğŸ¬ ì—°ì† íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹ (duration: {total_duration:.1f}s)")
            
            return bg_clip
                
        except Exception as e:
            print(f"âŒ ì—°ì† ë°°ê²½ í´ë¦½ ì—ëŸ¬: {str(e)}")
            # ì—ëŸ¬ ë°œìƒì‹œ ê¸°ë³¸ í´ë¦½ ë°˜í™˜
            fallback_clip = ImageClip(image_path).set_duration(total_duration)
            fallback_clip = fallback_clip.resize(height=670).set_position((0, 0))
            return fallback_clip
            
        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if square_image_path != image_path and os.path.exists(square_image_path):
                try:
                    os.unlink(square_image_path)
                    print(f"ğŸ—‘ï¸ ì—°ì† ì„ì‹œ íŒŒì¼ ì •ë¦¬: {square_image_path}")
                except:
                    pass

    
    def create_video_background_clip(self, video_path, duration):
        """ìƒˆë¡œìš´ ë¹„ë””ì˜¤ ë°°ì¹˜ ë° íŒ¨ë‹ ê·œì¹™ ì ìš©"""
        from moviepy.editor import VideoFileClip, ColorClip, CompositeVideoClip
        
        print(f"ğŸ¬ ë¹„ë””ì˜¤ ë°°ê²½ í´ë¦½ ìƒì„± ì‹œì‘: {video_path} (duration: {duration:.1f}s)")
        
        try:
            # ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œ
            video_clip = VideoFileClip(video_path)

            # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„° ê²€ì¦
            if video_clip.duration is None or video_clip.duration <= 0:
                raise Exception(f"ë¹„ë””ì˜¤ íŒŒì¼ì˜ ì§€ì† ì‹œê°„ ì •ë³´ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {video_clip.duration}")

            # ë¹„ë””ì˜¤ ì›ë³¸ í¬ê¸°
            orig_width = video_clip.w
            orig_height = video_clip.h
            print(f"ğŸ“ ë¹„ë””ì˜¤ ì›ë³¸: {orig_width}x{orig_height}")

            # ë¹„ë””ì˜¤ íŒŒì¼ ì •ë³´ ê²€ì¦
            if orig_width <= 0 or orig_height <= 0:
                raise Exception(f"ë¹„ë””ì˜¤ í•´ìƒë„ ì •ë³´ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {orig_width}x{orig_height}")
            
            # ì‘ì—… ì˜ì—­ ì •ì˜: (0, 220) ~ (504, 890)
            work_width = 504
            work_height = 670  # 890 - 220
            work_aspect_ratio = work_width / work_height  # 252:335 = 0.751
            video_aspect_ratio = orig_width / orig_height
            
            print(f"ğŸ“Š ì¢…íš¡ë¹„ ë¹„êµ: ë¹„ë””ì˜¤ {video_aspect_ratio:.3f} vs ì‘ì—…ì˜ì—­ {work_aspect_ratio:.3f}")
            
            # ë¹„ë””ì˜¤ ê¸¸ì´ ì¡°ì • (ì•ˆì „í•œ ì²˜ë¦¬)
            original_duration = video_clip.duration
            print(f"ğŸ“ ë¹„ë””ì˜¤ ì›ë³¸ ê¸¸ì´: {original_duration:.2f}ì´ˆ, ëª©í‘œ ê¸¸ì´: {duration:.2f}ì´ˆ")

            if original_duration > duration:
                # ë¹„ë””ì˜¤ê°€ ê¸´ ê²½ìš°: ì•ˆì „í•˜ê²Œ ìë¥´ê¸° (ì•½ê°„ì˜ ì—¬ìœ ë¥¼ ë‘ )
                safe_duration = min(duration, original_duration - 0.2)  # 0.2ì´ˆ ì—¬ìœ 
                safe_duration = max(safe_duration, 0.5)  # ìµœì†Œ 0.5ì´ˆëŠ” ë³´ì¥
                print(f"â‚ ë¹„ë””ì˜¤ ê¸¸ì´ ì¡°ì •: {safe_duration:.2f}ì´ˆë¡œ ì•ˆì „í•˜ê²Œ ì˜ë¼ëƒ„")
                video_clip = video_clip.subclip(0, safe_duration)
            elif original_duration < duration:
                # ë¹„ë””ì˜¤ê°€ ì§§ì€ ê²½ìš°: ë°˜ë³µ ì¬ìƒìœ¼ë¡œ ê¸¸ì´ ë§ì¶¤
                try:
                    # ì•ˆì „í•œ ë°˜ë³µ ì²˜ë¦¬
                    loop_count = int(duration // original_duration) + 1
                    print(f"ğŸ” ë¹„ë””ì˜¤ ë°˜ë³µ ì²˜ë¦¬: {loop_count}íšŒ ë°˜ë³µí•˜ì—¬ {duration}ì´ˆ ë‹¬ì„±")

                    # ê°œë³„ í´ë¦½ë“¤ì„ ìƒì„±í•´ì„œ ì—°ê²°í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë³€ê²½
                    clips = []
                    current_time = 0

                    while current_time < duration:
                        remaining_time = duration - current_time
                        if remaining_time >= original_duration:
                            # ì „ì²´ í´ë¦½ ì¶”ê°€
                            clips.append(video_clip)
                            current_time += original_duration
                        else:
                            # ë¶€ë¶„ í´ë¦½ ì¶”ê°€ (ì•ˆì „í•˜ê²Œ)
                            safe_remaining = min(remaining_time, original_duration - 0.2)
                            if safe_remaining > 0.2:  # ìµœì†Œ 0.2ì´ˆëŠ” ìˆì–´ì•¼ í•¨
                                print(f"ğŸ“ ë¶€ë¶„ í´ë¦½ ìƒì„±: 0ì´ˆ ~ {safe_remaining:.2f}ì´ˆ")
                                clips.append(video_clip.subclip(0, safe_remaining))
                            current_time = duration  # ë£¨í”„ ì¢…ë£Œ

                    if clips:
                        from moviepy.editor import concatenate_videoclips
                        video_clip = concatenate_videoclips(clips)
                        print(f"âœ… ë¹„ë””ì˜¤ ë°˜ë³µ ì™„ì„±: ìµœì¢… ê¸¸ì´ {video_clip.duration:.2f}ì´ˆ")

                except Exception as e:
                    print(f"âš ï¸ ë¹„ë””ì˜¤ ë°˜ë³µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¹„ë””ì˜¤ë¥¼ ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì—°ì¥
                    print("ğŸ“¸ ëŒ€ì•ˆ: ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì—°ì¥ ì²˜ë¦¬")
                    from moviepy.editor import ImageClip, concatenate_videoclips

                    # ì›ë³¸ ë¹„ë””ì˜¤ + ë§ˆì§€ë§‰ í”„ë ˆì„ ì •ì§€ ì´ë¯¸ì§€
                    safe_frame_time = max(0, min(original_duration - 0.3, original_duration * 0.9))
                    print(f"ğŸ“¸ ì•ˆì „í•œ í”„ë ˆì„ ì¶”ì¶œ ì‹œê°„: {safe_frame_time:.2f}ì´ˆ")

                    last_frame = video_clip.to_ImageClip(t=safe_frame_time)
                    extension_duration = duration - original_duration
                    extension_clip = last_frame.set_duration(extension_duration)

                    video_clip = concatenate_videoclips([video_clip, extension_clip])
                    print(f"ğŸ–¼ï¸ ë§ˆì§€ë§‰ í”„ë ˆì„ ì—°ì¥: {extension_duration:.2f}ì´ˆ ì¶”ê°€")
            
            if video_aspect_ratio > work_aspect_ratio:
                # ê°€ë¡œí˜• ë¹„ë””ì˜¤: ì„¸ë¡œ ë†’ì´ë¥¼ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë°°ì¹˜í•˜ê³  ì¢Œìš° íŒ¨ë‹
                print(f"ğŸ”„ ê°€ë¡œí˜• ë¹„ë””ì˜¤ ì²˜ë¦¬: ì„¸ë¡œ ë†’ì´ë¥¼ {work_height}ì— ë§ì¶¤")
                
                # ì„¸ë¡œë¥¼ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ
                video_clip = video_clip.resize(height=work_height)
                resized_width = int(orig_width * work_height / orig_height)
                print(f"ğŸ”§ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ: {resized_width}x{work_height}")
                
                # ì¢Œìš° íŒ¨ë‹ ë²”ìœ„ ê³„ì‚°
                pan_range = min(60, (resized_width - work_width) // 2)  # ìµœëŒ€ 60px ë˜ëŠ” ì—¬ìœ  ê³µê°„ì˜ ì ˆë°˜
                
                # 2ê°€ì§€ ì¢Œìš° íŒ¨ë‹ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ
                pattern = random.randint(1, 2)
                
                if pattern == 1:
                    # íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹
                    def left_to_right(t):
                        progress = self.linear_easing_function(t / duration)
                        x_offset = -((resized_width - work_width) // 2 - pan_range * progress)
                        return (x_offset, 220)  # YëŠ” íƒ€ì´í‹€ ë°”ë¡œ ì•„ë˜
                    
                    video_clip = video_clip.set_position(left_to_right)
                    print(f"ğŸ¬ íŒ¨í„´ 1: ì¢Œ â†’ ìš° íŒ¨ë‹ ({pan_range}px ì´ë™)")
                    
                else:
                    # íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹
                    def right_to_left(t):
                        progress = self.linear_easing_function(t / duration)
                        x_offset = -((resized_width - work_width) // 2 - pan_range * (1 - progress))
                        return (x_offset, 220)  # YëŠ” íƒ€ì´í‹€ ë°”ë¡œ ì•„ë˜
                    
                    video_clip = video_clip.set_position(right_to_left)
                    print(f"ğŸ¬ íŒ¨í„´ 2: ìš° â†’ ì¢Œ íŒ¨ë‹ ({pan_range}px ì´ë™)")
                    
            else:
                # ì„¸ë¡œí˜• ë¹„ë””ì˜¤: ê°€ë¡œ í­ì„ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë°°ì¹˜í•˜ê³  ìƒí•˜ íŒ¨ë‹
                print(f"ğŸ”„ ì„¸ë¡œí˜• ë¹„ë””ì˜¤ ì²˜ë¦¬: ê°€ë¡œ í­ì„ {work_width}ì— ë§ì¶¤")
                
                # ê°€ë¡œë¥¼ ì‘ì—… ì˜ì—­ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ
                video_clip = video_clip.resize(width=work_width)
                resized_height = int(orig_height * work_width / orig_width)
                print(f"ğŸ”§ ë¦¬ì‚¬ì´ì¦ˆ ì™„ë£Œ: {work_width}x{resized_height}")
                
                # ìƒí•˜ íŒ¨ë‹ ë²”ìœ„ ê³„ì‚°
                pan_range = min(60, (resized_height - work_height) // 2)  # ìµœëŒ€ 60px ë˜ëŠ” ì—¬ìœ  ê³µê°„ì˜ ì ˆë°˜
                
                # 2ê°€ì§€ ìƒí•˜ íŒ¨ë‹ íŒ¨í„´ ì¤‘ ëœë¤ ì„ íƒ
                pattern = random.randint(3, 4)  # íŒ¨í„´ 3, 4ë¡œ êµ¬ë¶„
                
                if pattern == 3:
                    # íŒ¨í„´ 3: ìœ„ â†’ ì•„ë˜ íŒ¨ë‹
                    def top_to_bottom(t):
                        progress = self.linear_easing_function(t / duration)
                        y_offset = 220 - ((resized_height - work_height) // 2 - pan_range * progress)
                        return (0, y_offset)  # XëŠ” ì¤‘ì•™
                    
                    video_clip = video_clip.set_position(top_to_bottom)
                    print(f"ğŸ¬ íŒ¨í„´ 3: ìœ„ â†’ ì•„ë˜ íŒ¨ë‹ ({pan_range}px ì´ë™)")
                    
                else:
                    # íŒ¨í„´ 4: ì•„ë˜ â†’ ìœ„ íŒ¨ë‹
                    def bottom_to_top(t):
                        progress = self.linear_easing_function(t / duration)
                        y_offset = 220 - ((resized_height - work_height) // 2 - pan_range * (1 - progress))
                        return (0, y_offset)  # XëŠ” ì¤‘ì•™
                    
                    video_clip = video_clip.set_position(bottom_to_top)
                    print(f"ğŸ¬ íŒ¨í„´ 4: ì•„ë˜ â†’ ìœ„ íŒ¨ë‹ ({pan_range}px ì´ë™)")
            
            return video_clip
                
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ë°°ê²½ í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            
            # ì‹¤íŒ¨ ì‹œ ê²€ì€ í™”ë©´ìœ¼ë¡œ ëŒ€ì²´
            fallback_clip = ColorClip(size=(504, 670), color=(0,0,0), duration=duration)
            fallback_clip = fallback_clip.set_position((0, 220))
            print(f"ğŸ”„ ê²€ì€ í™”ë©´ìœ¼ë¡œ ëŒ€ì²´: 504x670")
            return fallback_clip
    
    def create_tts_with_naver(self, text):
        """ë„¤ì´ë²„ Clova Voice TTS ìƒì„±"""
        if not self.naver_client_id or not self.naver_client_secret:
            return None
            
        try:
            print(f"ë„¤ì´ë²„ TTS ìƒì„± ì¤‘: {text[:50]}...")
            
            # Naver Clova Voice API í˜¸ì¶œ
            url = "https://naveropenapi.apigw.ntruss.com/tts-premium/v1/tts"
            headers = {
                "X-NCP-APIGW-API-KEY-ID": self.naver_client_id,
                "X-NCP-APIGW-API-KEY": self.naver_client_secret,
                "Content-Type": "application/x-www-form-urlencoded"
            }
            
            data = {
                "speaker": "nara",  # ì—¬ì„± ìŒì„± (clara, matt, shinji, nara ë“± ì„ íƒ ê°€ëŠ¥)
                "volume": "0",      # ë³¼ë¥¨ (-5~5)
                "speed": "0",       # ì†ë„ (-5~5)
                "pitch": "0",       # ìŒë†’ì´ (-5~5)
                "format": "mp3",    # ì¶œë ¥ í¬ë§·
                "text": text
            }
            
            response = requests.post(url, headers=headers, data=data)
            
            if response.status_code == 200:
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
                temp_file.write(response.content)
                temp_file.close()
                print(f"ë„¤ì´ë²„ TTS ìƒì„± ì™„ë£Œ: {temp_file.name}")
                return temp_file.name
            else:
                print(f"ë„¤ì´ë²„ TTS API ì˜¤ë¥˜: {response.status_code}")
                return None
                
        except Exception as e:
            print(f"ë„¤ì´ë²„ TTS ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def create_tts_with_azure(self, text):
        """Microsoft Azure Cognitive Services TTS ìƒì„±"""
        if not self.azure_speech_key:
            return None
            
        try:
            print(f"Azure TTS ìƒì„± ì¤‘: {text[:50]}...")
            
            # Azure Cognitive Services Speech API í˜¸ì¶œ
            url = f"https://{self.azure_speech_region}.tts.speech.microsoft.com/cognitiveservices/v1"
            headers = {
                "Ocp-Apim-Subscription-Key": self.azure_speech_key,
                "Content-Type": "application/ssml+xml",
                "X-Microsoft-OutputFormat": "audio-24khz-48kbitrate-mono-mp3"
            }
            
            # SSML í˜•ì‹ìœ¼ë¡œ ìš”ì²­ ìƒì„± (í•œêµ­ì–´ ì—¬ì„± ìŒì„±)
            ssml = f"""<speak version='1.0' xml:lang='ko-KR'>
                <voice xml:lang='ko-KR' xml:gender='Female' name='ko-KR-SunHiNeural'>
                    <prosody rate='medium' pitch='medium'>
                        {text}
                    </prosody>
                </voice>
            </speak>"""
            
            response = requests.post(url, headers=headers, data=ssml.encode('utf-8'))
            
            if response.status_code == 200:
                temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
                temp_file.write(response.content)
                temp_file.close()
                print(f"Azure TTS ìƒì„± ì™„ë£Œ: {temp_file.name}")
                return temp_file.name
            else:
                print(f"Azure TTS API ì˜¤ë¥˜: {response.status_code}, {response.text}")
                return None
                
        except Exception as e:
            print(f"Azure TTS ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def create_tts_audio(self, text, lang='ko'):
        """Google TTSë¡œ ìµœì í™”ëœ í•œêµ­ì–´ ìŒì„± ìƒì„± - 1.7ë°° ë¹ ë¥¸ ì†ë„ ì ìš©"""
        try:
            print(f"Google TTS ìƒì„± ì¤‘: {text[:50]}...")
            
            # í•œêµ­ì–´ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ë” ìì—°ìŠ¤ëŸ½ê²Œ)
            processed_text = self.preprocess_korean_text(text)
            
            # ìµœì í™”ëœ í•œêµ­ì–´ Google TTS ì„¤ì •
            tts = gTTS(
                text=processed_text, 
                lang='ko',  # ëª…ì‹œì ìœ¼ë¡œ í•œêµ­ì–´ ì„¤ì •
                slow=False,
                tld='com'   # êµ¬ê¸€ ë„ë©”ì¸ ìµœì í™”
            )
            
            # ì„ì‹œ íŒŒì¼ì— ì €ì¥ (ì›ë³¸ ì†ë„)
            original_temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
            tts.save(original_temp_file.name)
            original_temp_file.close()
            print(f"Google TTS ì›ë³¸ ìƒì„± ì™„ë£Œ: {original_temp_file.name}")
            
            # 70% ë¹ ë¥´ê²Œ ì†ë„ ì¡°ì • (1.7ë°°ì†)
            speed_adjusted_file = self.speed_up_audio(original_temp_file.name, speed_factor=1.7)
            
            # ì†ë„ ì¡°ì •ì´ ì‹¤íŒ¨í•˜ë©´ ì›ë³¸ íŒŒì¼ ì‚¬ìš©, ì„±ê³µí•˜ë©´ ì›ë³¸ íŒŒì¼ë§Œ ì •ë¦¬
            if speed_adjusted_file != original_temp_file.name and os.path.exists(speed_adjusted_file):
                # ì†ë„ ì¡°ì • ì„±ê³µ: ìƒˆë¡œìš´ íŒŒì¼ì´ ìƒì„±ë¨, ì›ë³¸ íŒŒì¼ë§Œ ì •ë¦¬
                if os.path.exists(original_temp_file.name):
                    os.unlink(original_temp_file.name)
                    print(f"ğŸ—‘ï¸ ì›ë³¸ TTS íŒŒì¼ ì •ë¦¬: {original_temp_file.name}")
                print(f"Google TTS ìƒì„± ì™„ë£Œ (70% ê³ ì†í™”): {speed_adjusted_file}")
            else:
                # ì†ë„ ì¡°ì • ì‹¤íŒ¨: ì›ë³¸ íŒŒì¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì‚­ì œí•˜ì§€ ì•ŠìŒ)
                print(f"Google TTS ìƒì„± ì™„ë£Œ (ì›ë³¸ ì†ë„): {speed_adjusted_file}")
            
            return speed_adjusted_file
            
        except Exception as e:
            print(f"TTS ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def speed_up_audio(self, audio_path, speed_factor=1.5):
        """ê³ ê¸‰ ì˜¤ë””ì˜¤ ì†ë„ ì¡°ì • (ë‹¤ì¤‘ ì•Œê³ ë¦¬ì¦˜ ì§€ì›)"""
        try:
            print(f"ğŸµ ê³ ê¸‰ ì˜¤ë””ì˜¤ ì†ë„ ì¡°ì • ì‹œì‘: {speed_factor}x ì†ë„")
            
            # ë°©ë²• 1: FFmpeg ì§ì ‘ ì‚¬ìš© (ê°€ì¥ ì•ˆì •ì )
            try:
                return self._speed_up_with_ffmpeg(audio_path, speed_factor)
            except Exception as e:
                print(f"âš ï¸ FFmpeg ë°©ë²• ì‹¤íŒ¨: {e}")
            
            # ë°©ë²• 2: MoviePy ë‹¤ì¤‘ ë°©ì‹
            try:
                return self._speed_up_with_moviepy(audio_path, speed_factor)
            except Exception as e:
                print(f"âš ï¸ MoviePy ë°©ë²• ì‹¤íŒ¨: {e}")
            
            # ë°©ë²• 3: Pydub ì‚¬ìš©
            try:
                return self._speed_up_with_pydub(audio_path, speed_factor)
            except Exception as e:
                print(f"âš ï¸ Pydub ë°©ë²• ì‹¤íŒ¨: {e}")
            
            # ë°©ë²• 4: ìƒ˜í”Œë§ ê¸°ë°˜ ê°„ë‹¨í•œ ì†ë„ ì¡°ì •
            try:
                return self._speed_up_with_sampling(audio_path, speed_factor)
            except Exception as e:
                print(f"âš ï¸ ìƒ˜í”Œë§ ë°©ë²• ì‹¤íŒ¨: {e}")
            
            print(f"âŒ ëª¨ë“  ì†ë„ ì¡°ì • ë°©ë²• ì‹¤íŒ¨, ì›ë³¸ íŒŒì¼ ì‚¬ìš©: {audio_path}")
            return audio_path
            
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì†ë„ ì¡°ì • ì „ì²´ ì‹¤íŒ¨: {e}")
            return audio_path

    def _speed_up_with_ffmpeg(self, audio_path, speed_factor):
        """ë°©ë²• 1: FFmpegë¥¼ ì§ì ‘ ì‚¬ìš©í•œ ê³ í’ˆì§ˆ ì†ë„ ì¡°ì •"""
        print(f"ğŸ”§ FFmpeg ë°©ì‹ ì†ë„ ì¡°ì • ì‹œë„...")
        
        import subprocess
        import shutil
        
        # FFmpeg ì„¤ì¹˜ í™•ì¸
        if not shutil.which('ffmpeg'):
            raise Exception("FFmpegê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ì¶œë ¥ íŒŒì¼ ìƒì„±
        speed_adjusted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
        speed_adjusted_file.close()
        
        # FFmpeg ëª…ë ¹ì–´ë¡œ ì†ë„ ì¡°ì • (atempo í•„í„° ì‚¬ìš©)
        # atempoëŠ” í”¼ì¹˜ ë³€ê²½ ì—†ì´ ì†ë„ë§Œ ì¡°ì • (ìµœëŒ€ 2.0ë°°ê¹Œì§€)
        if speed_factor <= 2.0:
            atempo_filter = f"atempo={speed_factor}"
        else:
            # 2.0ë°° ì´ˆê³¼ì‹œ ì—¬ëŸ¬ ë‹¨ê³„ë¡œ ë‚˜ëˆ”
            atempo_filter = "atempo=2.0,atempo=" + str(speed_factor / 2.0)
        
        cmd = [
            'ffmpeg', '-y',  # ë®ì–´ì“°ê¸° í—ˆìš©
            '-i', audio_path,
            '-filter:a', atempo_filter,
            '-loglevel', 'error',  # ì—ëŸ¬ë§Œ ì¶œë ¥
            speed_adjusted_file.name
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… FFmpeg ì†ë„ ì¡°ì • ì„±ê³µ: {speed_factor}x")
            return speed_adjusted_file.name
        else:
            raise Exception(f"FFmpeg ì‹¤í–‰ ì‹¤íŒ¨: {result.stderr}")
    
    def _speed_up_with_moviepy(self, audio_path, speed_factor):
        """ë°©ë²• 2: MoviePy ë‹¤ì¤‘ ë°©ì‹ ì‹œë„"""
        print(f"ğŸ¬ MoviePy ë°©ì‹ ì†ë„ ì¡°ì • ì‹œë„...")
        
        from moviepy.editor import AudioFileClip
        
        audio_clip = AudioFileClip(audio_path)
        original_duration = audio_clip.duration
        
        # ì‹œë„ 1: speedx import
        try:
            from moviepy.audio.fx import speedx
            speed_adjusted_clip = audio_clip.fx(speedx.speedx, speed_factor)
        except ImportError:
            try:
                from moviepy.audio.fx.speedx import speedx
                speed_adjusted_clip = audio_clip.fx(speedx, speed_factor)
            except ImportError:
                # ì‹œë„ 2: ì§ì ‘ ì‹œê°„ ë§¤í•‘
                print("ğŸ“ ì§ì ‘ ì‹œê°„ ë§¤í•‘ìœ¼ë¡œ ì†ë„ ì¡°ì •...")
                def speed_function(get_frame, t):
                    return get_frame(t * speed_factor)
                
                speed_adjusted_clip = audio_clip.fl(speed_function, apply_to=['mask'])
                speed_adjusted_clip = speed_adjusted_clip.set_duration(audio_clip.duration / speed_factor)
        
        new_duration = speed_adjusted_clip.duration
        
        # íŒŒì¼ ì €ì¥
        speed_adjusted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
        speed_adjusted_clip.write_audiofile(
            speed_adjusted_file.name, 
            verbose=False, 
            logger=None,
            temp_audiofile=None  # ì„ì‹œ íŒŒì¼ ê²½ë¡œ ë¬¸ì œ ë°©ì§€
        )
        speed_adjusted_file.close()
        
        # ë¦¬ì†ŒìŠ¤ í•´ì œ
        audio_clip.close()
        speed_adjusted_clip.close()
        
        print(f"âœ… MoviePy ì†ë„ ì¡°ì • ì™„ë£Œ: {original_duration:.1f}ì´ˆ â†’ {new_duration:.1f}ì´ˆ")
        return speed_adjusted_file.name
    
    def _speed_up_with_pydub(self, audio_path, speed_factor):
        """ë°©ë²• 3: Pydubë¥¼ ì‚¬ìš©í•œ ì†ë„ ì¡°ì •"""
        print(f"ğŸµ Pydub ë°©ì‹ ì†ë„ ì¡°ì • ì‹œë„...")
        
        try:
            from pydub import AudioSegment
            from pydub.playback import play
        except ImportError:
            raise Exception("pydub ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ì˜¤ë””ì˜¤ ë¡œë“œ
        audio = AudioSegment.from_mp3(audio_path)
        
        # ì†ë„ ì¡°ì • (ì¬ìƒ ì†ë„ ë³€ê²½)
        # frame_rateë¥¼ ì¦ê°€ì‹œì¼œ ì†ë„ë¥¼ ë¹ ë¥´ê²Œ í•¨
        new_sample_rate = int(audio.frame_rate * speed_factor)
        speed_adjusted_audio = audio._spawn(audio.raw_data, overrides={"frame_rate": new_sample_rate})
        speed_adjusted_audio = speed_adjusted_audio.set_frame_rate(audio.frame_rate)
        
        # íŒŒì¼ ì €ì¥
        speed_adjusted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
        speed_adjusted_audio.export(speed_adjusted_file.name, format="mp3")
        speed_adjusted_file.close()
        
        print(f"âœ… Pydub ì†ë„ ì¡°ì • ì™„ë£Œ: {len(audio)}ms â†’ {len(speed_adjusted_audio)}ms")
        return speed_adjusted_file.name
    
    def _speed_up_with_sampling(self, audio_path, speed_factor):
        """ë°©ë²• 4: ê°„ë‹¨í•œ ìƒ˜í”Œë§ ê¸°ë°˜ ì†ë„ ì¡°ì •"""
        print(f"ğŸ“Š ìƒ˜í”Œë§ ë°©ì‹ ì†ë„ ì¡°ì • ì‹œë„...")
        
        try:
            import numpy as np
            import wave
        except ImportError:
            raise Exception("numpy ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # WAVë¡œ ë¨¼ì € ë³€í™˜ (í•„ìš”í•œ ê²½ìš°)
        from moviepy.editor import AudioFileClip
        temp_wav = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        temp_wav.close()
        
        audio_clip = AudioFileClip(audio_path)
        audio_clip.write_audiofile(temp_wav.name, verbose=False, logger=None)
        audio_clip.close()
        
        # WAV íŒŒì¼ ì½ê¸°
        with wave.open(temp_wav.name, 'rb') as wav_file:
            frames = wav_file.readframes(-1)
            sound_info = wav_file.getparams()
            audio_data = np.frombuffer(frames, dtype=np.int16)
        
        # ìƒ˜í”Œë§ìœ¼ë¡œ ì†ë„ ì¡°ì • (ê°„ë‹¨í•œ ë°©ë²•)
        step = int(1 / speed_factor * len(audio_data))
        if step > 0:
            speed_adjusted_data = audio_data[::int(1/speed_factor)]
        else:
            speed_adjusted_data = audio_data
        
        # ìƒˆë¡œìš´ WAV íŒŒì¼ ìƒì„±
        speed_adjusted_wav = tempfile.NamedTemporaryFile(delete=False, suffix='.wav')
        with wave.open(speed_adjusted_wav.name, 'wb') as new_wav:
            new_wav.setparams(sound_info)
            new_wav.writeframes(speed_adjusted_data.tobytes())
        speed_adjusted_wav.close()
        
        # MP3ë¡œ ë³€í™˜
        speed_adjusted_file = tempfile.NamedTemporaryFile(delete=False, suffix='.mp3')
        converted_clip = AudioFileClip(speed_adjusted_wav.name)
        converted_clip.write_audiofile(speed_adjusted_file.name, verbose=False, logger=None)
        converted_clip.close()
        speed_adjusted_file.close()
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        os.unlink(temp_wav.name)
        os.unlink(speed_adjusted_wav.name)
        
        print(f"âœ… ìƒ˜í”Œë§ ì†ë„ ì¡°ì • ì™„ë£Œ")
        return speed_adjusted_file.name
    
    def preprocess_korean_text(self, text):
        """í•œêµ­ì–´ TTS í’ˆì§ˆ í–¥ìƒì„ ìœ„í•œ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ê°„ë‹¨ ë²„ì „)"""
        try:
            import re
            processed = text.strip()
            
            # 1. ì´ëª¨ì§€ë§Œ ì œê±° (í•œê¸€ í…ìŠ¤íŠ¸ëŠ” ë³´ì¡´)
            emoji_pattern = re.compile("["
                u"\U0001F600-\U0001F64F"  # emoticons
                u"\U0001F300-\U0001F5FF"  # symbols & pictographs
                u"\U0001F680-\U0001F6FF"  # transport & map symbols
                u"\U0001F1E0-\U0001F1FF"  # flags (iOS)
                "]+", flags=re.UNICODE)
            processed = emoji_pattern.sub(' ', processed)
            
            # 2. ë¬¼ìŒí‘œ, ëŠë‚Œí‘œ, ë¬¼ê²°í‘œì‹œë¥¼ ë§ˆì¹¨í‘œë¡œ ë³€í™˜
            processed = re.sub(r'[?!~]+', '.', processed)
            
            # 3. ê³µë°± ì •ë¦¬
            processed = re.sub(r'\s+', ' ', processed).strip()
            if processed and not processed.endswith('.'):
                processed += '.'
            
            print(f"TTS ì „ì²˜ë¦¬ ì „: {text}")
            print(f"TTS ì „ì²˜ë¦¬ í›„: {processed}")
            
            return processed
            
        except Exception as e:
            print(f"í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return text  # ì‹¤íŒ¨ì‹œ ì›ë³¸ ë°˜í™˜
    
    def get_audio_duration(self, audio_path):
        """ì˜¤ë””ì˜¤ íŒŒì¼ì˜ ì‹¤ì œ ì¬ìƒ ì‹œê°„ ë°˜í™˜"""
        try:
            audio = AudioFileClip(audio_path)
            duration = audio.duration
            audio.close()
            return duration
        except Exception as e:
            print(f"ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨: {e}")
            return 3.0  # ê¸°ë³¸ê°’
    
    def get_local_images(self, test_folder="./test"):
        """test í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì´ë¦„ìˆœìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        import glob
        
        # ì´ë¯¸ì§€ í™•ì¥ì íŒ¨í„´ (webp ì¶”ê°€)
        image_patterns = ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.gif", "*.webp"]
        image_files = []
        
        for pattern in image_patterns:
            files = glob.glob(os.path.join(test_folder, pattern))
            files.extend(glob.glob(os.path.join(test_folder, pattern.upper())))
            image_files.extend(files)
        
        # ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬ (1.png, 2.png, 3.png, 4.png)
        import re
        def natural_sort_key(path):
            filename = os.path.basename(path).lower()
            # ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
            numbers = re.findall(r'\d+', filename)
            if numbers:
                return int(numbers[0])  # ì²« ë²ˆì§¸ ìˆ«ìë¡œ ì •ë ¬
            else:
                return float('inf')  # ìˆ«ìê°€ ì—†ìœ¼ë©´ ë§¨ ë’¤ë¡œ
        
        image_files.sort(key=natural_sort_key)
        
        print(f"ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {len(image_files)}ê°œ (ìˆ«ì ìˆœì„œëŒ€ë¡œ)")
        for i, file in enumerate(image_files):
            print(f"  {i+1}. {os.path.basename(file)}")
        
        if len(image_files) == 0:
            print("âŒ test í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            print(f"âœ… ì´ë¯¸ì§€ ì‚¬ìš© ìˆœì„œ: {' â†’ '.join([os.path.basename(f) for f in image_files])}")
        
        return image_files
    
    def create_video_with_local_images(self, content, music_path, output_folder, image_allocation_mode="2_per_image", text_position="bottom", text_style="outline", title_area_mode="keep", title_font="BMYEONSUNG_otf.otf", body_font="BMYEONSUNG_otf.otf", music_mood="bright", media_files=None, voice_narration="enabled", cross_dissolve="enabled"):
        """ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì‚¬ìš©í•œ ë¦´ìŠ¤ ì˜ìƒ ìƒì„±"""
        try:
            # ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ë“¤ ê°€ì ¸ì˜¤ê¸°
            local_images = self.get_local_images()

            if not local_images:
                raise Exception("test í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")

            print(f"ë¡œì»¬ ì´ë¯¸ì§€ {len(local_images)}ê°œë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ìƒì„±")

            # media_filesê°€ ì—†ëŠ” ê²½ìš° ë¡œì»¬ íŒŒì¼ë“¤ì˜ íƒ€ì… ì •ë³´ ìƒì„±
            if media_files is None:
                logging.info("ğŸ” media_filesê°€ Noneì´ë¯€ë¡œ ìë™ ìƒì„±í•©ë‹ˆë‹¤...")
                print("ğŸ” media_filesê°€ Noneì´ë¯€ë¡œ ìë™ ìƒì„±í•©ë‹ˆë‹¤...")
                media_files = []
                video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                for i, image_path in enumerate(local_images):
                    # íŒŒì¼ í™•ì¥ìë¡œ íƒ€ì… íŒë‹¨
                    is_video = any(image_path.lower().endswith(ext) for ext in video_extensions)
                    file_type = "video" if is_video else "image"
                    media_files.append((image_path, file_type))
                    msg = f"  ğŸ“ ìë™ ê°ì§€ [{i}]: {os.path.basename(image_path)} -> {file_type}"
                    print(msg)
                    logging.info(msg)
            else:
                msg = f"ğŸ” media_filesê°€ ì´ë¯¸ ì œê³µë¨: {len(media_files)}ê°œ"
                print(msg)
                logging.info(msg)

            msg = f"ğŸ’½ ìµœì¢… ë¯¸ë””ì–´ íŒŒì¼ ì •ë³´: {len(media_files)}ê°œ"
            print(msg)
            logging.info(msg)
            for i, (path, file_type) in enumerate(media_files):
                msg = f"  [{i}] {os.path.basename(path)} -> {file_type}"
                print(msg)
                logging.info(msg)
            print(f"ğŸ  íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œ: {title_area_mode}")

            # íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬
            title_image_path = None
            if title_area_mode == "keep":
                # ê¸°ì¡´ ë°©ì‹: íƒ€ì´í‹€ ì˜ì—­ ìœ ì§€ (504x220)
                title_image_path = self.create_title_image(
                    content['title'],
                    self.video_width,
                    220,
                    title_font
                )
                print("âœ… íƒ€ì´í‹€ ì˜ì—­ í™•ë³´: 220px íƒ€ì´í‹€ + 670px ë¯¸ë””ì–´")
            else:
                # remove ëª¨ë“œ: íƒ€ì´í‹€ ì œê±°, ì „ì²´ í™”ë©´ ë¯¸ë””ì–´
                print("âœ… íƒ€ì´í‹€ ì˜ì—­ ì œê±°: ì „ì²´ 890px ë¯¸ë””ì–´")
            
            # ê° bodyë³„ë¡œ ê°œë³„ TTS ìƒì„± (ë¹ˆ ê°’ ì œì™¸, ìˆœì„œ ë³´ì¥)
            body_keys = [key for key in content.keys() if key.startswith('body') and content[key].strip()]
            body_keys.sort(key=lambda x: int(x.replace('body', '')))  # body1, body2, ... ìˆœì„œë¡œ ì •ë ¬
            print(f"ğŸ¯ body ìˆœì„œ í™•ì¸: {body_keys}")
            tts_files = []
            
            for body_key in body_keys:
                print(f"ğŸ™ï¸ {body_key} TTS ìƒì„± ì¤‘... ë‚´ìš©: '{content[body_key][:50]}...'")
                body_tts = self.create_tts_audio(content[body_key])
                if body_tts:
                    body_duration = self.get_audio_duration(body_tts)
                    tts_files.append((body_key, body_tts, body_duration))
                    print(f"âœ… {body_key} TTS ì™„ë£Œ: {body_duration:.1f}ì´ˆ")
                else:
                    print(f"âŒ {body_key} TTS ìƒì„± ì‹¤íŒ¨")
            
            # ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
            print(f"ğŸ¬ ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ: {image_allocation_mode}")
            
            group_clips = []
            audio_segments = []
            
            if image_allocation_mode == "1_per_image":
                # Mode 2: body 1ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (1:1 ë§¤ì¹­)
                print("ğŸ–¼ï¸ 1:1 ë§¤ì¹­ ëª¨ë“œ: bodyë³„ë¡œ ê°ê° ë‹¤ë¥¸ ì´ë¯¸ì§€ ì‚¬ìš©")
                
                for i, body_key in enumerate(body_keys):
                    # bodyë³„ë¡œ ê°œë³„ ì´ë¯¸ì§€ í• ë‹¹ (ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ì‚¬ìš©)
                    image_index = min(i, len(local_images) - 1)
                    current_image_path = local_images[image_index]
                    print(f"ğŸ¯ ë§¤ì¹­ ë””ë²„ê·¸: i={i}, body_key={body_key}, image_index={image_index}, image={os.path.basename(current_image_path)}")
                    
                    # í•´ë‹¹ bodyì˜ TTS ì •ë³´ ì°¾ê¸°
                    body_tts_info = None
                    body_duration = 3.0
                    for tts_key, tts_path, tts_duration in tts_files:
                        if tts_key == body_key:
                            body_tts_info = (body_key, content[body_key], tts_path, tts_duration)
                            body_duration = tts_duration
                            break
                    else:
                        body_tts_info = (body_key, content[body_key], None, 3.0)
                    
                    # íŒŒì¼ íƒ€ì… í™•ì¸ (ë¹„ë””ì˜¤ vs ì´ë¯¸ì§€)
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                    is_video = any(current_image_path.lower().endswith(ext) for ext in video_extensions)
                    file_type = "ë¹„ë””ì˜¤" if is_video else "ì´ë¯¸ì§€"
                    
                    print(f"ğŸ“¸ {body_key}: {file_type} {image_index + 1}/{len(local_images)} â†’ '{os.path.basename(current_image_path)}' ({body_duration:.1f}ì´ˆ)")
                    
                    # íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œì— ë”°ë¥¸ ë°°ê²½ í´ë¦½ ìƒì„±
                    if title_area_mode == "keep":
                        # ê¸°ì¡´ ë°©ì‹: íƒ€ì´í‹€ ì˜ì—­ + ë¯¸ë””ì–´ ì˜ì—­
                        if is_video:
                            bg_clip = self.create_video_background_clip(current_image_path, body_duration)
                        else:
                            bg_clip = self.create_background_clip(current_image_path, body_duration)
                        black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(body_duration).set_position((0, 0))
                        title_clip = ImageClip(title_image_path).set_duration(body_duration).set_position((0, 0))

                        # í…ìŠ¤íŠ¸ í´ë¦½ (ê¸°ì¡´ ìœ„ì¹˜)
                        text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font)
                        text_clip = ImageClip(text_image_path).set_duration(body_duration).set_position((0, 0))

                        # ê¸°ì¡´ ë°©ì‹ í•©ì„±
                        individual_clip = CompositeVideoClip([bg_clip, black_top, title_clip, text_clip], size=(self.video_width, self.video_height))
                    else:
                        # remove ëª¨ë“œ: ì „ì²´ í™”ë©´ ë¯¸ë””ì–´ + ë™ì¼í•œ í…ìŠ¤íŠ¸ ìœ„ì¹˜
                        if is_video:
                            bg_clip = self.create_fullscreen_video_clip(current_image_path, body_duration)
                        else:
                            bg_clip = self.create_fullscreen_background_clip(current_image_path, body_duration)

                        # í…ìŠ¤íŠ¸ í´ë¦½ (ê¸°ì¡´ê³¼ ë™ì¼í•œ ìœ„ì¹˜ ìœ ì§€)
                        text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font)
                        text_clip = ImageClip(text_image_path).set_duration(body_duration).set_position((0, 0))

                        # ì „ì²´ í™”ë©´ í•©ì„± (íƒ€ì´í‹€ ì—†ìŒ)
                        individual_clip = CompositeVideoClip([bg_clip, text_clip], size=(self.video_width, self.video_height))
                    group_clips.append(individual_clip)
                    print(f"    âœ… {body_key} ì™„ë£Œ: ê°œë³„ ì´ë¯¸ì§€ ì ìš©")
                    
                    # ì˜¤ë””ì˜¤ ì¶”ê°€
                    if body_tts_info[2]:  # tts_pathê°€ ìˆìœ¼ë©´
                        audio_segments.append(AudioFileClip(body_tts_info[2]))

            elif image_allocation_mode == "2_per_image":
                # Mode 1: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (ê·¸ë£¹ ë°©ì‹)
                print("ğŸ–¼ï¸ 2:1 ë§¤ì¹­ ëª¨ë“œ: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ ì‚¬ìš©")
                
                for group_idx in range(0, len(body_keys), 2):
                    group_bodies = body_keys[group_idx:group_idx + 2]
                    # ê·¸ë£¹ ìˆœì„œëŒ€ë¡œ ì´ë¯¸ì§€ ì‚¬ìš© (body1,2 â†’ image0, body3,4 â†’ image1)
                    image_index = min(group_idx // 2, len(local_images) - 1)
                    current_image_path = local_images[image_index]
                    print(f"ê·¸ë£¹ {group_idx//2 + 1}: ì´ë¯¸ì§€ ì¸ë±ìŠ¤ {image_index}, íŒŒì¼: {os.path.basename(current_image_path)}")
                    
                    # ê·¸ë£¹ TTS ì •ë³´ ìˆ˜ì§‘
                    group_tts_info = []
                    group_total_duration = 0.0
                    
                    for body_key in group_bodies:
                        for tts_key, tts_path, tts_duration in tts_files:
                            if tts_key == body_key:
                                group_tts_info.append((body_key, content[body_key], tts_path, tts_duration))
                                group_total_duration += tts_duration
                                break
                        else:
                            group_tts_info.append((body_key, content[body_key], None, 3.0))
                            group_total_duration += 3.0
                    
                    # íŒŒì¼ íƒ€ì… í™•ì¸ (ë¹„ë””ì˜¤ vs ì´ë¯¸ì§€)
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                    is_video = any(current_image_path.lower().endswith(ext) for ext in video_extensions)
                    file_type = "ë¹„ë””ì˜¤" if is_video else "ì´ë¯¸ì§€"
                    
                    print(f"ğŸ“¸ ê·¸ë£¹ {group_idx//2 + 1}: {[info[0] for info in group_tts_info]} â†’ '{os.path.basename(current_image_path)}' ({file_type}, {group_total_duration:.1f}ì´ˆ)")
                    
                    # íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œì— ë”°ë¥¸ ë°°ê²½ í´ë¦½ ìƒì„±
                    if title_area_mode == "keep":
                        # ê¸°ì¡´ ë°©ì‹: íƒ€ì´í‹€ ì˜ì—­ + ë¯¸ë””ì–´ ì˜ì—­
                        if is_video:
                            bg_clip = self.create_video_background_clip(current_image_path, group_total_duration)
                        else:
                            bg_clip = self.create_continuous_background_clip(current_image_path, group_total_duration, 0.0)
                        black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(group_total_duration)
                        title_clip = ImageClip(title_image_path).set_duration(group_total_duration).set_position((0, 0))

                        # í…ìŠ¤íŠ¸ í´ë¦½ë“¤ (ê¸°ì¡´ ìœ„ì¹˜)
                        text_clips = []
                        current_time = 0.0
                        for body_key, body_text, tts_path, duration in group_tts_info:
                            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font)
                            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(duration).set_position((0, 0))
                            text_clips.append(text_clip)
                            print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                            current_time += duration

                        # ê¸°ì¡´ ë°©ì‹ í•©ì„±
                        group_clip = CompositeVideoClip([bg_clip, black_top, title_clip] + text_clips, size=(self.video_width, self.video_height))
                    else:
                        # remove ëª¨ë“œ: ì „ì²´ í™”ë©´ ë¯¸ë””ì–´ + ë™ì¼í•œ í…ìŠ¤íŠ¸ ìœ„ì¹˜
                        if is_video:
                            bg_clip = self.create_fullscreen_video_clip(current_image_path, group_total_duration)
                        else:
                            bg_clip = self.create_fullscreen_background_clip(current_image_path, group_total_duration)

                        # í…ìŠ¤íŠ¸ í´ë¦½ë“¤ (ê¸°ì¡´ê³¼ ë™ì¼í•œ ìœ„ì¹˜ ìœ ì§€)
                        text_clips = []
                        current_time = 0.0
                        for body_key, body_text, tts_path, duration in group_tts_info:
                            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font)
                            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(duration).set_position((0, 0))
                            text_clips.append(text_clip)
                            print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                            current_time += duration

                        # ì „ì²´ í™”ë©´ í•©ì„± (íƒ€ì´í‹€ ì—†ìŒ)
                        group_clip = CompositeVideoClip([bg_clip] + text_clips, size=(self.video_width, self.video_height))
                    group_clips.append(group_clip)
                    print(f"    âœ… ê·¸ë£¹ {group_idx//2 + 1} ì™„ë£Œ: ë°°ê²½ ì—°ì† ë³´ì¥")
                    
                    # ì˜¤ë””ì˜¤ ì¶”ê°€
                    for _, _, tts_path, _ in group_tts_info:
                        if tts_path:
                            audio_segments.append(AudioFileClip(tts_path))

            else:  # image_allocation_mode == "single_for_all"
                # Mode 3: ëª¨ë“  ëŒ€ì‚¬ì— ë¯¸ë””ì–´ 1ê°œ (ë‹¨ì¼ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ì—°ì† ì‚¬ìš©)
                print("ğŸ–¼ï¸ 1:ALL ë§¤ì¹­ ëª¨ë“œ: ëª¨ë“  ëŒ€ì‚¬ì— ë™ì¼í•œ ë¯¸ë””ì–´ 1ê°œ ì—°ì† ì‚¬ìš©")

                # ì²« ë²ˆì§¸ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ë§Œ ì‚¬ìš©
                if local_images:
                    single_media_path = local_images[0]
                    print(f"ì‚¬ìš©í•  ë¯¸ë””ì–´: {os.path.basename(single_media_path)}")

                    # ëª¨ë“  ëŒ€ì‚¬ì˜ TTS ì •ë³´ ìˆ˜ì§‘
                    all_tts_info = []
                    total_duration = 0.0

                    for body_key in body_keys:
                        for tts_key, tts_path, tts_duration in tts_files:
                            if tts_key == body_key:
                                all_tts_info.append((body_key, content[body_key], tts_path, tts_duration))
                                total_duration += tts_duration
                                break
                        else:
                            all_tts_info.append((body_key, content[body_key], None, 3.0))
                            total_duration += 3.0

                    # íŒŒì¼ íƒ€ì… í™•ì¸ (ë¹„ë””ì˜¤ vs ì´ë¯¸ì§€)
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                    is_video = any(single_media_path.lower().endswith(ext) for ext in video_extensions)
                    file_type = "ë¹„ë””ì˜¤" if is_video else "ì´ë¯¸ì§€"

                    print(f"ğŸ“ ëª¨ë“  ëŒ€ì‚¬ ({len(body_keys)}ê°œ): {file_type} ì—°ì† ì‚¬ìš© - {os.path.basename(single_media_path)} (ì´ {total_duration:.1f}ì´ˆ)")

                    # íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œì— ë”°ë¥¸ ë°°ê²½ í´ë¦½ ìƒì„±
                    if title_area_mode == "keep":
                        # ê¸°ì¡´ ë°©ì‹: íƒ€ì´í‹€ ì˜ì—­ + ë¯¸ë””ì–´ ì˜ì—­
                        if is_video:
                            bg_clip = self.create_video_background_clip(single_media_path, total_duration)
                        else:
                            bg_clip = self.create_continuous_background_clip(single_media_path, total_duration, 0.0)
                        black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(total_duration)
                        title_clip = ImageClip(title_image_path).set_duration(total_duration).set_position((0, 0))

                        # í…ìŠ¤íŠ¸ í´ë¦½ë“¤ (ê¸°ì¡´ ìœ„ì¹˜)
                        text_clips = []
                        current_time = 0.0
                        for body_key, body_text, tts_path, duration in all_tts_info:
                            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font)
                            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(duration).set_position((0, 0))
                            text_clips.append(text_clip)
                            print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                            current_time += duration

                        # ê¸°ì¡´ ë°©ì‹ í•©ì„±
                        single_clip = CompositeVideoClip([bg_clip, black_top, title_clip] + text_clips, size=(self.video_width, self.video_height))
                    else:
                        # remove ëª¨ë“œ: ì „ì²´ í™”ë©´ ë¯¸ë””ì–´ + ë™ì¼í•œ í…ìŠ¤íŠ¸ ìœ„ì¹˜
                        if is_video:
                            bg_clip = self.create_fullscreen_video_clip(single_media_path, total_duration)
                        else:
                            bg_clip = self.create_fullscreen_background_clip(single_media_path, total_duration)

                        # í…ìŠ¤íŠ¸ í´ë¦½ë“¤ (ê¸°ì¡´ê³¼ ë™ì¼í•œ ìœ„ì¹˜ ìœ ì§€)
                        text_clips = []
                        current_time = 0.0
                        for body_key, body_text, tts_path, duration in all_tts_info:
                            text_image_path = self.create_text_image(body_text, self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font)
                            text_clip = ImageClip(text_image_path).set_start(current_time).set_duration(duration).set_position((0, 0))
                            text_clips.append(text_clip)
                            print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                            current_time += duration

                        # ì „ì²´ í™”ë©´ í•©ì„± (íƒ€ì´í‹€ ì—†ìŒ)
                        single_clip = CompositeVideoClip([bg_clip] + text_clips, size=(self.video_width, self.video_height))

                    group_clips.append(single_clip)
                    print(f"    âœ… ëª¨ë“  ëŒ€ì‚¬ ì™„ë£Œ: ë‹¨ì¼ ë¯¸ë””ì–´ ì—°ì† ì ìš© ({total_duration:.1f}ì´ˆ)")

                    # ì˜¤ë””ì˜¤ ì¶”ê°€
                    for _, _, tts_path, _ in all_tts_info:
                        if tts_path:
                            audio_segments.append(AudioFileClip(tts_path))

            # ê·¸ë£¹ë“¤ ì—°ê²° (í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì˜µì…˜ì— ë”°ë¼ ì²˜ë¦¬)
            print(f"ğŸ¬ ì˜ìƒ í´ë¦½ë“¤ ì—°ê²°: {len(group_clips)}ê°œ í´ë¦½")
            if cross_dissolve == "enabled":
                print("ğŸ¨ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ íš¨ê³¼ ì ìš©")
                final_video = self.apply_smart_crossfade_transitions(group_clips, media_files, image_allocation_mode)
            else:
                print("ğŸ¬ ê¸°ë³¸ ì—°ê²° ë°©ì‹ ì‚¬ìš© (í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ë¯¸ì ìš©)")
                final_video = concatenate_videoclips(group_clips, method="compose")
            
            # 8. TTS ì˜¤ë””ì˜¤ë“¤ ì—°ê²°
            if audio_segments:
                final_audio = concatenate_audioclips(audio_segments)

                # ìë§‰ ì½ì–´ì£¼ê¸° ì„¤ì •ì— ë”°ë¥¸ TTS ë³¼ë¥¨ ì¡°ì ˆ
                if voice_narration == "disabled":
                    print("ğŸ”‡ ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: TTS ë³¼ë¥¨ì„ 0ìœ¼ë¡œ ì„¤ì •")
                    final_audio = final_audio.volumex(0)  # TTS ìŒì„± ë¬´ìŒ ì²˜ë¦¬
                
                # 9. ë°°ê²½ìŒì•… ë˜ëŠ” ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ê°€
                if music_mood == "none":
                    # ìŒì•… ì„ íƒ ì•ˆí•¨: ë¹„ë””ì˜¤ ì›ë³¸ ì†Œë¦¬ ì‚¬ìš©
                    print("ğŸ”‡ ìŒì•… ì„ íƒ ì•ˆí•¨ ëª¨ë“œ: ë¹„ë””ì˜¤ ì›ë³¸ ì†Œë¦¬ ì‚¬ìš©")
                    video_audio_segments = []

                    # ê° í´ë¦½ì—ì„œ ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì¶”ì¶œ
                    for i, group_clip in enumerate(group_clips):
                        try:
                            # ë¹„ë””ì˜¤ í´ë¦½ì— ì˜¤ë””ì˜¤ê°€ ìˆëŠ”ì§€ í™•ì¸
                            if hasattr(group_clip, 'audio') and group_clip.audio is not None:
                                video_audio = group_clip.audio
                                video_audio_segments.append(video_audio)
                                print(f"ğŸ“¹ í´ë¦½ {i+1}: ë¹„ë””ì˜¤ ì›ë³¸ ì˜¤ë””ì˜¤ ì¶”ì¶œë¨")
                            else:
                                # ì˜¤ë””ì˜¤ê°€ ì—†ëŠ” ê²½ìš° ë¬´ìŒ ì¶”ê°€
                                silent_audio = AudioFileClip(None).set_duration(group_clip.duration) if hasattr(group_clip, 'duration') else None
                                if silent_audio:
                                    video_audio_segments.append(silent_audio)
                                print(f"ğŸ“¸ í´ë¦½ {i+1}: ì´ë¯¸ì§€ - ë¬´ìŒ ì²˜ë¦¬")
                        except Exception as e:
                            print(f"âš ï¸ í´ë¦½ {i+1} ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨: {e}")

                    # ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ì™€ TTS í•©ì„±
                    if video_audio_segments:
                        combined_video_audio = concatenate_audioclips(video_audio_segments)

                        if voice_narration == "disabled":
                            # ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ 100%
                            final_audio = combined_video_audio.volumex(1.0)  # ë¹„ë””ì˜¤ ì›ë³¸ ì†Œë¦¬ 100%
                            print("ğŸ”‡ ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ 100%")
                        else:
                            # ìë§‰ ì½ì–´ì£¼ê¸° ì¶”ê°€: TTS(70%) + ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬(30%) ë¯¹ì‹±
                            final_audio = CompositeAudioClip([
                                final_audio.volumex(0.7),  # TTS ë³¼ë¥¨ 70%
                                combined_video_audio.volumex(0.3)  # ë¹„ë””ì˜¤ ì›ë³¸ ì†Œë¦¬ 30%
                            ])
                            print("ğŸµ TTS + ë¹„ë””ì˜¤ ì›ë³¸ ì˜¤ë””ì˜¤ í•©ì„± ì™„ë£Œ")
                    else:
                        if voice_narration == "disabled":
                            # ìë§‰ ì½ì–´ì£¼ê¸° ì œê±° + ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì—†ìŒ: ì™„ì „ ë¬´ìŒ
                            print("ğŸ”‡ ìë§‰ ì½ì–´ì£¼ê¸° ì œê±° + ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì—†ìŒ: ì™„ì „ ë¬´ìŒ")
                        else:
                            print("ğŸ”‡ ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì—†ìŒ: TTSë§Œ ì‚¬ìš©")

                elif music_path and os.path.exists(music_path):
                    # ë°°ê²½ìŒì•… ì‚¬ìš©
                    background_music = AudioFileClip(music_path)

                    # ë°°ê²½ìŒì•…ì´ ì˜ìƒë³´ë‹¤ ì§§ìœ¼ë©´ ë°˜ë³µ, ê¸¸ë©´ ìë¥´ê¸°
                    if background_music.duration < final_audio.duration:
                        background_music = background_music.loop(duration=final_audio.duration)
                    else:
                        background_music = background_music.subclip(0, final_audio.duration)

                    if voice_narration == "disabled":
                        # ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: ë°°ê²½ìŒì•… 100%
                        final_audio = background_music.volumex(1.0)  # ë°°ê²½ìŒì•… ë³¼ë¥¨ 100%
                        print("ğŸ”‡ ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: ë°°ê²½ìŒì•… 100%")
                    else:
                        # ìë§‰ ì½ì–´ì£¼ê¸° ì¶”ê°€: TTS + ë°°ê²½ìŒì•… í•©ì„±
                        background_music = background_music.volumex(0.17)  # ë³¼ë¥¨ 17%
                        final_audio = CompositeAudioClip([final_audio, background_music])
                        print("ğŸµ TTS + ë°°ê²½ìŒì•… í•©ì„± ì™„ë£Œ")

                final_video = final_video.set_audio(final_audio)
            
            # 10. ìµœì¢… ì˜ìƒ ì €ì¥
            video_id = str(uuid.uuid4())[:8]
            output_filename = f"reels_{video_id}.mp4"
            output_path = os.path.join(output_folder, output_filename)
            
            print(f"ìµœì¢… ì˜ìƒ ë Œë”ë§ ì‹œì‘: {output_path}")
            final_video.write_videofile(
                output_path,
                fps=self.fps,
                codec='libx264',
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True
            )
            
            print(f"ì˜ìƒ ìƒì„± ì™„ë£Œ: {output_path}")
            return output_path
            
        except Exception as e:
            raise Exception(f"ë¡œì»¬ ì´ë¯¸ì§€ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def create_video(self, content, image_urls, music_path, output_folder, image_allocation_mode="2_per_image", text_position="bottom", text_style="outline"):
        """ë¦´ìŠ¤ ì˜ìƒ ìƒì„± (414x896 í•´ìƒë„, ì—¬ëŸ¬ ì´ë¯¸ì§€ ì§€ì›)"""
        try:
            # ì—¬ëŸ¬ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            image_paths = []
            for i, image_url in enumerate(image_urls):
                print(f"ì´ë¯¸ì§€ {i+1}/{len(image_urls)} ë‹¤ìš´ë¡œë“œ ì¤‘: {image_url}")
                image_path = self.download_image(image_url)
                image_paths.append(image_path)
            
            # ì œëª© ì´ë¯¸ì§€ ìƒì„± (504x220, ì •í™•í•œ íƒ€ì´í‹€ ì˜ì—­)
            title_image_path = self.create_title_image(
                content['title'],
                self.video_width,
                220,
                title_font
            )
            
            # ê° bodyë³„ë¡œ ê°œë³„ TTS ìƒì„± (ë¹ˆ ê°’ ì œì™¸, ìˆœì„œ ë³´ì¥)
            body_keys = [key for key in content.keys() if key.startswith('body') and content[key].strip()]
            body_keys.sort(key=lambda x: int(x.replace('body', '')))  # body1, body2, ... ìˆœì„œë¡œ ì •ë ¬
            print(f"ğŸ¯ body ìˆœì„œ í™•ì¸: {body_keys}")
            tts_files = []
            
            # ì œëª© TTS ìƒì„±
            print("ì œëª© TTS ìƒì„± ì¤‘...")
            title_tts = self.create_tts_audio(content['title'])
            if title_tts:
                title_duration = self.get_audio_duration(title_tts)
                tts_files.append(('title', title_tts, title_duration))
                print(f"ì œëª© TTS ì™„ë£Œ: {title_duration:.1f}ì´ˆ")
            
            # ê° body TTS ìƒì„±
            for body_key in body_keys:
                print(f"ğŸ™ï¸ {body_key} TTS ìƒì„± ì¤‘... ë‚´ìš©: '{content[body_key][:50]}...'")
                body_tts = self.create_tts_audio(content[body_key])
                if body_tts:
                    body_duration = self.get_audio_duration(body_tts)
                    tts_files.append((body_key, body_tts, body_duration))
                    print(f"âœ… {body_key} TTS ì™„ë£Œ: {body_duration:.1f}ì´ˆ")
                else:
                    print(f"âŒ {body_key} TTS ìƒì„± ì‹¤íŒ¨")
            
            # ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬ ë¶„ê¸°
            print(f"ğŸ¬ ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ: {image_allocation_mode}")
            body_clips = []
            audio_segments = []  # TTS ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë“¤
            
            if image_allocation_mode == "1_per_image":
                # Mode 2: body 1ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (1:1 ë§¤ì¹­)
                print("ğŸ–¼ï¸ 1:1 ë§¤ì¹­ ëª¨ë“œ: bodyë³„ë¡œ ê°ê° ë‹¤ë¥¸ ì´ë¯¸ì§€ ì‚¬ìš©")

                for i, body_key in enumerate(body_keys):
                    print(f"ğŸ¯ ë””ë²„ê·¸ 2: i={i}, body_key={body_key} (create_video_with_local_images)")
                    # í•´ë‹¹ bodyì˜ TTS ì •ë³´ ì°¾ê¸°
                    body_tts_info = None
                    for tts_key, tts_path, tts_duration in tts_files:
                        if tts_key == body_key:
                            body_tts_info = (tts_path, tts_duration)
                            break
                    
                    if not body_tts_info:
                        print(f"{body_key}ì˜ TTSë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œê°„ ì‚¬ìš©.")
                        clip_duration = 3.0
                        tts_path = None
                    else:
                        tts_path, clip_duration = body_tts_info
                    
                    # bodyë³„ë¡œ ê°œë³„ ì´ë¯¸ì§€ í• ë‹¹ (ì´ë¯¸ì§€ê°€ ë¶€ì¡±í•˜ë©´ ë§ˆì§€ë§‰ ì´ë¯¸ì§€ ì‚¬ìš©)
                    image_index = min(i, len(image_paths) - 1)  # body1 â†’ image0, body2 â†’ image1, body3 â†’ image2
                    current_image_path = image_paths[image_index]
                    
                    print(f"{body_key} í´ë¦½ ìƒì„±: {clip_duration:.1f}ì´ˆ, ì´ë¯¸ì§€: {image_index + 1}/{len(image_paths)} (1:1 ë§¤ì¹­)")
                    
                    # ê°œë³„ body í´ë¦½ ìƒì„±
                    bg_clip = self.create_background_clip(current_image_path, clip_duration)
                    black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(clip_duration).set_position((0, 0))
                    title_clip = ImageClip(title_image_path).set_duration(clip_duration).set_position((0, 0))

                    text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font)
                    text_clip = ImageClip(text_image_path).set_duration(clip_duration).set_position((0, 0))
                    
                    # ê°œë³„ í´ë¦½ í•©ì„±
                    combined_clip = CompositeVideoClip([bg_clip, black_top, title_clip, text_clip], size=(self.video_width, self.video_height))
                    body_clips.append(combined_clip)
                    
                    # ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
                    if tts_path and os.path.exists(tts_path):
                        body_audio = AudioFileClip(tts_path)
                        audio_segments.append(body_audio)
                        print(f"{body_key} ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€")
                        
            elif image_allocation_mode == "2_per_image":
                # Mode 1: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ (ê·¸ë£¹ ë°©ì‹)
                print("ğŸ–¼ï¸ 2:1 ë§¤ì¹­ ëª¨ë“œ: body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ ì‚¬ìš©")

                for i, body_key in enumerate(body_keys):
                    print(f"ğŸ¯ ë””ë²„ê·¸ 3: i={i}, body_key={body_key} (2_per_image mode)")
                    # í•´ë‹¹ bodyì˜ TTS ì •ë³´ ì°¾ê¸°
                    body_tts_info = None
                    for tts_key, tts_path, tts_duration in tts_files:
                        if tts_key == body_key:
                            body_tts_info = (tts_path, tts_duration)
                            break
                    
                    if not body_tts_info:
                        print(f"{body_key}ì˜ TTSë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œê°„ ì‚¬ìš©.")
                        clip_duration = 3.0
                        tts_path = None
                    else:
                        tts_path, clip_duration = body_tts_info
                    
                    # body 2ê°œë‹¹ ì´ë¯¸ì§€ 1ê°œ í• ë‹¹ (body1,2 â†’ image0, body3,4 â†’ image1)
                    image_index = min(i // 2, len(image_paths) - 1)
                    current_image_path = image_paths[image_index]
                    
                    print(f"{body_key} í´ë¦½ ìƒì„±: {clip_duration:.1f}ì´ˆ, ì´ë¯¸ì§€: {image_index + 1}/{len(image_paths)} (2:1 ë§¤ì¹­)")
                    
                    # ê¸°ì¡´ ë°©ì‹ëŒ€ë¡œ í´ë¦½ ìƒì„±
                    bg_clip = self.create_background_clip(current_image_path, clip_duration)
                    black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(clip_duration).set_position((0, 0))
                    title_clip = ImageClip(title_image_path).set_duration(clip_duration).set_position((0, 0))

                    text_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height, text_position, text_style, is_title=False, title_font=title_font, body_font=body_font)
                    text_clip = ImageClip(text_image_path).set_duration(clip_duration).set_position((0, 0))
                    
                    # í´ë¦½ í•©ì„±
                    combined_clip = CompositeVideoClip([bg_clip, black_top, title_clip, text_clip], size=(self.video_width, self.video_height))
                    body_clips.append(combined_clip)
                    
                    # ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
                    if tts_path and os.path.exists(tts_path):
                        body_audio = AudioFileClip(tts_path)
                        audio_segments.append(body_audio)
                        print(f"{body_key} ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€")

            else:  # image_allocation_mode == "single_for_all"
                # Mode 3: ëª¨ë“  ëŒ€ì‚¬ì— ë¯¸ë””ì–´ 1ê°œ (ë‹¨ì¼ ì´ë¯¸ì§€ ì—°ì† ì‚¬ìš©)
                print("ğŸ–¼ï¸ 1:ALL ë§¤ì¹­ ëª¨ë“œ: ëª¨ë“  ëŒ€ì‚¬ì— ë™ì¼í•œ ì´ë¯¸ì§€ 1ê°œ ì—°ì† ì‚¬ìš©")

                # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ë§Œ ì‚¬ìš©
                if image_paths:
                    single_image_path = image_paths[0]
                    print(f"ì‚¬ìš©í•  ì´ë¯¸ì§€: {single_image_path}")

                    # ëª¨ë“  ëŒ€ì‚¬ì˜ TTS ì •ë³´ ìˆ˜ì§‘
                    all_tts_info = []
                    total_duration = 0.0

                    for body_key in body_keys:
                        body_tts_info = None
                        for tts_key, tts_path, tts_duration in tts_files:
                            if tts_key == body_key:
                                body_tts_info = (tts_path, tts_duration)
                                break

                        if not body_tts_info:
                            print(f"{body_key}ì˜ TTSë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ ì‹œê°„ ì‚¬ìš©.")
                            all_tts_info.append((body_key, None, 3.0))
                            total_duration += 3.0
                        else:
                            tts_path, clip_duration = body_tts_info
                            all_tts_info.append((body_key, tts_path, clip_duration))
                            total_duration += clip_duration

                    print(f"ğŸ“ ëª¨ë“  ëŒ€ì‚¬ ({len(body_keys)}ê°œ): ì´ë¯¸ì§€ ì—°ì† ì‚¬ìš© - {single_image_path} (ì´ {total_duration:.1f}ì´ˆ)")

                    # ì—°ì†ëœ ë°°ê²½ í´ë¦½ ìƒì„±
                    bg_clip = self.create_continuous_background_clip(single_image_path, total_duration, 0.0)
                    black_top = ColorClip(size=(self.video_width, 220), color=(0,0,0)).set_duration(total_duration)

                    # íƒ€ì´í‹€ í´ë¦½ ìƒì„±
                    title_image_path = self.create_text_image(content['title'], self.video_width, 220, text_position, text_style, title_font)
                    title_clip = ImageClip(title_image_path).set_duration(total_duration).set_position((0, 0))

                    # í…ìŠ¤íŠ¸ í´ë¦½ë“¤ ìƒì„± (ì‹œê°„ì— ë”°ë¼ ìˆœì°¨ í‘œì‹œ)
                    text_clips = []
                    current_time = 0.0
                    for body_key, tts_path, duration in all_tts_info:
                        body_image_path = self.create_text_image(content[body_key], self.video_width, self.video_height, text_position, text_style, body_font)
                        text_clip = ImageClip(body_image_path).set_start(current_time).set_duration(duration).set_position((0, 0))
                        text_clips.append(text_clip)
                        print(f"      {body_key}: {current_time:.1f}~{current_time + duration:.1f}ì´ˆ")
                        current_time += duration

                    # í•˜ë‚˜ì˜ ì—°ì†ëœ í´ë¦½ìœ¼ë¡œ í•©ì„±
                    single_continuous_clip = CompositeVideoClip([bg_clip, black_top, title_clip] + text_clips, size=(self.video_width, self.video_height))
                    body_clips.append(single_continuous_clip)

                    # ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€
                    for body_key, tts_path, duration in all_tts_info:
                        if tts_path and os.path.exists(tts_path):
                            body_audio = AudioFileClip(tts_path)
                            audio_segments.append(body_audio)
                            print(f"{body_key} ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ì¶”ê°€")

                    print(f"    âœ… ëª¨ë“  ëŒ€ì‚¬ ì™„ë£Œ: ë‹¨ì¼ ì´ë¯¸ì§€ ì—°ì† ì ìš© ({total_duration:.1f}ì´ˆ)")

            # ì „ì²´ ì˜ìƒ ì—°ê²° (í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì˜µì…˜ì— ë”°ë¼ ì²˜ë¦¬)
            print(f"ğŸ¬ ë³¸ë¬¸ í´ë¦½ë“¤ ì—°ê²°: {len(body_clips)}ê°œ í´ë¦½")
            if cross_dissolve == "enabled":
                print("ğŸ¨ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ íš¨ê³¼ ì ìš©")
                final_video = self.apply_smart_crossfade_transitions(body_clips, media_files, image_allocation_mode)
            else:
                print("ğŸ¬ ê¸°ë³¸ ì—°ê²° ë°©ì‹ ì‚¬ìš© (í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ë¯¸ì ìš©)")
                final_video = concatenate_videoclips(body_clips, method="compose")
            print(f"ìµœì¢… ë¹„ë””ì˜¤ ê¸¸ì´: {final_video.duration:.1f}ì´ˆ")
            
            # TTS ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì„ ìˆœì„œëŒ€ë¡œ ì—°ê²°
            if audio_segments:
                print(f"TTS ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ ê°œìˆ˜: {len(audio_segments)}")
                combined_tts = concatenate_audioclips(audio_segments)
                print(f"ê²°í•©ëœ TTS ê¸¸ì´: {combined_tts.duration:.1f}ì´ˆ")

                # ìë§‰ ì½ì–´ì£¼ê¸° ì„¤ì •ì— ë”°ë¥¸ TTS ë³¼ë¥¨ ì¡°ì ˆ
                if voice_narration == "disabled":
                    print("ğŸ”‡ ìë§‰ ì½ì–´ì£¼ê¸° ì œê±°: TTS ë³¼ë¥¨ì„ 0ìœ¼ë¡œ ì„¤ì •")
                    combined_tts = combined_tts.volumex(0)  # TTS ìŒì„± ë¬´ìŒ ì²˜ë¦¬

                # ë°°ê²½ìŒì•… ë˜ëŠ” ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ê°€
                audio_tracks = [combined_tts]

                if music_mood == "none":
                    print("ìŒì•… ì„ íƒ ì•ˆí•¨ - ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ì¶œ ë° ì¶”ê°€ ì¤‘...")
                    # ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ì¶œ
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                    if media_files:
                        for media_file in media_files:
                            media_path, file_type = media_file
                            if file_type == "video" and any(media_path.lower().endswith(ext) for ext in video_extensions):
                                try:
                                    video_audio = VideoFileClip(media_path).audio
                                    if video_audio is not None:
                                        # ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ê¸¸ì´ë¥¼ TTSì— ë§ì¶¤
                                        if video_audio.duration < combined_tts.duration:
                                            video_audio = video_audio.loop(duration=combined_tts.duration)
                                        else:
                                            video_audio = video_audio.subclip(0, combined_tts.duration)
                                        # ìë§‰ ì½ì–´ì£¼ê¸° ì„¤ì •ì— ë”°ë¥¸ ë¹„ë””ì˜¤ ë³¼ë¥¨ ì¡°ì ˆ
                                        if voice_narration == "disabled":
                                            # TTS ìŒì„±ì´ êº¼ì§„ ê²½ìš° ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ë¥¼ 100%ë¡œ ì„¤ì •
                                            video_audio = video_audio.volumex(1.0)
                                            print("ğŸ”Š ìë§‰ ì½ì–´ì£¼ê¸° êº¼ì§ - ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ 100%")
                                        else:
                                            # TTSì™€ ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•´ 50% ë³¼ë¥¨ìœ¼ë¡œ ì„¤ì •
                                            video_audio = video_audio.volumex(0.5)
                                            print("ğŸ”Š ìë§‰ ì½ì–´ì£¼ê¸° ì¼œì§ - ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ 50%")
                                        audio_tracks.append(video_audio)
                                        print(f"ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ê°€: {media_path}")
                                        break  # ì²« ë²ˆì§¸ ë¹„ë””ì˜¤ì˜ ì†Œë¦¬ë§Œ ì‚¬ìš©
                                except Exception as e:
                                    print(f"ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨ ({media_path}): {e}")
                                    continue
                    else:
                        print("âš ï¸ ë¯¸ë””ì–´ íŒŒì¼ ì •ë³´ ì—†ìŒ - ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì‚¬ìš© ë¶ˆê°€")
                elif os.path.exists(music_path):
                    print("ë°°ê²½ìŒì•… ì¶”ê°€ ì¤‘...")
                    # ìë§‰ ì½ì–´ì£¼ê¸° ì„¤ì •ì— ë”°ë¥¸ ë°°ê²½ìŒì•… ë³¼ë¥¨ ì¡°ì ˆ
                    if voice_narration == "disabled":
                        # TTS ìŒì„±ì´ êº¼ì§„ ê²½ìš° ë°°ê²½ìŒì•…ì„ 100%ë¡œ ì„¤ì •
                        bg_music = AudioFileClip(music_path).volumex(1.0)
                        print("ğŸµ ìë§‰ ì½ì–´ì£¼ê¸° êº¼ì§ - ë°°ê²½ìŒì•… 100%")
                    else:
                        # TTSê°€ ë” ì˜ ë“¤ë¦¬ë„ë¡ 17%ë¡œ ë‚®ì¶¤
                        bg_music = AudioFileClip(music_path).volumex(0.17)
                        print("ğŸµ ìë§‰ ì½ì–´ì£¼ê¸° ì¼œì§ - ë°°ê²½ìŒì•… 17%")
                    if bg_music.duration < combined_tts.duration:
                        bg_music = bg_music.loop(duration=combined_tts.duration)
                    else:
                        bg_music = bg_music.subclip(0, combined_tts.duration)
                    audio_tracks.append(bg_music)
                
                # ì˜¤ë””ì˜¤ í•©ì„±
                if len(audio_tracks) > 1:
                    print("TTS + ë°°ê²½ìŒì•… í•©ì„± ì¤‘...")
                    final_audio = CompositeAudioClip(audio_tracks)
                else:
                    print("TTSë§Œ ì‚¬ìš©")
                    final_audio = audio_tracks[0]
                
                final_video = final_video.set_audio(final_audio)
                print("ìµœì¢… ë¹„ë””ì˜¤ì— ì˜¤ë””ì˜¤ ì¶”ê°€ ì™„ë£Œ")
                
            else:
                print("TTS ì˜¤ë””ì˜¤ê°€ ì—†ì–´ì„œ ë°°ê²½ìŒì•… ë˜ëŠ” ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ë§Œ ì‚¬ìš©")
                if music_mood == "none":
                    print("ìŒì•… ì„ íƒ ì•ˆí•¨ - ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ë§Œ ì‚¬ìš©")
                    # ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì¶”ì¶œ
                    video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
                    if media_files:
                        for media_file in media_files:
                            media_path, file_type = media_file
                            if file_type == "video" and any(media_path.lower().endswith(ext) for ext in video_extensions):
                                try:
                                    video_audio = VideoFileClip(media_path).audio
                                    if video_audio is not None:
                                        if video_audio.duration > final_video.duration:
                                            video_audio = video_audio.subclip(0, final_video.duration)
                                        final_video = final_video.set_audio(video_audio)
                                        print(f"ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì ìš©: {media_path}")
                                        break
                                except Exception as e:
                                    print(f"ë¹„ë””ì˜¤ ì˜¤ë””ì˜¤ ì¶”ì¶œ ì‹¤íŒ¨ ({media_path}): {e}")
                                    continue
                    else:
                        print("âš ï¸ ë¯¸ë””ì–´ íŒŒì¼ ì •ë³´ ì—†ìŒ - ì›ë³¸ ë¹„ë””ì˜¤ ì†Œë¦¬ ì‚¬ìš© ë¶ˆê°€")
                elif os.path.exists(music_path):
                    bg_music = AudioFileClip(music_path)
                    if bg_music.duration > final_video.duration:
                        bg_music = bg_music.subclip(0, final_video.duration)
                    final_video = final_video.set_audio(bg_music)
            
            # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ìƒì„±
            output_filename = f"reels_{uuid.uuid4().hex[:8]}.mp4"
            output_path = os.path.join(output_folder, output_filename)
            
            # ì˜ìƒ ë Œë”ë§ (ì´ë¯¸ 414x896ìœ¼ë¡œ êµ¬ì„±ë¨)
            final_video.write_videofile(
                output_path,
                fps=self.fps,
                codec='libx264',
                audio_codec='aac',
                temp_audiofile='temp-audio.m4a',
                remove_temp=True
            )
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if os.path.exists(image_path):
                os.unlink(image_path)
            if os.path.exists(title_image_path):
                os.unlink(title_image_path)
            
            # ëª¨ë“  TTS íŒŒì¼ ì •ë¦¬
            for tts_key, tts_path, tts_duration in tts_files:
                if os.path.exists(tts_path):
                    os.unlink(tts_path)
                    print(f"{tts_key} TTS íŒŒì¼ ì •ë¦¬: {tts_path}")
            
            return output_path
            
        except Exception as e:
            raise Exception(f"Video generation failed: {str(e)}")
    
    def scan_uploads_folder(self, uploads_folder="uploads"):
        """uploads í´ë”ë¥¼ ìŠ¤ìº”í•˜ì—¬ íŒŒì¼ë“¤ì„ ì°¾ê³  ë¶„ë¥˜"""
        scan_result = {
            'json_file': None,
            'image_files': [],  # í˜¸í™˜ì„± ìœ ì§€
            'media_files': []   # ìƒˆë¡œìš´ ë¯¸ë””ì–´ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
        }
        
        if not os.path.exists(uploads_folder):
            print(f"âŒ {uploads_folder} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
            return scan_result
        
        # JSON íŒŒì¼ ì°¾ê¸° (text.json)
        json_path = os.path.join(uploads_folder, "text.json")
        if os.path.exists(json_path):
            scan_result['json_file'] = json_path
            print(f"âœ… JSON íŒŒì¼ ë°œê²¬: {json_path}")
        
        # ìŒì•… íŒŒì¼ì€ ë” ì´ìƒ uploadsì—ì„œ ì°¾ì§€ ì•ŠìŒ (bgm í´ë” ì§ì ‘ ì‚¬ìš©)
        
        # ë¯¸ë””ì–´ íŒŒì¼ë“¤ ì°¾ê¸° (ì´ë¯¸ì§€ + ë¹„ë””ì˜¤)
        image_extensions = ['.png', '.jpg', '.jpeg', '.gif', '.webp', '.bmp']
        video_extensions = ['.mp4', '.mov', '.avi', '.webm', '.mkv']
        all_extensions = image_extensions + video_extensions
        
        # ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ë¯¸ë””ì–´ íŒŒì¼ë“¤ì„ ì°¾ì•„ì„œ ì •ë ¬
        media_files = []
        image_files = []  # í˜¸í™˜ì„±ì„ ìœ„í•œ ê¸°ì¡´ ì´ë¯¸ì§€ íŒŒì¼ ë¦¬ìŠ¤íŠ¸
        
        for filename in os.listdir(uploads_folder):
            if any(filename.lower().endswith(ext) for ext in all_extensions):
                # íŒŒì¼ëª…ì´ ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸
                name_without_ext = os.path.splitext(filename)[0]
                if name_without_ext.isdigit():
                    file_number = int(name_without_ext)
                    full_path = os.path.join(uploads_folder, filename)
                    
                    # íŒŒì¼ íƒ€ì… ê²°ì •
                    is_video = any(filename.lower().endswith(ext) for ext in video_extensions)
                    file_type = "video" if is_video else "image"
                    
                    media_files.append((file_number, full_path, file_type))
                    
                    # í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ image_filesì—ë„ ì¶”ê°€
                    image_files.append((file_number, full_path))
        
        # ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬
        media_files.sort(key=lambda x: x[0])
        image_files.sort(key=lambda x: x[0])
        
        # ê²°ê³¼ ì €ì¥
        scan_result['media_files'] = [(path, file_type) for _, path, file_type in media_files]
        scan_result['image_files'] = [path for _, path in image_files]  # í˜¸í™˜ì„± ìœ ì§€
        
        print(f"ğŸ“Š ë¯¸ë””ì–´ íŒŒì¼ {len(scan_result['media_files'])}ê°œ ë°œê²¬:")
        for i, (media_path, file_type) in enumerate(scan_result['media_files'], 1):
            print(f"   {i}. {os.path.basename(media_path)} ({file_type})")
        
        return scan_result
    
    def create_video_from_uploads(self, output_folder, bgm_file_path=None, image_allocation_mode="2_per_image", text_position="bottom", text_style="outline", title_area_mode="keep", title_font="BMYEONSUNG_otf.otf", body_font="BMYEONSUNG_otf.otf", uploads_folder="uploads", music_mood="bright", voice_narration="enabled", cross_dissolve="enabled"):
        """uploads í´ë”ì˜ íŒŒì¼ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì˜ìƒ ìƒì„± (ê¸°ì¡´ ë©”ì„œë“œ ì¬ì‚¬ìš©)"""
        try:
            print("ğŸš€ uploads í´ë” ê¸°ë°˜ ì˜ìƒ ìƒì„± ì‹œì‘")
            
            # uploads í´ë” ìŠ¤ìº”
            scan_result = self.scan_uploads_folder(uploads_folder)
            
            # í•„ìˆ˜ íŒŒì¼ ê²€ì¦
            if not scan_result['json_file']:
                raise Exception("text.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            
            if not scan_result['image_files']:
                raise Exception("ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            
            # JSON ë‚´ìš© ë¡œë“œ
            with open(scan_result['json_file'], 'r', encoding='utf-8') as f:
                content = json.load(f)
            print(f"âœ… JSON ë‚´ìš© ë¡œë“œ: {scan_result['json_file']}")
            
            # ìŒì•… íŒŒì¼ ì„¤ì • (bgm_file_path ì§ì ‘ ì‚¬ìš©)
            music_path = bgm_file_path or ""
            if music_path and os.path.exists(music_path):
                print(f"âœ… ìŒì•… íŒŒì¼ ì‚¬ìš©: {music_path}")
            else:
                print("âš ï¸  ìŒì•… íŒŒì¼ ì—†ìŒ - ìŒì„±ë§Œ ì‚¬ìš©")
                music_path = ""
            
            # ê¸°ì¡´ create_video_with_local_images ë°©ì‹ ì¬ì‚¬ìš©
            # ìŠ¤ìº”ëœ ì´ë¯¸ì§€ íŒŒì¼ë“¤ë¡œ ë¡œì»¬ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ ëŒ€ì²´
            self._temp_local_images = scan_result['image_files']
            
            # ê¸°ì¡´ ë©”ì„œë“œ í˜¸ì¶œ (ì´ë¯¸ì§€ í• ë‹¹ ëª¨ë“œ, í…ìŠ¤íŠ¸ ìœ„ì¹˜, í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼, íƒ€ì´í‹€ ì˜ì—­ ëª¨ë“œ, í°íŠ¸ ì„¤ì •, ìë§‰ ì½ì–´ì£¼ê¸° ì „ë‹¬)
            return self.create_video_with_local_images(content, music_path, output_folder, image_allocation_mode, text_position, text_style, title_area_mode, title_font, body_font, music_mood, scan_result['media_files'], voice_narration, cross_dissolve)
            
        except Exception as e:
            raise Exception(f"uploads í´ë” ê¸°ë°˜ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {str(e)}")
    
    def get_local_images(self, test_folder="./test"):
        """test í´ë”ì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì´ë¦„ìˆœìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°"""
        # uploads í´ë” ì‚¬ìš© ì‹œ ì„ì‹œ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©
        if hasattr(self, '_temp_local_images') and self._temp_local_images:
            images = self._temp_local_images
            self._temp_local_images = None  # ì‚¬ìš© í›„ ì •ë¦¬
            print(f"ì—…ë¡œë“œ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {len(images)}ê°œ (ìˆœì„œëŒ€ë¡œ)")
            for i, file in enumerate(images):
                print(f"  {i+1}. {os.path.basename(file)}")
            return images
        
        # ê¸°ì¡´ test í´ë” ë¡œì§
        import glob
        
        # ì´ë¯¸ì§€ í™•ì¥ì íŒ¨í„´ (webp ì¶”ê°€)
        image_patterns = ["*.jpg", "*.jpeg", "*.png", "*.bmp", "*.gif", "*.webp"]
        image_files = []
        
        for pattern in image_patterns:
            files = glob.glob(os.path.join(test_folder, pattern))
            files.extend(glob.glob(os.path.join(test_folder, pattern.upper())))
            image_files.extend(files)
        
        # ìˆ«ì ìˆœì„œëŒ€ë¡œ ì •ë ¬ (1.png, 2.png, 3.png, 4.png)
        import re
        def natural_sort_key(path):
            filename = os.path.basename(path).lower()
            # ìˆ«ì ë¶€ë¶„ ì¶”ì¶œ
            numbers = re.findall(r'\d+', filename)
            if numbers:
                return int(numbers[0])  # ì²« ë²ˆì§¸ ìˆ«ìë¡œ ì •ë ¬
            else:
                return float('inf')  # ìˆ«ìê°€ ì—†ìœ¼ë©´ ë§¨ ë’¤ë¡œ
        
        image_files.sort(key=natural_sort_key)
        
        print(f"ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ë°œê²¬: {len(image_files)}ê°œ (ìˆ«ì ìˆœì„œëŒ€ë¡œ)")
        for i, file in enumerate(image_files):
            print(f"  {i+1}. {os.path.basename(file)}")
        
        if len(image_files) == 0:
            print("âŒ test í´ë”ì— ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
        else:
            print(f"âœ… ì´ë¯¸ì§€ ì‚¬ìš© ìˆœì„œ: {' â†’ '.join([os.path.basename(f) for f in image_files])}")
        
        return image_files
    def create_fullscreen_background_clip(self, image_path, duration):
        """ì „ì²´ í™”ë©´(504x890)ìš© ì´ë¯¸ì§€ ë°°ê²½ í´ë¦½ ìƒì„±"""
        print(f"ğŸ–¼ï¸ ì „ì²´ í™”ë©´ ì´ë¯¸ì§€ í´ë¦½ ìƒì„±: {os.path.basename(image_path)}")

        try:
            # ì´ë¯¸ì§€ ë¡œë“œ ë° í¬ê¸° í™•ì¸
            img = Image.open(image_path)
            orig_width, orig_height = img.size
            print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€: {orig_width}x{orig_height}")

            # ì‘ì—… ì˜ì—­: ì „ì²´ í™”ë©´ 504x890
            work_width = self.video_width
            work_height = self.video_height
            work_aspect_ratio = work_width / work_height
            image_aspect_ratio = orig_width / orig_height

            print(f"ğŸ¯ ëª©í‘œ: ì „ì²´ í™”ë©´ {work_width}x{work_height}")

            # ì¢…íš¡ë¹„ ê¸°ë°˜ ì§€ëŠ¥í˜• ë°°ì¹˜
            if image_aspect_ratio > work_aspect_ratio:
                # ê°€ë¡œí˜•: ë†’ì´ ë§ì¶¤ í›„ ì¢Œìš° íŒ¨ë‹
                resized_height = work_height
                resized_width = int(orig_width * resized_height / orig_height)
                print(f"ğŸ”³ ê°€ë¡œí˜• ì´ë¯¸ì§€: ë†’ì´ ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ {resized_width}x{resized_height}")

                # ì¢Œìš° íŒ¨ë‹ ë²”ìœ„
                pan_range = min(60, (resized_width - work_width) // 2)
            else:
                # ì„¸ë¡œí˜•: í­ ë§ì¶¤ í›„ ìƒí•˜ íŒ¨ë‹
                resized_width = work_width
                resized_height = int(orig_height * resized_width / orig_width)
                print(f"ğŸ”³ ì„¸ë¡œí˜• ì´ë¯¸ì§€: í­ ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ {resized_width}x{resized_height}")

                # ìƒí•˜ íŒ¨ë‹ ë²”ìœ„
                pan_range = min(60, (resized_height - work_height) // 2)

            # MoviePy ì´ë¯¸ì§€ í´ë¦½ ìƒì„±
            clip = ImageClip(image_path).set_duration(duration)
            clip = clip.resize((resized_width, resized_height))

            # íŒ¨ë‹ ì• ë‹ˆë©”ì´ì…˜ (4íŒ¨í„´ ëœë¤)
            patterns = [1, 2, 3, 4]
            pattern = random.choice(patterns)

            if image_aspect_ratio > work_aspect_ratio:
                # ê°€ë¡œí˜• íŒ¨ë‹ (ì¢Œìš°)
                if pattern in [1, 3]:
                    # ì¢Œ â†’ ìš°
                    print(f"ğŸ¬ íŒ¨í„´ {pattern}: ì¢Œ â†’ ìš° íŒ¨ë‹ (duration: {duration:.1f}s)")
                    start_x = -pan_range
                    end_x = pan_range
                else:
                    # ìš° â†’ ì¢Œ
                    print(f"ğŸ¬ íŒ¨í„´ {pattern}: ìš° â†’ ì¢Œ íŒ¨ë‹ (duration: {duration:.1f}s)")
                    start_x = pan_range
                    end_x = -pan_range

                start_y = (work_height - resized_height) // 2
                end_y = start_y
            else:
                # ì„¸ë¡œí˜• íŒ¨ë‹ (ìƒí•˜)
                if pattern in [1, 3]:
                    # ìƒ â†’ í•˜
                    print(f"ğŸ¬ íŒ¨í„´ {pattern}: ìƒ â†’ í•˜ íŒ¨ë‹ (duration: {duration:.1f}s)")
                    start_y = -pan_range
                    end_y = pan_range
                else:
                    # í•˜ â†’ ìƒ
                    print(f"ğŸ¬ íŒ¨í„´ {pattern}: í•˜ â†’ ìƒ íŒ¨ë‹ (duration: {duration:.1f}s)")
                    start_y = pan_range
                    end_y = -pan_range

                start_x = (work_width - resized_width) // 2
                end_x = start_x

            # Linear ì´ì§•ìœ¼ë¡œ íŒ¨ë‹ ì ìš©
            def pos_func(t):
                progress = t / duration if duration > 0 else 0
                x = start_x + (end_x - start_x) * progress
                y = start_y + (end_y - start_y) * progress
                return (x, y)

            clip = clip.set_position(pos_func)

            print(f"ğŸ¯ Linear ì´ì§• ì ìš©: ì¼ì •í•œ ì†ë„ë¡œ ëª…í™•í•œ ì›€ì§ì„")
            print(f"ğŸ“ íŒ¨ë‹ ë²”ìœ„: {pan_range}px ì´ë™ (2ë°° í™•ëŒ€)")
            print(f"âœ… ì „ì²´ í™”ë©´ ì´ë¯¸ì§€ í´ë¦½ ìƒì„± ì™„ë£Œ!")

            return clip

        except Exception as e:
            print(f"âŒ ì „ì²´ í™”ë©´ ì´ë¯¸ì§€ í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê²€ì€ ë°°ê²½
            return ColorClip(size=(self.video_width, self.video_height),
                           color=(0,0,0), duration=duration)

    def create_fullscreen_video_clip(self, video_path, duration):
        """ì „ì²´ í™”ë©´(504x890)ìš© ë¹„ë””ì˜¤ ë°°ê²½ í´ë¦½ ìƒì„±"""
        print(f"ğŸ¬ ì „ì²´ í™”ë©´ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„±: {os.path.basename(video_path)}")

        try:
            # ë¹„ë””ì˜¤ í´ë¦½ ë¡œë“œ
            video_clip = VideoFileClip(video_path)
            orig_width, orig_height = video_clip.size
            print(f"ğŸ“ ì›ë³¸ ë¹„ë””ì˜¤: {orig_width}x{orig_height}")

            # ì „ì²´ í™”ë©´ì— ë§ì¶° ë¦¬ì‚¬ì´ì¦ˆ (ì¢…íš¡ë¹„ ìœ ì§€í•˜ë©´ì„œ í™”ë©´ ê½‰ ì±„ì›€)
            work_width = self.video_width
            work_height = self.video_height
            work_aspect_ratio = work_width / work_height
            video_aspect_ratio = orig_width / orig_height

            print(f"ğŸ¯ ëª©í‘œ: ì „ì²´ í™”ë©´ {work_width}x{work_height}")

            # í™”ë©´ë¹„ì— ë”°ë¥¸ í¬ë¡­ ë° ë¦¬ì‚¬ì´ì¦ˆ
            if video_aspect_ratio > work_aspect_ratio:
                # ê°€ë¡œí˜• ë¹„ë””ì˜¤: ë†’ì´ ë§ì¶¤ í›„ ì–‘ì˜† í¬ë¡­
                new_height = work_height
                new_width = int(orig_width * new_height / orig_height)
                print(f"ğŸ“ ê°€ë¡œí˜• ë¹„ë””ì˜¤: ë†’ì´ ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ {new_width}x{new_height}")
                video_clip = video_clip.resize(height=new_height)

                # ì¤‘ì•™ í¬ë¡­
                crop_x = (new_width - work_width) // 2
                video_clip = video_clip.crop(x1=crop_x, x2=crop_x + work_width)
            else:
                # ì„¸ë¡œí˜• ë¹„ë””ì˜¤: í­ ë§ì¶¤ í›„ ìƒí•˜ í¬ë¡­
                new_width = work_width
                new_height = int(orig_height * new_width / orig_width)
                print(f"ğŸ“ ì„¸ë¡œí˜• ë¹„ë””ì˜¤: í­ ê¸°ì¤€ ë¦¬ì‚¬ì´ì¦ˆ {new_width}x{new_height}")
                video_clip = video_clip.resize(width=new_width)

                # ì¤‘ì•™ í¬ë¡­
                crop_y = (new_height - work_height) // 2
                video_clip = video_clip.crop(y1=crop_y, y2=crop_y + work_height)

            # ê¸¸ì´ ì¡°ì •
            original_duration = video_clip.duration
            print(f"ğŸ“ ë¹„ë””ì˜¤ ì›ë³¸ ê¸¸ì´: {original_duration:.2f}ì´ˆ, ëª©í‘œ ê¸¸ì´: {duration:.2f}ì´ˆ")

            if original_duration > duration:
                # ë¹„ë””ì˜¤ê°€ ê¸´ ê²½ìš°: ì•ˆì „í•˜ê²Œ ìë¥´ê¸°
                safe_duration = min(duration, original_duration - 0.2)
                video_clip = video_clip.subclip(0, safe_duration)
                print(f"â‚ ë¹„ë””ì˜¤ ê¸¸ì´ ì¡°ì •: {safe_duration:.2f}ì´ˆë¡œ ì˜ë¼ëƒ„")
            elif original_duration < duration:
                # ë¹„ë””ì˜¤ê°€ ì§§ì€ ê²½ìš°: ë°˜ë³µ ì¬ìƒìœ¼ë¡œ ê¸¸ì´ ë§ì¶¤
                try:
                    loop_count = int(duration // original_duration) + 1
                    print(f"ğŸ” ì „ì²´í™”ë©´ ë¹„ë””ì˜¤ ë°˜ë³µ ì²˜ë¦¬: {loop_count}íšŒ ë°˜ë³µí•˜ì—¬ {duration}ì´ˆ ë‹¬ì„±")

                    # ê°œë³„ í´ë¦½ë“¤ì„ ìƒì„±í•´ì„œ ì—°ê²°í•˜ëŠ” ë°©ì‹
                    clips = []
                    current_time = 0

                    while current_time < duration:
                        remaining_time = duration - current_time
                        if remaining_time >= original_duration:
                            # ì „ì²´ í´ë¦½ ì¶”ê°€
                            clips.append(video_clip)
                            current_time += original_duration
                        else:
                            # ë¶€ë¶„ í´ë¦½ ì¶”ê°€ (ì•ˆì „í•˜ê²Œ)
                            safe_remaining = min(remaining_time, original_duration - 0.2)
                            if safe_remaining > 0.2:  # ìµœì†Œ 0.2ì´ˆëŠ” ìˆì–´ì•¼ í•¨
                                print(f"ğŸ“ ë¶€ë¶„ í´ë¦½ ìƒì„±: 0ì´ˆ ~ {safe_remaining:.2f}ì´ˆ")
                                clips.append(video_clip.subclip(0, safe_remaining))
                            current_time = duration  # ë£¨í”„ ì¢…ë£Œ

                    if clips:
                        from moviepy.editor import concatenate_videoclips
                        video_clip = concatenate_videoclips(clips)
                        print(f"âœ… ì „ì²´í™”ë©´ ë¹„ë””ì˜¤ ë°˜ë³µ ì™„ì„±: ìµœì¢… ê¸¸ì´ {video_clip.duration:.2f}ì´ˆ")

                except Exception as e:
                    print(f"âš ï¸ ì „ì²´í™”ë©´ ë¹„ë””ì˜¤ ë°˜ë³µ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    # ì‹¤íŒ¨ ì‹œ ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì—°ì¥ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
                    print("ğŸ“¸ ëŒ€ì•ˆ: ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì—°ì¥ ì²˜ë¦¬")
                    safe_frame_time = max(0, min(original_duration - 0.3, original_duration * 0.9))
                    last_frame = video_clip.to_ImageClip(t=safe_frame_time)
                    extension_duration = duration - original_duration
                    extension_clip = last_frame.set_duration(extension_duration)
                    from moviepy.editor import concatenate_videoclips
                    video_clip = concatenate_videoclips([video_clip, extension_clip])
                    print(f"ğŸ–¼ï¸ ë§ˆì§€ë§‰ í”„ë ˆì„ ì—°ì¥: {extension_duration:.2f}ì´ˆ ì¶”ê°€")

            # ìœ„ì¹˜ ì„¤ì • (í™”ë©´ ê°€ë“)
            video_clip = video_clip.set_position((0, 0))

            print(f"âœ… ì „ì²´ í™”ë©´ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± ì™„ë£Œ!")

            return video_clip

        except Exception as e:
            print(f"âŒ ì „ì²´ í™”ë©´ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± ì‹¤íŒ¨: {e}")
            # í´ë°±: ê²€ì€ ë°°ê²½
            return ColorClip(size=(self.video_width, self.video_height),
                           color=(0,0,0), duration=duration)

    # ==================== ì „í™˜ íš¨ê³¼ ë©”ì†Œë“œë“¤ ====================


    def apply_random_transitions(self, clips, transition_duration=0.4):
        """í´ë¦½ë“¤ ì‚¬ì´ì— ëœë¤ ì „í™˜ íš¨ê³¼ ì ìš©"""
        if len(clips) <= 1:
            return concatenate_videoclips(clips, method="compose") if clips else None

        # ì›ë˜ ì´ ê¸¸ì´ ê³„ì‚° (TTSì™€ ë§ì¶°ì•¼ í•  ê¸°ì¤€)
        original_total_duration = sum(clip.duration for clip in clips)
        print(f"ğŸ¬ ëœë¤ ì „í™˜ íš¨ê³¼ ì ìš©: {len(clips)}ê°œ í´ë¦½, ì›ë³¸ ì´ ê¸¸ì´ {original_total_duration:.2f}ì´ˆ")

        # ë””ì¡¸ë¸Œ ì „í™˜ íš¨ê³¼ë§Œ ì‚¬ìš© (í…ŒìŠ¤íŠ¸ìš©)
        print("ğŸ¬ ë””ì¡¸ë¸Œ ì „í™˜ íš¨ê³¼ í…ŒìŠ¤íŠ¸: ëª¨ë“  ì „í™˜ì„ ë””ì¡¸ë¸Œë¡œ ê³ ì •")

        # ëª¨ë“  í´ë¦½ë“¤ì„ ì²˜ë¦¬í•  ë¦¬ìŠ¤íŠ¸
        processed_clips = []

        for i in range(len(clips)):
            if i == 0:
                # ì²« ë²ˆì§¸ í´ë¦½ì€ ê·¸ëŒ€ë¡œ ì¶”ê°€
                processed_clips.append(clips[i])
                print(f"  ğŸ“¹ í´ë¦½ {i+1}: ì²« ë²ˆì§¸ í´ë¦½ (ì „í™˜ ì—†ìŒ)")
            else:
                # ë””ì¡¸ë¸Œ ì „í™˜ ì ìš©
                print(f"  ğŸ”„ í´ë¦½ {i+1}: ë””ì¡¸ë¸Œ ì „í™˜ ì ìš©")

                try:
                    # ì´ì „ í´ë¦½ê³¼ í˜„ì¬ í´ë¦½ ì‚¬ì´ì— ë””ì¡¸ë¸Œ ì ìš©
                    prev_clip = processed_clips[-1]
                    curr_clip = clips[i]

                    # ì•ˆì „í•œ ì „í™˜ ì‹œê°„ ê³„ì‚° (0.5ì´ˆ)
                    transition_duration = 0.5
                    safe_duration = min(transition_duration, prev_clip.duration * 0.3, curr_clip.duration * 0.3)
                    safe_duration = max(0.2, safe_duration)  # ìµœì†Œ 0.2ì´ˆ

                    # í˜„ì¬ í´ë¦½ì„ ì´ì „ í´ë¦½ ëì—ì„œ ê²¹ì¹˜ë„ë¡ ì‹œì‘ ì‹œê°„ ì„¤ì •
                    curr_clip_overlapped = curr_clip.set_start(prev_clip.duration - safe_duration)

                    # fadein íš¨ê³¼ ì ìš© (ë””ì¡¸ë¸Œ)
                    from moviepy.video.fx.fadein import fadein
                    curr_clip_faded = curr_clip_overlapped.fx(fadein, safe_duration)
                    processed_clips.append(curr_clip_faded)

                    print(f"    âœ¨ ë””ì¡¸ë¸Œ ì ìš©: {safe_duration:.2f}ì´ˆ ë¸”ë Œë”©")

                except Exception as e:
                    print(f"    âš ï¸ ë””ì¡¸ë¸Œ ì‹¤íŒ¨, cutìœ¼ë¡œ ëŒ€ì²´: {e}")
                    processed_clips.append(clips[i])

        # CompositeVideoClipìœ¼ë¡œ ì²˜ë¦¬ (ê²¹ì¹˜ëŠ” í´ë¦½ë“¤ ë•Œë¬¸ì—)
        try:
            final_video = CompositeVideoClip(processed_clips)
            print(f"âœ… ë””ì¡¸ë¸Œ ì „í™˜ ì ìš© ì™„ë£Œ: ìµœì¢… ê¸¸ì´ {final_video.duration:.2f}ì´ˆ")
        except Exception as e:
            print(f"âš ï¸ Composite ì‹¤íŒ¨, concatenateë¡œ ëŒ€ì²´: {e}")
            final_video = concatenate_videoclips([clip for clip in processed_clips if hasattr(clip, 'duration')], method="compose")
            print(f"âœ… ë””ì¡¸ë¸Œ ì „í™˜ ì ìš© ì™„ë£Œ (Fallback): ìµœì¢… ê¸¸ì´ {final_video.duration:.2f}ì´ˆ")

        return final_video

        # ê¸°ì¡´ ì „í™˜ íš¨ê³¼ ì½”ë“œ (ì¼ì‹œì ìœ¼ë¡œ ë¹„í™œì„±í™”)
        """
        transitions = ['cut', 'dissolve', 'wipe']

        # ëª¨ë“  í´ë¦½ë“¤ì„ ì²˜ë¦¬í•  ë¦¬ìŠ¤íŠ¸
        processed_clips = []

        for i in range(len(clips)):
            if i == 0:
                # ì²« ë²ˆì§¸ í´ë¦½ì€ ê·¸ëŒ€ë¡œ ì¶”ê°€
                processed_clips.append(clips[i])
            else:
                # ì´ì „ í´ë¦½ê³¼ í˜„ì¬ í´ë¦½ ì‚¬ì´ì— ì „í™˜ íš¨ê³¼ ì ìš©
                transition_type = random.choice(transitions)
                print(f"  ğŸ”„ í´ë¦½ {i}: {transition_type} ì „í™˜")

                if transition_type == 'cut':
                    # ë‹¨ìˆœ ì—°ê²° (ê¸°ì¡´ ë°©ì‹)
                    processed_clips.append(clips[i])

                elif transition_type == 'dissolve':
                    # í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ - ë” ê°„ë‹¨í•œ ë°©ì‹
                    try:
                        # ì´ì „ í´ë¦½ì˜ ë ë¶€ë¶„ê³¼ í˜„ì¬ í´ë¦½ì˜ ì‹œì‘ ë¶€ë¶„ì„ ì˜¤ë²„ë©
                        prev_clip = processed_clips[-1]
                        curr_clip = clips[i]

                        # ì•ˆì „í•œ ì „í™˜ ì‹œê°„ ê³„ì‚°
                        safe_duration = min(transition_duration, prev_clip.duration * 0.2, curr_clip.duration * 0.2)
                        safe_duration = max(0.1, safe_duration)

                        # í˜„ì¬ í´ë¦½ì„ ì´ì „ í´ë¦½ ëì—ì„œ ê²¹ì¹˜ë„ë¡ ì‹œì‘ ì‹œê°„ ì„¤ì •
                        curr_clip_overlapped = curr_clip.set_start(prev_clip.duration - safe_duration)

                        # fadein íš¨ê³¼ ì ìš©
                        curr_clip_faded = curr_clip_overlapped.fx(fadein, safe_duration)
                        processed_clips.append(curr_clip_faded)

                        print(f"    âœ¨ Cross dissolve: {safe_duration:.2f}ì´ˆ ë¸”ë Œë”©")

                    except Exception as e:
                        print(f"    âš ï¸ Dissolve ì‹¤íŒ¨, cutìœ¼ë¡œ ëŒ€ì²´: {e}")
                        processed_clips.append(clips[i])

                elif transition_type == 'wipe':
                    # ì™€ì´í”„ ì „í™˜
                    try:
                        processed_clip = self._apply_wipe_transition(
                            processed_clips[-1], clips[i], transition_duration * 0.7
                        )
                        # ì „ì²´ compositeë¥¼ ë¦¬ìŠ¤íŠ¸ì˜ ë§ˆì§€ë§‰ ìš”ì†Œë¡œ êµì²´
                        processed_clips[-1] = processed_clip
                    except Exception as e:
                        print(f"    âš ï¸ Wipe ì‹¤íŒ¨, cutìœ¼ë¡œ ëŒ€ì²´: {e}")
                        processed_clips.append(clips[i])

        # dissolveë‚˜ wipeì— ì˜í•´ ê²¹ì¹œ í´ë¦½ë“¤ì€ CompositeVideoClipìœ¼ë¡œ ì²˜ë¦¬í•˜ê³ 
        # ë‚˜ë¨¸ì§€ëŠ” concatenateë¡œ ì²˜ë¦¬
        try:
            final_video = CompositeVideoClip(processed_clips)
            print(f"âœ… ëœë¤ ì „í™˜ ì ìš© ì™„ë£Œ (Composite): ìµœì¢… ê¸¸ì´ {final_video.duration:.2f}ì´ˆ")
        except:
            # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ concatenate ì‚¬ìš©
            final_video = concatenate_videoclips([clip for clip in processed_clips if hasattr(clip, 'duration')], method="compose")
            print(f"âœ… ëœë¤ ì „í™˜ ì ìš© ì™„ë£Œ (Fallback): ìµœì¢… ê¸¸ì´ {final_video.duration:.2f}ì´ˆ")

        return final_video
        """

    def _apply_cross_dissolve(self, clip1, clip2, duration=0.4):
        """í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ íš¨ê³¼ ì ìš© (ì§„ì§œ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ - ê²€ì€ í™”ë©´ ì—†ìŒ)"""
        try:
            # ì•ˆì „í•œ duration ê³„ì‚°
            safe_duration = min(duration, clip1.duration * 0.3, clip2.duration * 0.3)
            safe_duration = max(0.1, safe_duration)  # ìµœì†Œ 0.1ì´ˆ

            # clip1ì„ ê·¸ëŒ€ë¡œ ìœ ì§€
            clip1_part = clip1

            # clip2ë¥¼ clip1 ëì—ì„œ safe_durationë§Œí¼ ì•ë‹¹ê²¨ ì‹œì‘
            # clip2ì˜ ì‹œì‘ ë¶€ë¶„ì— transparency ì• ë‹ˆë©”ì´ì…˜ ì ìš©
            def make_mask(t):
                # 0ì´ˆì—ì„œ safe_durationê¹Œì§€ opacityê°€ 0ì—ì„œ 1ë¡œ ë³€í™”
                if t < safe_duration:
                    opacity = t / safe_duration  # 0 â†’ 1
                    return opacity
                else:
                    return 1.0

            # clip2ë¥¼ íˆ¬ëª…ë„ ì• ë‹ˆë©”ì´ì…˜ê³¼ í•¨ê»˜ ì˜¤ë²„ë©
            clip2_with_alpha = clip2.set_start(clip1.duration - safe_duration)

            # ê°„ë‹¨í•œ linear fade-in ì ìš© (ê²€ì€ìƒ‰ í˜ì´ë“œê°€ ì•„ë‹Œ íˆ¬ëª…ë„ ë³€í™”)
            try:
                # MoviePyì˜ crossfadein ì‚¬ìš© ì‹œë„
                clip2_crossfade = clip2_with_alpha.fx(fadein, safe_duration)
                print(f"    âœ¨ Cross dissolve: {safe_duration:.2f}ì´ˆ ë¸”ë Œë”©")
                return clip1_part, clip2_crossfade
            except:
                # ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ composite ì ìš©
                print(f"    âœ¨ Cross dissolve (simple): {safe_duration:.2f}ì´ˆ ë¸”ë Œë”©")
                return clip1_part, clip2_with_alpha

        except Exception as e:
            print(f"    âš ï¸ Cross dissolve ì‹¤íŒ¨, cutìœ¼ë¡œ ëŒ€ì²´: {e}")
            return clip1, clip2

    def _apply_wipe_transition(self, clip1, clip2, duration=0.3):
        """ì™€ì´í”„ ì „í™˜ íš¨ê³¼ ì ìš© (4ë°©í–¥ ëœë¤)"""
        try:
            wipe_directions = ['left_to_right', 'right_to_left', 'top_to_bottom', 'bottom_to_top']
            direction = random.choice(wipe_directions)

            # ì•ˆì „í•œ duration ê³„ì‚°
            safe_duration = min(duration, clip1.duration * 0.2)
            safe_duration = max(0.1, safe_duration)

            print(f"    ğŸŒŠ Wipe {direction}: {safe_duration:.2f}ì´ˆ")

            # ì™€ì´í”„ ë§ˆìŠ¤í¬ ìƒì„±
            mask_clip = self._create_wipe_mask(direction, safe_duration)

            # clip1ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ê³¼ clip2ì˜ ì‹œì‘ ë¶€ë¶„ì„ ì˜¤ë²„ë©
            clip1_end = clip1.duration

            # clip2ë¥¼ clip1 ëì—ì„œ ì‹œì‘í•˜ë˜, ì™€ì´í”„ durationë§Œí¼ ì•ë‹¹ê¹€
            clip2_with_wipe = clip2.set_start(clip1_end - safe_duration)
            clip2_with_mask = clip2_with_wipe.set_mask(mask_clip.set_start(clip1_end - safe_duration))

            # ë‘ í´ë¦½ì„ í•©ì„±
            composite = CompositeVideoClip([clip1, clip2_with_mask])

            return composite

        except Exception as e:
            print(f"    âš ï¸ Wipe ì „í™˜ ì‹¤íŒ¨, cutìœ¼ë¡œ ëŒ€ì²´: {e}")
            # ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ì—°ê²°
            return concatenate_videoclips([clip1, clip2], method="compose")

    def _create_wipe_mask(self, direction, duration):
        """ì™€ì´í”„ ì „í™˜ìš© ë§ˆìŠ¤í¬ í´ë¦½ ìƒì„±"""
        def make_frame(t):
            # ì§„í–‰ ë¹„ìœ¨ (0 â†’ 1)
            progress = t / duration

            # ë§ˆìŠ¤í¬ ë°°ì—´ ìƒì„± (0=íˆ¬ëª…, 255=ë¶ˆíˆ¬ëª…)
            mask = np.zeros((self.video_height, self.video_width))

            if direction == 'left_to_right':
                # ì¢Œì—ì„œ ìš°ë¡œ
                cutoff = int(self.video_width * progress)
                mask[:, :cutoff] = 255

            elif direction == 'right_to_left':
                # ìš°ì—ì„œ ì¢Œë¡œ
                cutoff = int(self.video_width * (1 - progress))
                mask[:, cutoff:] = 255

            elif direction == 'top_to_bottom':
                # ìƒì—ì„œ í•˜ë¡œ
                cutoff = int(self.video_height * progress)
                mask[:cutoff, :] = 255

            elif direction == 'bottom_to_top':
                # í•˜ì—ì„œ ìƒìœ¼ë¡œ
                cutoff = int(self.video_height * (1 - progress))
                mask[cutoff:, :] = 255

            return mask

        # numpy importê°€ í•„ìš”í•  ìˆ˜ ìˆìŒ
        try:
            import numpy as np
        except ImportError:
            print("    âš ï¸ numpy ì—†ìŒ, ê°„ë‹¨í•œ ë§ˆìŠ¤í¬ ì‚¬ìš©")
            # numpy ì—†ì„ ê²½ìš° ê°„ë‹¨í•œ í˜ì´ë“œ ë§ˆìŠ¤í¬
            return ColorClip(size=(self.video_width, self.video_height),
                           color=(255, 255, 255)).set_duration(duration).fx(fadein, duration)

        mask_clip = VideoClip(make_frame, duration=duration)
        return mask_clip

    def detect_image_transitions(self, clips, media_files, image_allocation_mode):
        """í´ë¦½ê³¼ ë¯¸ë””ì–´ íŒŒì¼ì„ ë§¤í•‘í•˜ì—¬ ì´ë¯¸ì§€-ì´ë¯¸ì§€ ì „í™˜ êµ¬ê°„ì˜ ì¸ë±ìŠ¤ë¥¼ ë°˜í™˜"""
        msg = f"ğŸ” ì´ë¯¸ì§€ ì „í™˜ êµ¬ê°„ ê°ì§€ ì‹œì‘..."
        print(msg)
        logging.info(msg)

        msg = f"   clips ê°œìˆ˜: {len(clips) if clips else 0}"
        print(msg)
        logging.info(msg)

        msg = f"   media_files ê°œìˆ˜: {len(media_files) if media_files else 0}"
        print(msg)
        logging.info(msg)

        msg = f"   image_allocation_mode: {image_allocation_mode}"
        print(msg)
        logging.info(msg)

        if not media_files or not clips:
            msg = "   âš ï¸ media_files ë˜ëŠ” clipsê°€ ì—†ìŠµë‹ˆë‹¤"
            print(msg)
            logging.warning(msg)
            return []

        # í´ë¦½ê³¼ ë¯¸ë””ì–´ íŒŒì¼ ë§¤í•‘ ìƒì„±
        clip_to_media_mapping = self._create_clip_media_mapping(clips, media_files, image_allocation_mode)

        msg = f"   í´ë¦½-ë¯¸ë””ì–´ ë§¤í•‘: {clip_to_media_mapping}"
        print(msg)
        logging.info(msg)

        transition_indices = []
        for i in range(len(clips) - 1):
            try:
                curr_media_idx = clip_to_media_mapping.get(i)
                next_media_idx = clip_to_media_mapping.get(i+1)

                if curr_media_idx is None or next_media_idx is None:
                    msg = f"   [{i}] ë§¤í•‘ ì—†ìŒ: {curr_media_idx} â†’ {next_media_idx}"
                    print(msg)
                    logging.info(msg)
                    continue

                curr_media = media_files[curr_media_idx]
                next_media = media_files[next_media_idx]

                curr_type = curr_media[1] if len(curr_media) > 1 else "unknown"
                next_type = next_media[1] if len(next_media) > 1 else "unknown"

                msg = f"   í´ë¦½ [{i}] â†’ [{i+1}]: ë¯¸ë””ì–´ [{curr_media_idx}] ({curr_type}) â†’ [{next_media_idx}] ({next_type})"
                print(msg)
                logging.info(msg)

                if curr_type == "image" and next_type == "image":
                    transition_indices.append(i)
                    msg = f"  âœ… ì „í™˜ êµ¬ê°„ ë°œê²¬: í´ë¦½ {i} â†’ {i+1} (ì´ë¯¸ì§€â†’ì´ë¯¸ì§€)"
                    print(msg)
                    logging.info(msg)
                else:
                    msg = f"  âŒ ì „í™˜ êµ¬ê°„ ì•„ë‹˜: í´ë¦½ {i} â†’ {i+1} ({curr_type}â†’{next_type})"
                    print(msg)
                    logging.info(msg)

            except Exception as e:
                msg = f"   âš ï¸ í´ë¦½ [{i}] ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}"
                print(msg)
                logging.error(msg)
                continue

        msg = f"ğŸ­ ì´ {len(transition_indices)}ê°œ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ êµ¬ê°„ ê°ì§€: {transition_indices}"
        print(msg)
        logging.info(msg)
        return transition_indices

    def _create_clip_media_mapping(self, clips, media_files, image_allocation_mode):
        """í´ë¦½ê³¼ ë¯¸ë””ì–´ íŒŒì¼ ê°„ì˜ ë§¤í•‘ ìƒì„±"""
        mapping = {}

        if image_allocation_mode == "1_per_image":
            # ê° í´ë¦½ë§ˆë‹¤ ë¯¸ë””ì–´ 1ê°œ
            for i, clip in enumerate(clips):
                media_idx = i % len(media_files)  # ë¯¸ë””ì–´ íŒŒì¼ ìˆœí™˜ ì‚¬ìš©
                mapping[i] = media_idx
        elif image_allocation_mode == "2_per_image":
            # í´ë¦½ 2ê°œë‹¹ ë¯¸ë””ì–´ 1ê°œ
            for i, clip in enumerate(clips):
                media_idx = (i // 2) % len(media_files)  # 2ê°œì”© ë¬¶ì–´ì„œ ë¯¸ë””ì–´ ì‚¬ìš©
                mapping[i] = media_idx
        else:
            # ê¸°ë³¸: 1:1 ë§¤í•‘
            for i, clip in enumerate(clips):
                if i < len(media_files):
                    mapping[i] = i

        return mapping

    def apply_crossfade_to_clips(self, clips, transition_indices, fade_duration=2.0):
        """ì§€ì •ëœ ì „í™˜ êµ¬ê°„ì˜ í´ë¦½ë“¤ì— fade íš¨ê³¼ ì ìš©"""
        print(f"ğŸ¨ apply_crossfade_to_clips í˜¸ì¶œë¨!")
        print(f"   transition_indices: {transition_indices}")
        print(f"   fade_duration: {fade_duration}")
        print(f"   clips ê°œìˆ˜: {len(clips) if clips else 0}")

        if not transition_indices:
            print("   âš ï¸ transition_indicesê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ì›ë³¸ í´ë¦½ ë°˜í™˜")
            return clips

        processed_clips = clips.copy()

        # fade íš¨ê³¼ ì„í¬íŠ¸
        try:
            from moviepy.video.fx import fadeout, fadein
            msg = "   âœ… MoviePy fade íš¨ê³¼ ì„í¬íŠ¸ ì„±ê³µ"
            print(msg)
            logging.info(msg)
        except ImportError as e:
            msg = f"   âš ï¸ MoviePy fade íš¨ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}"
            print(msg)
            logging.error(msg)
            msg = "   -> ê¸°ë³¸ í´ë¦½ì„ ë°˜í™˜í•©ë‹ˆë‹¤."
            print(msg)
            logging.info(msg)
            return clips

        print(f"ğŸ¨ {len(transition_indices)}ê°œ êµ¬ê°„ì— ê°•í™”ëœ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ íš¨ê³¼ ì ìš© (2ì´ˆ)")

        for i in transition_indices:
            try:
                print(f"   ğŸ”„ ì „í™˜ êµ¬ê°„ {i}â†’{i+1} ì²˜ë¦¬ ì¤‘...")

                # ì•ˆì „í•œ fade ì‹œê°„ ê³„ì‚°
                current_clip = processed_clips[i]
                next_clip = processed_clips[i+1]

                print(f"     í˜„ì¬ í´ë¦½ [{i}] ê¸¸ì´: {current_clip.duration:.2f}ì´ˆ")
                print(f"     ë‹¤ìŒ í´ë¦½ [{i+1}] ê¸¸ì´: {next_clip.duration:.2f}ì´ˆ")

                safe_fade = min(fade_duration, current_clip.duration * 0.7, next_clip.duration * 0.7)
                safe_fade = max(0.5, safe_fade)  # ìµœì†Œ 0.5ì´ˆ

                print(f"     ê³„ì‚°ëœ safe_fade: {safe_fade:.2f}ì´ˆ (ìš”ì²­: {fade_duration}ì´ˆ)")

                # í˜„ì¬ í´ë¦½ì— fadeout ì ìš© (ë ë¶€ë¶„)
                print(f"     í˜„ì¬ í´ë¦½ì— fadeout({safe_fade:.2f}ì´ˆ) ì ìš©...")
                faded_current = current_clip.fx(fadeout, safe_fade)
                print(f"     âœ… fadeout ì ìš© ì™„ë£Œ")

                # ë‹¤ìŒ í´ë¦½ì— fadein ì ìš© (ì‹œì‘ ë¶€ë¶„)
                print(f"     ë‹¤ìŒ í´ë¦½ì— fadein({safe_fade:.2f}ì´ˆ) ì ìš©...")
                faded_next = next_clip.fx(fadein, safe_fade)
                print(f"     âœ… fadein ì ìš© ì™„ë£Œ")

                # í´ë¦½ ê¸¸ì´ ì¡°ì •ìœ¼ë¡œ ìì—°ìŠ¤ëŸ¬ìš´ ì˜¤ë²„ë© ìƒì„±
                overlap = safe_fade * 0.6  # ë” ê¸´ ê²¹ì¹¨ (2ì´ˆì˜ 60% = 1.2ì´ˆ)
                print(f"     ê³„ì‚°ëœ overlap: {overlap:.2f}ì´ˆ")

                # í˜„ì¬ í´ë¦½: ë ë¶€ë¶„ ì•½ê°„ ë‹¨ì¶•
                if current_clip.duration > overlap:
                    print(f"     í˜„ì¬ í´ë¦½ ë‹¨ì¶•: {current_clip.duration:.2f}ì´ˆ â†’ {current_clip.duration - overlap:.2f}ì´ˆ")
                    shortened_current = faded_current.subclip(0, current_clip.duration - overlap)
                else:
                    print(f"     í˜„ì¬ í´ë¦½ ë‹¨ì¶• ë¶ˆê°€ (ë„ˆë¬´ ì§§ìŒ)")
                    shortened_current = faded_current

                # ë‹¤ìŒ í´ë¦½: ì‹œì‘ ë¶€ë¶„ ì•½ê°„ ìƒëµ
                if next_clip.duration > overlap:
                    print(f"     ë‹¤ìŒ í´ë¦½ ì‹œí”„íŠ¸: {overlap:.2f}ì´ˆ~{next_clip.duration:.2f}ì´ˆ")
                    shifted_next = faded_next.subclip(overlap, next_clip.duration)
                else:
                    print(f"     ë‹¤ìŒ í´ë¦½ ì‹œí”„íŠ¸ ë¶ˆê°€ (ë„ˆë¬´ ì§§ìŒ)")
                    shifted_next = faded_next

                processed_clips[i] = shortened_current
                processed_clips[i+1] = shifted_next

                print(f"  âœ¨ í´ë¦½ {i}â†’{i+1}: {safe_fade:.2f}ì´ˆ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì ìš© ì™„ë£Œ (ê²¹ì¹¨: {overlap:.2f}ì´ˆ)")

            except Exception as e:
                print(f"  âš ï¸ í´ë¦½ {i}â†’{i+1}: fade íš¨ê³¼ ì ìš© ì‹¤íŒ¨ - {e}")
                import traceback
                traceback.print_exc()
                # ì‹¤íŒ¨ ì‹œ ì›ë³¸ í´ë¦½ ìœ ì§€
                continue

        return processed_clips

    def apply_crossfade_to_clips(self, clips, transition_indices, fade_duration=0.5):
        """ì§€ì •ëœ ì „í™˜ êµ¬ê°„ì˜ í´ë¦½ë“¤ì— fade íš¨ê³¼ ì ìš©"""
        msg = "ğŸ¨ apply_crossfade_to_clips í˜¸ì¶œë¨!"
        print(msg)
        logging.info(msg)

        msg = f"   ì „í™˜ êµ¬ê°„: {transition_indices}"
        print(msg)
        logging.info(msg)

        msg = f"   í˜ì´ë“œ ì‹œê°„: {fade_duration}ì´ˆ"
        print(msg)
        logging.info(msg)

        try:
            # MoviePy fade ëª¨ë“ˆ import ì‹œë„ (ìµœì‹  ë²„ì „ í˜¸í™˜)
            from moviepy.video.fx.fadein import fadein
            from moviepy.video.fx.fadeout import fadeout
            msg = "âœ… MoviePy fade ëª¨ë“ˆ import ì„±ê³µ"
            print(msg)
            logging.info(msg)
        except ImportError as e:
            msg = f"âŒ MoviePy fade ëª¨ë“ˆ import ì‹¤íŒ¨: {e}"
            print(msg)
            logging.error(msg)
            return clips

        processed_clips = []

        for i, clip in enumerate(clips):
            try:
                clip_copy = clip.copy()

                # í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ë¡œì§:
                # transition_indicesì— ìˆëŠ” ì¸ë±ìŠ¤ëŠ” "ì „í™˜ì´ ì‹œì‘ë˜ëŠ” í´ë¦½"ì„ ì˜ë¯¸
                # ì¦‰, í´ë¦½ iì—ì„œ í´ë¦½ i+1ë¡œ ì „í™˜

                # í˜„ì¬ í´ë¦½ì—ì„œ ë‹¤ìŒ í´ë¦½ìœ¼ë¡œì˜ ì „í™˜ (fadeout)
                if i in transition_indices:
                    if clip_copy.duration >= fade_duration:
                        clip_copy = clip_copy.fx(fadeout, fade_duration)
                        msg = f"âœ¨ í´ë¦½ {i}â†’{i+1}: 2ì´ˆ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì ìš© ì™„ë£Œ (fadeout)"
                        print(msg)
                        logging.info(msg)
                    else:
                        msg = f"âš ï¸ í´ë¦½ {i}: ê¸¸ì´({clip_copy.duration:.1f}ì´ˆ)ê°€ í˜ì´ë“œ ì‹œê°„ë³´ë‹¤ ì§§ì•„ fadeout ìƒëµ"
                        print(msg)
                        logging.warning(msg)

                # ì´ì „ í´ë¦½ì—ì„œ í˜„ì¬ í´ë¦½ìœ¼ë¡œì˜ ì „í™˜ (fadein)
                # i-1ì´ transition_indicesì— ìˆìœ¼ë©´ í˜„ì¬ í´ë¦½ì— fadein ì ìš©
                if i > 0 and (i-1) in transition_indices:
                    clip_copy = clip_copy.fx(fadein, fade_duration)
                    msg = f"âœ¨ í´ë¦½ {i-1}â†’{i}: 2ì´ˆ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì ìš© ì™„ë£Œ (fadein)"
                    print(msg)
                    logging.info(msg)

                processed_clips.append(clip_copy)
                msg = f"âœ… í´ë¦½ {i} ì²˜ë¦¬ ì™„ë£Œ"
                print(msg)
                logging.info(msg)

            except Exception as e:
                msg = f"âš ï¸ í´ë¦½ {i} ì²˜ë¦¬ ì‹¤íŒ¨: {e}"
                print(msg)
                logging.error(msg)
                # ì‹¤íŒ¨ ì‹œ ì›ë³¸ í´ë¦½ ì‚¬ìš©
                processed_clips.append(clip)

        msg = f"ğŸ¨ í¬ë¡œìŠ¤í˜ì´ë“œ íš¨ê³¼ ì ìš© ì™„ë£Œ: {len(processed_clips)}ê°œ í´ë¦½"
        print(msg)
        logging.info(msg)

        return processed_clips

    def apply_smart_crossfade_transitions(self, clips, media_files=None, image_allocation_mode="1_per_image", fade_duration=0.5):
        """ê¸°ì¡´ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ìŠ¤ë§ˆíŠ¸ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì ìš©"""
        msg = f"ğŸ¬ apply_smart_crossfade_transitions í˜¸ì¶œë¨!"
        print(msg)
        logging.info(msg)

        msg = f"   clips ê°œìˆ˜: {len(clips) if clips else 0}"
        print(msg)
        logging.info(msg)

        msg = f"   media_files íƒ€ì…: {type(media_files)}"
        print(msg)
        logging.info(msg)

        msg = f"   media_files ê°œìˆ˜: {len(media_files) if media_files else 0}"
        print(msg)
        logging.info(msg)

        msg = f"   image_allocation_mode: {image_allocation_mode}"
        print(msg)
        logging.info(msg)

        msg = f"   fade_duration: {fade_duration}"
        print(msg)
        logging.info(msg)

        if not clips or len(clips) <= 1:
            msg = "   âš ï¸ í´ë¦½ì´ ì—†ê±°ë‚˜ 1ê°œ ì´í•˜ì…ë‹ˆë‹¤. ê¸°ë³¸ ì—°ê²° ì‚¬ìš©"
            print(msg)
            logging.warning(msg)
            return concatenate_videoclips(clips, method="compose") if clips else None

        msg = f"ğŸ¬ ìŠ¤ë§ˆíŠ¸ í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì „í™˜ ì‹œì‘: {len(clips)}ê°œ í´ë¦½ (ê°•í™”ëœ 2ì´ˆ íš¨ê³¼)"
        print(msg)
        logging.info(msg)

        # ì´ë¯¸ì§€-ì´ë¯¸ì§€ ì „í™˜ êµ¬ê°„ ê°ì§€ (ìˆ˜ì •ëœ ë§¤ê°œë³€ìˆ˜)
        msg = "ğŸ” ì´ë¯¸ì§€ ì „í™˜ êµ¬ê°„ ê°ì§€ í˜¸ì¶œ..."
        print(msg)
        logging.info(msg)

        transition_indices = self.detect_image_transitions(clips, media_files, image_allocation_mode)

        msg = f"ğŸ” ê°ì§€ ê²°ê³¼: {transition_indices}"
        print(msg)
        logging.info(msg)

        if not transition_indices:
            msg = "â„¹ï¸ ì´ë¯¸ì§€-ì´ë¯¸ì§€ ì „í™˜ êµ¬ê°„ì´ ì—†ì–´ ì¼ë°˜ ì—°ê²° ì‚¬ìš©"
            print(msg)
            logging.info(msg)

            msg = "   -> concatenate_videoclipsë¡œ ê¸°ë³¸ ì—°ê²°í•©ë‹ˆë‹¤"
            print(msg)
            logging.info(msg)
            return concatenate_videoclips(clips, method="compose")

        # ê°œë³„ í´ë¦½ì— fade íš¨ê³¼ ì ìš©
        print("ğŸ”„ ê°œë³„ í´ë¦½ì— fade íš¨ê³¼ ì ìš© í˜¸ì¶œ...")
        processed_clips = self.apply_crossfade_to_clips(clips, transition_indices, fade_duration)
        print(f"ğŸ”„ fade íš¨ê³¼ ì ìš© ì™„ë£Œ. ì²˜ë¦¬ëœ í´ë¦½ ê°œìˆ˜: {len(processed_clips)}")

        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ìˆœì°¨ ì—°ê²° (CompositeVideoClip ì‚¬ìš© ì•ˆí•¨)
        try:
            print("ğŸ”— ìµœì¢… ì˜ìƒ ì—°ê²° ì‹œì‘...")
            print(f"   ì—°ê²°í•  í´ë¦½ ê°œìˆ˜: {len(processed_clips)}")

            # ê° í´ë¦½ì˜ ìƒíƒœ í™•ì¸
            for i, clip in enumerate(processed_clips):
                try:
                    print(f"   í´ë¦½ [{i}]: ê¸¸ì´ {clip.duration:.2f}ì´ˆ, í¬ê¸° {clip.size}")
                except Exception as e:
                    print(f"   í´ë¦½ [{i}]: ì •ë³´ í™•ì¸ ì‹¤íŒ¨ - {e}")

            final_video = concatenate_videoclips(processed_clips, method="compose")
            print(f"âœ… í¬ë¡œìŠ¤ ë””ì¡¸ë¸Œ ì „í™˜ ì™„ë£Œ: ìµœì¢… ê¸¸ì´ {final_video.duration:.2f}ì´ˆ")
            return final_video
        except Exception as e:
            print(f"âš ï¸ ì „í™˜ íš¨ê³¼ ì ìš© ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            print("   -> ì›ë³¸ í´ë¦½ë“¤ë¡œ ê¸°ë³¸ ì—°ê²°ì„ ì‹œë„í•©ë‹ˆë‹¤...")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ í´ë¦½ë“¤ë¡œ ê¸°ë³¸ ì—°ê²°
            try:
                fallback_video = concatenate_videoclips(clips, method="compose")
                print(f"âœ… ê¸°ë³¸ ì—°ê²° ì„±ê³µ: ê¸¸ì´ {fallback_video.duration:.2f}ì´ˆ")
                return fallback_video
            except Exception as e2:
                print(f"âš ï¸ ê¸°ë³¸ ì—°ê²°ë„ ì‹¤íŒ¨: {e2}")
                return None


